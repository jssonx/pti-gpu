[INFO] At the moment, this sample is incompatible with IGC's ZE binary format.
Run `export IGC_EnableZEBinary=0` to use old format.
    [3811295] minitest process started
  [3811295] Process 3811295, Host headroom
       [3811295] overhead of real-time delta measurement:     87.000 ns.

    [3811295] This test will use a single CPU thread with data array size = 40000000; for 3 iterations

  [3811295] start 3 iterations
    [3811295] Completed iteration 0, thread 0 in   0.330700565 s.
    [3811295] Completed iteration 1, thread 0 in   0.109757933 s.
    [3811295] Completed iteration 2, thread 0 in   0.052729407 s.
  [3811295] end 3 iterations
    [3811295] result p array -- t 0, p[0]=1.1994e+08; p[1]=1.1994e+08; p[2500000]=1.1994e+08; p[5000000]=1.1994e+08; p[39999999]=1.1994e+08
      [3811295] all good -- thread 0:  good count = 40000000
    [3811295]   minitest app exiting
======================================================
    [3811295] running on device: Intel(R) Data Center GPU Max 1100

===== Kernel: _ZTSZZ5tworkiiENKUlRN4sycl3_V17handlerEE_clES2_EUlT_E_ =====
=== File: Unknown ===
		[0x00B70]         illegal                
=== File: /home/users/yuning/pg/qahpct/minitest/intelgpu/single.sycloffload.ipcx/../../src/syclgpu.cc ===
[    1] //==============================================================
[    2] // This code performs GPU offloading using sycl.
[    3] // =============================================================
[    4] #include "minitest.h"
[    5] #include <CL/sycl.hpp>
[    6] #include <vector>
[    7] #include <iostream>
[    8] #include <string>
[    9] 
[   10] using namespace sycl;
[   11] sycl::queue q;
[   12] // sycl::default_selector d_selector;
[   13] 
[   14] // Create an exception handler for asynchronous SYCL exceptions
[   15] static auto exception_handler = [](sycl::exception_list e_list) {
[   16]   for (std::exception_ptr const &e : e_list) {
[   17]     try {
[   18]       std::rethrow_exception(e);
[   19]     }
[   20]     catch (std::exception const &e) {
[   21] #if _DEBUG
[   22]       std::cout << "Failure" << std::endl;
[   23] #endif
[   24]       std::terminate();
[   25]     }
[   26]   }
[   27] };
[   28] 
[   29] void
[   30] twork( int iter, int threadnum)
[   31] {
[   32]   hrtime_t starttime = gethrtime();
[   33] 
[   34]   int nelements = nn;
[   35]   double *l1 = lptr[threadnum];
[   36]   double *r1 = rptr[threadnum];
[   37]   double *p1 = pptr[threadnum];
[   38] 
[   39]   // Create buffers that hold the data shared between the host and the devices.
[   40]   // The buffer destructor is responsible to copy the data back to host when it
[   41]   // goes out of scope.
[   42]   buffer<double, 1> a(l1, nn);
[   43]   buffer<double, 1> b(r1, nn);
[   44]   buffer<double, 1> c(p1, nn);
[   45] 
[   46]   // Submit a command group to the queue by a lambda function that contains the
[   47]   // data access permission and device computation (kernel).
[   48]   q.submit([&](handler &h) {
[   49]     // Create an accessor for each buffer with access permission: read, write or
[   50]     // read/write. The accessor is a mean to access the memory in the buffer.
[   51]     accessor d_l1(a, h, read_only);
[   52]     accessor d_r1(b, h, read_only);
[   53]     accessor d_p1(c, h, read_write);
[   54] 
[   55]     // Use parallel_for to run vector addition in parallel on device. This
[   56]     // executes the kernel.
[   57]     //    1st parameter is the number of work items.
[   58]     //    2nd parameter is the kernel, a lambda that specifies what to do per
[   59]     //    work item. The parameter of the lambda is the work item id.
[   60]     // DPC++ supports unnamed lambda kernel by default.
[   61] 
[   62]     h.parallel_for(nelements, [=](auto i) {
		[0x00000] (W)     mov (16|M0)              r127.0<1>:ud  0x0:ud                             
		[0x00010] (W)     and (1|M0)               r127.2<1>:ud  r0.0<0;1,0>:ud    0xFFFFFFC0:ud             
		[0x00020] (W)     and (1|M0)               r127.0<1>:uw  r0.4<0;1,0>:uw    0xFF:uw             
		[0x00030] (W)     add (1|M0)               r127.2<1>:ud  r127.2<0;1,0>:ud  0x80:uw              {I@2}
		[0x00040] (W)     add (1|M0)               r127.2<1>:ud  r127.2<0;1,0>:ud  0x0:ud              {I@1}
		[0x00050] (W)     mad (1|M0)               r127.0<1>:ud  r127.2<0;0>:ud    r127.0<0;0>:uw    0xC0:uw              {I@1}
		[0x00060]         send.ugm (1|M0)          r1       r127    null:0  0xFF000000            0x6228E500           {A@1,$0} // wr:1+0, rd:2; load.ugm.d32x32t.a32.ca.ca.bti[255]
		[0x00070] (W)     add (1|M0)               r127.0<1>:ud  r127.0<0;1,0>:ud  0x80:uw              {$0.src}
		[0x00080]         send.ugm (1|M0)          r3       r127    null:0  0xFF000000            0x6218D500           {A@1,$1} // wr:1+0, rd:1; load.ugm.d32x16t.a32.ca.ca.bti[255]
		[0x00090]         nop                    
		[0x000A0]         nop                    
		[0x000B0]         nop                    
		[0x000C0] (W)     and (1|M0)               r127.0<1>:ud  r0.0<0;1,0>:ud    0xFFFFFFC0:ud              {$1.src}
		[0x000D0] (W)     add (1|M0)               r127.0<1>:ud  r127.0<0;1,0>:ud  0x0:ud              {I@1}
		[0x000E0]         send.ugm (1|M0)          r4       r127    null:0  0xFF000000            0x6228E500           {I@1,$2} // wr:1+0, rd:2; load.ugm.d32x32t.a32.ca.ca.bti[255]
		[0x000F0] (W)     or (1|M0)                cr0.0<1>:ud   cr0.0<0;1,0>:ud   0x4C0:uw              {Compacted,A@1}
[   63] #include "compute.h"
[   64]     } );
[   65]   } );
[   66] 
[   67]   hrtime_t endtime = gethrtime();
[   68]   double  tempus =  (double) (endtime - starttime) / (double)1000000000.;
[   69] #if 1
[   70]  fprintf(stderr, "    [%d] Completed iteration %d, thread %d in %13.9f s.\n",
[   71]    thispid, iter, threadnum, tempus);
[   72] #endif
[   73]   spacer(50, true);
[   74] 
[   75] }
[   76] 
[   77] void
[   78] initgpu()
[   79] {
[   80]   try {
[   81]     queue origq(exception_handler);
[   82] 
[   83]     // Print out the device information used for the kernel code.
[   84]     std::cout << "    [" << thispid << "] running on device: "
[   85]               << origq.get_device().get_info<info::device::name>() << "\n";
[   86]     q = origq;
[   87] 
[   88]   } catch (exception const &e) {
[   89]     std::cout << "An exception is caught trying to determine device.\n";
[   90]     std::terminate();
[   91]   }
[   92] }
=== File: /storage/users/yuning/intel/oneapi/compiler/2024.1/bin/compiler/../../include/sycl/accessor.hpp ===
[    1] //==------------ accessor.hpp - SYCL standard header file ------------------==//
[    2] //
[    3] // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
[    4] // See https://llvm.org/LICENSE.txt for license information.
[    5] // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
[    6] //
[    7] //===----------------------------------------------------------------------===//
[    8] 
[    9] #pragma once
[   10] 
[   11] #include <sycl/access/access.hpp>                     // for target, mode
[   12] #include <sycl/aliases.hpp>                           // for float4, int4
[   13] #include <sycl/aspects.hpp>                           // for aspect
[   14] #include <sycl/atomic.hpp>                            // for atomic
[   15] #include <sycl/buffer.hpp>                            // for range
[   16] #include <sycl/detail/accessor_iterator.hpp>          // for accessor_iterator
[   17] #include <sycl/detail/common.hpp>                     // for code_location
[   18] #include <sycl/detail/defines.hpp>                    // for __SYCL_SPECIAL...
[   19] #include <sycl/detail/defines_elementary.hpp>         // for __SYCL2020_DEP...
[   20] #include <sycl/detail/export.hpp>                     // for __SYCL_EXPORT
[   21] #include <sycl/detail/generic_type_traits.hpp>        // for is_genint, Try...
[   22] #include <sycl/detail/handler_proxy.hpp>              // for associateWithH...
[   23] #include <sycl/detail/helpers.hpp>                    // for loop
[   24] #include <sycl/detail/image_accessor_util.hpp>        // for imageReadSampl...
[   25] #include <sycl/detail/owner_less_base.hpp>            // for OwnerLessBase
[   26] #include <sycl/detail/pi.h>                           // for PI_ERROR_INVAL...
[   27] #include <sycl/detail/property_helper.hpp>            // for PropWithDataKind
[   28] #include <sycl/detail/property_list_base.hpp>         // for PropertyListBase
[   29] #include <sycl/detail/type_list.hpp>                  // for is_contained
[   30] #include <sycl/detail/type_traits.hpp>                // for const_if_const_AS
[   31] #include <sycl/device.hpp>                            // for device
[   32] #include <sycl/exception.hpp>                         // for make_error_code
[   33] #include <sycl/ext/oneapi/accessor_property_list.hpp> // for accessor_prope...
[   34] #include <sycl/ext/oneapi/weak_object_base.hpp>       // for getSyclWeakObj...
[   35] #include <sycl/id.hpp>                                // for id
[   36] #include <sycl/image.hpp>                             // for image, image_c...
[   37] #include <sycl/multi_ptr.hpp>                         // for multi_ptr
[   38] #include <sycl/pointers.hpp>                          // for local_ptr, glo...
[   39] #include <sycl/properties/accessor_properties.hpp>    // for buffer_location
[   40] #include <sycl/properties/buffer_properties.hpp>      // for buffer, buffer...
[   41] #include <sycl/property_list.hpp>                     // for property_list
[   42] #include <sycl/range.hpp>                             // for range
[   43] #include <sycl/sampler.hpp>                           // for addressing_mode
[   44] #include <sycl/types.hpp>                             // for vec
[   45] 
[   46] #ifdef __SYCL_DEVICE_ONLY__
[   47] #include <sycl/detail/image_ocl_types.hpp>
[   48] #endif
[   49] 
[   50] #include <cstddef>     // for size_t
[   51] #include <functional>  // for hash
[   52] #include <iterator>    // for reverse_iterator
[   53] #include <limits>      // for numeric_limits
[   54] #include <memory>      // for shared_ptr
[   55] #include <optional>    // for nullopt, optional
[   56] #include <stdint.h>    // for uint32_t
[   57] #include <tuple>       // for _Swallow_assign
[   58] #include <type_traits> // for enable_if_t
[   59] #include <typeinfo>    // for type_info
[   60] #include <variant>     // for hash
[   61] 
[   62] /// \file accessor.hpp
[   63] /// The file contains implementations of accessor class.
[   64] ///
[   65] /// Objects of accessor class define a requirement to access some SYCL memory
[   66] /// object or local memory of the device.
[   67] ///
[   68] /// Basically there are 3 distinct types of accessors.
[   69] ///
[   70] /// One of them is an accessor to a SYCL buffer object(Buffer accessor) which
[   71] /// has the richest interface. It supports things like accessing only a part of
[   72] /// buffer, multidimensional access using sycl::id, conversions to various
[   73] /// multi_ptr and atomic classes.
[   74] ///
[   75] /// Second type is an accessor to a SYCL image object(Image accessor) which has
[   76] /// "image" specific methods for reading and writing.
[   77] ///
[   78] /// Finally, accessor to local memory(Local accessor) doesn't require access to
[   79] /// any SYCL memory object, but asks for some local memory on device to be
[   80] /// available. Some methods overlap with ones that "Buffer accessor" provides.
[   81] ///
[   82] /// Buffer and Image accessors create the requirement to access some SYCL memory
[   83] /// object(or part of it). SYCL RT must detect when two kernels want to access
[   84] /// the same memory objects and make sure they are executed in correct order.
[   85] ///
[   86] /// "accessor_common" class that contains several common methods between Buffer
[   87] /// and Local accessors.
[   88] ///
[   89] /// Accessors have different representation on host and on device. On host they
[   90] /// have non-templated base class, that is needed to safely work with any
[   91] /// accessor type. Furhermore on host we need some additional fields in order
[   92] /// to implement functionality required by Specification, for example during
[   93] /// lifetime of a host accessor other operations with memory object the accessor
[   94] /// refers to should be blocked and when all references to the host accessor are
[   95] /// desctructed, the memory this host accessor refers to should be "written
[   96] /// back".
[   97] ///
[   98] /// The scheme of inheritance for host side:
[   99] ///
[  100] /// \dot
[  101] /// digraph G {
[  102] ///    node [shape="box"];
[  103] ///    graph [splines=ortho];
[  104] ///    a1 [label =
[  105] ///   "accessor(1)\nFor targets:\nhost_buffer\nglobal_buffer\nconstant_buffer"];
[  106] ///    a2 [label = "accessor(2)\nFor targets:\n host_image"];
[  107] ///    a3 [label = "accessor(3)\nFor targets:\nlocal"];
[  108] ///    a4 [label = "accessor(4)\nFor targets:\nimage"];
[  109] ///    a5 [label = "accessor(5)\nFor targets:\nimage_array"];
[  110] ///    "AccessorBaseHost" -> "image_accessor";
[  111] ///    "AccessorBaseHost" -> a1;
[  112] ///    "accessor_common" -> a1;
[  113] ///    "accessor_common" -> a3;
[  114] ///    "LocalAccessorBaseHost" -> a3;
[  115] ///    "image_accessor" -> a2;
[  116] ///    "image_accessor" -> a4;
[  117] ///    "image_accessor" -> a5;
[  118] /// }
[  119] /// \enddot
[  120] ///
[  121] //  +------------------+     +-----------------+     +-----------------------+
[  122] //  |                  |     |                 |     |                       |
[  123] //  | AccessorBaseHost |     | accessor_common |     | LocalAccessorBaseHost |
[  124] //  |                  |     |                 |     |                       |
[  125] //  +------------------+     +-----+-----------+     +--------+--------------+
[  126] //         |     |                     |   |                   |
[  127] //         |     +-----------+    +----+   +---------+  +------+
[  128] //         |                 |    |                  |  |
[  129] //         v                 v    v                  v  v
[  130] //  +----------------+  +-----------------+   +-------------+
[  131] //  |                |  |   accessor(1)   |   | accessor(3) |
[  132] //  | image_accessor |  +-----------------|   +-------------+
[  133] //  |                |  | for targets:    |   | for target: |
[  134] //  +---+---+---+----+  |                 |   |             |
[  135] //      |   |   |       | host_buffer     |   | local       |
[  136] //      |   |   |       | global_buffer   |   +-------------+
[  137] //      |   |   |       | constant_buffer |
[  138] //      |   |   |       +-----------------+
[  139] //      |   |   |
[  140] //      |   |   +------------------------------------+
[  141] //      |   |                                        |
[  142] //      |   +----------------------+                 |
[  143] //      v                          v                 v
[  144] //  +-----------------+    +--------------+    +-------------+
[  145] //  |     acessor(2)  |    |  accessor(4) |    | accessor(5) |
[  146] //  +-----------------+    +--------------+    +-------------+
[  147] //  | for targets:    |    | for targets: |    | for target: |
[  148] //  |                 |    |              |    |             |
[  149] //  | host_image      |    |  image       |    | image_array |
[  150] //  +-----------------+    +--------------+    +-------------+
[  151] //
[  152] /// \file accessor.hpp
[  153] ///
[  154] /// For host side AccessorBaseHost/LocalAccessorBaseHost contains shared_ptr
[  155] /// which points to AccessorImplHost/LocalAccessorImplHost object.
[  156] ///
[  157] /// The scheme of inheritance for device side:
[  158] /// \dot
[  159] /// digraph Diagram {
[  160] ///    node [shape="box"];
[  161] ///    a1 [label =
[  162] ///   "accessor(1)\nFor targets:\nhost_buffer\nglobal_buffer\nconstant_buffer"];
[  163] ///    a2 [label = "accessor(2)\nFor targets:\nhost_image"];
[  164] ///    a3 [label = "accessor(3)\nFor targets:\nlocal"];
[  165] ///    a4 [label = "accessor(4)\nFor targets:\nimage"];
[  166] ///    a5 [label = "accessor(5)\nFor targets:\nimage_array"];
[  167] ///    "accessor_common" -> a1;
[  168] ///    "accessor_common" -> a3;
[  169] ///    "image_accessor" -> a2;
[  170] ///    "image_accessor" -> a4;
[  171] ///    "image_accessor" -> a5;
[  172] ///    a1 -> "host_accessor";
[  173] /// }
[  174] /// \enddot
[  175] ///
[  176] //
[  177] //                            +-----------------+
[  178] //                            |                 |
[  179] //                            | accessor_common |
[  180] //                            |                 |
[  181] //                            +-----+-------+---+
[  182] //                                     |       |
[  183] //                                +----+       +-----+
[  184] //                                |                  |
[  185] //                                v                  v
[  186] //  +----------------+  +-----------------+   +-------------+
[  187] //  |                |  |   accessor(1)   |   | accessor(3) |
[  188] //  | image_accessor |  +-----------------|   +-------------+
[  189] //  |                |  | for targets:    |   | for target: |
[  190] //  +---+---+---+----+  |                 |   |             |
[  191] //      |   |   |       | host_buffer     |   | local       |
[  192] //      |   |   |       | global_buffer   |   +-------------+
[  193] //      |   |   |       | constant_buffer |
[  194] //      |   |   |       +-----------------+
[  195] //      |   |   |                 |
[  196] //      |   |   |                 v
[  197] //      |   |   |       +-----------------+
[  198] //      |   |   |       |                 |
[  199] //      |   |   |       |  host_accessor  |
[  200] //      |   |   |       |                 |
[  201] //      |   |   |       +-----------------+
[  202] //      |   |   |
[  203] //      |   |   +------------------------------------+
[  204] //      |   |                                        |
[  205] //      |   +----------------------+                 |
[  206] //      v                          v                 v
[  207] //  +-----------------+    +--------------+    +-------------+
[  208] //  |     acessor(2)  |    |  accessor(4) |    | accessor(5) |
[  209] //  +-----------------+    +--------------+    +-------------+
[  210] //  | for targets:    |    | for targets: |    | for target: |
[  211] //  |                 |    |              |    |             |
[  212] //  | host_image      |    |  image       |    | image_array |
[  213] //  +-----------------+    +--------------+    +-------------+
[  214] //
[  215] /// \file accessor.hpp
[  216] ///
[  217] /// For device side AccessorImplHost/LocalAccessorImplHost are fileds of
[  218] /// accessor(1) and accessor(3).
[  219] ///
[  220] /// accessor(1) declares accessor as a template class and implements accessor
[  221] /// class for access targets: host_buffer, global_buffer and constant_buffer.
[  222] ///
[  223] /// accessor(3) specializes accessor(1) for the local access target.
[  224] ///
[  225] /// image_accessor contains implements interfaces for access targets:
[  226] /// host_image, image and image_array. But there are three distinct
[  227] /// specializations of the accessor(1) (accessor(2), accessor(4), accessor(5))
[  228] /// that are just inherited from image_accessor.
[  229] ///
[  230] /// accessor_common contains several helpers common for both accessor(1) and
[  231] /// accessor(3)
[  232] 
[  233] namespace sycl {
[  234] inline namespace _V1 {
[  235] class stream;
[  236] namespace ext::intel::esimd::detail {
[  237] // Forward declare a "back-door" access class to support ESIMD.
[  238] class AccessorPrivateProxy;
[  239] } // namespace ext::intel::esimd::detail
[  240] 
[  241] template <typename DataT, int Dimensions = 1,
[  242]           access::mode AccessMode = access::mode::read_write,
[  243]           access::target AccessTarget = access::target::device,
[  244]           access::placeholder IsPlaceholder = access::placeholder::false_t,
[  245]           typename PropertyListT = ext::oneapi::accessor_property_list<>>
[  246] class accessor;
[  247] 
[  248] namespace detail {
[  249] 
[  250] // A helper structure which is shared between buffer accessor and accessor_impl
[  251] // TODO: Unify with AccessorImplDevice?
[  252] struct AccHostDataT {
[  253]   AccHostDataT(const sycl::id<3> &Offset, const sycl::range<3> &Range,
[  254]                const sycl::range<3> &MemoryRange, void *Data = nullptr)
[  255]       : MOffset(Offset), MAccessRange(Range), MMemoryRange(MemoryRange),
[  256]         MData(Data) {}
[  257] 
[  258]   sycl::id<3> MOffset;
[  259]   sycl::range<3> MAccessRange;
[  260]   sycl::range<3> MMemoryRange;
[  261]   void *MData = nullptr;
[  262]   void *Reserved = nullptr;
[  263] };
[  264] 
[  265] void __SYCL_EXPORT constructorNotification(void *BufferObj, void *AccessorObj,
[  266]                                            access::target Target,
[  267]                                            access::mode Mode,
[  268]                                            const code_location &CodeLoc);
[  269] 
[  270] void __SYCL_EXPORT unsampledImageConstructorNotification(
[  271]     void *ImageObj, void *AccessorObj,
[  272]     const std::optional<image_target> &Target, access::mode Mode,
[  273]     const void *Type, uint32_t ElemSize, const code_location &CodeLoc);
[  274] 
[  275] void __SYCL_EXPORT sampledImageConstructorNotification(
[  276]     void *ImageObj, void *AccessorObj,
[  277]     const std::optional<image_target> &Target, const void *Type,
[  278]     uint32_t ElemSize, const code_location &CodeLoc);
[  279] 
[  280] template <typename T>
[  281] using IsPropertyListT = typename std::is_base_of<PropertyListBase, T>;
[  282] 
[  283] template <typename T>
[  284] using IsRunTimePropertyListT =
[  285]     typename std::is_same<ext::oneapi::accessor_property_list<>, T>;
[  286] 
[  287] template <typename T> struct IsCxPropertyList {
[  288]   constexpr static bool value = false;
[  289] };
[  290] 
[  291] template <typename... Props>
[  292] struct IsCxPropertyList<ext::oneapi::accessor_property_list<Props...>> {
[  293]   constexpr static bool value = true;
[  294] };
[  295] 
[  296] template <> struct IsCxPropertyList<ext::oneapi::accessor_property_list<>> {
[  297]   constexpr static bool value = false;
[  298] };
[  299] 
[  300] // Zero-dimensional accessors references at-most a single element, so the range
[  301] // is either 0 if the associated buffer is empty or 1 otherwise.
[  302] template <typename BufferT>
[  303] sycl::range<1> GetZeroDimAccessRange(BufferT Buffer) {
[  304]   return std::min(Buffer.size(), size_t{1});
[  305] }
[  306] 
[  307] __SYCL_EXPORT device getDeviceFromHandler(handler &CommandGroupHandlerRef);
[  308] 
[  309] template <typename DataT, int Dimensions, access::mode AccessMode,
[  310]           access::target AccessTarget, access::placeholder IsPlaceholder,
[  311]           typename PropertyListT = ext::oneapi::accessor_property_list<>>
[  312] class accessor_common {
[  313] protected:
[  314]   constexpr static access::address_space AS = TargetToAS<AccessTarget>::AS;
[  315] 
[  316]   constexpr static bool IsHostBuf = AccessTarget == access::target::host_buffer;
[  317]   constexpr static bool IsHostTask = AccessTarget == access::target::host_task;
[  318]   // SYCL2020 4.7.6.9.4.3
[  319]   // IsPlaceHolder template parameter has no bearing on whether the accessor
[  320]   // instance is a placeholder. This is determined solely by the constructor.
[  321]   // The rule seems to be: if the constructor receives a CommandGroupHandler
[  322]   // it is NOT a placeholder. Otherwise, it is a placeholder.
[  323]   // However, according to 4.7.6.9.4.6. accessor specialization with
[  324]   // target::host_buffer is never a placeholder. So, if the constructor
[  325]   // used receives a CommandGroupHandler, the accessor will never be a
[  326]   // placeholder. If it doesn't, but IsHostBuf is true, it won't be a
[  327]   // placeholder either. Otherwise, the accessor is a placeholder.
[  328]   constexpr static bool IsPlaceH = !IsHostBuf;
[  329] 
[  330]   // TODO: SYCL 2020 deprecates four of the target enum values
[  331]   // and replaces them with 2 (device and host_task). May want
[  332]   // to change these constexpr.
[  333]   constexpr static bool IsGlobalBuf =
[  334]       AccessTarget == access::target::global_buffer;
[  335] 
[  336]   constexpr static bool IsConstantBuf =
[  337]       AccessTarget == access::target::constant_buffer;
[  338] 
[  339]   constexpr static bool IsAccessAnyWrite =
[  340]       AccessMode == access::mode::write ||
[  341]       AccessMode == access::mode::read_write ||
[  342]       AccessMode == access::mode::discard_write ||
[  343]       AccessMode == access::mode::discard_read_write;
[  344] 
[  345]   constexpr static bool IsAccessReadOnly = AccessMode == access::mode::read;
[  346]   static constexpr bool IsConst = std::is_const_v<DataT>;
[  347] 
[  348]   constexpr static bool IsAccessReadWrite =
[  349]       AccessMode == access::mode::read_write;
[  350] 
[  351]   constexpr static bool IsAccessAtomic = AccessMode == access::mode::atomic;
[  352] 
[  353]   using RefType = detail::const_if_const_AS<AS, DataT> &;
[  354]   using ConstRefType = const DataT &;
[  355]   using PtrType = detail::const_if_const_AS<AS, DataT> *;
[  356] 
[  357]   // The class which allows to access value of N dimensional accessor using N
[  358]   // subscript operators, e.g. accessor[2][2][3]
[  359]   template <int SubDims,
[  360]             typename AccType =
[  361]                 accessor<DataT, Dimensions, AccessMode, AccessTarget,
[  362]                          IsPlaceholder, PropertyListT>>
[  363]   class AccessorSubscript {
[  364]     static constexpr int Dims = Dimensions;
[  365] 
[  366]     mutable id<Dims> MIDs;
[  367]     AccType MAccessor;
[  368] 
[  369]   public:
[  370]     AccessorSubscript(AccType Accessor, id<Dims> IDs)
[  371]         : MIDs(IDs), MAccessor(Accessor) {}
[  372] 
[  373]     // Only accessor class is supposed to use this c'tor for the first
[  374]     // operator[].
[  375]     AccessorSubscript(AccType Accessor, size_t Index) : MAccessor(Accessor) {
[  376]       MIDs[0] = Index;
[  377]     }
[  378] 
[  379]     template <int CurDims = SubDims, typename = std::enable_if_t<(CurDims > 1)>>
[  380]     auto operator[](size_t Index) {
[  381]       MIDs[Dims - CurDims] = Index;
[  382]       return AccessorSubscript<CurDims - 1, AccType>(MAccessor, MIDs);
[  383]     }
[  384] 
[  385]     template <int CurDims = SubDims,
[  386]               typename = std::enable_if_t<CurDims == 1 && (IsAccessReadOnly ||
[  387]                                                            IsAccessAnyWrite)>>
[  388]     typename AccType::reference operator[](size_t Index) const {
[  389]       MIDs[Dims - CurDims] = Index;
[  390]       return MAccessor[MIDs];
[  391]     }
[  392] 
[  393]     template <int CurDims = SubDims>
[  394]     typename std::enable_if_t<CurDims == 1 && IsAccessAtomic, atomic<DataT, AS>>
[  395]     operator[](size_t Index) const {
[  396]       MIDs[Dims - CurDims] = Index;
[  397]       return MAccessor[MIDs];
[  398]     }
[  399]   };
[  400] };
[  401] 
[  402] template <typename DataT> constexpr access::mode accessModeFromConstness() {
[  403]   if constexpr (std::is_const_v<DataT>)
[  404]     return access::mode::read;
[  405]   else
[  406]     return access::mode::read_write;
[  407] }
[  408] 
[  409] template <typename MayBeTag1, typename MayBeTag2>
[  410] constexpr access::mode deduceAccessMode() {
[  411]   // property_list = {} is not properly detected by deduction guide,
[  412]   // when parameter is passed without curly braces: access(buffer, no_init)
[  413]   // thus simplest approach is to check 2 last arguments for being a tag
[  414]   if constexpr (std::is_same_v<MayBeTag1, mode_tag_t<access::mode::read>> ||
[  415]                 std::is_same_v<MayBeTag2, mode_tag_t<access::mode::read>>) {
[  416]     return access::mode::read;
[  417]   }
[  418] 
[  419]   if constexpr (std::is_same_v<MayBeTag1, mode_tag_t<access::mode::write>> ||
[  420]                 std::is_same_v<MayBeTag2, mode_tag_t<access::mode::write>>) {
[  421]     return access::mode::write;
[  422]   }
[  423] 
[  424]   if constexpr (std::is_same_v<
[  425]                     MayBeTag1,
[  426]                     mode_target_tag_t<access::mode::read,
[  427]                                       access::target::constant_buffer>> ||
[  428]                 std::is_same_v<
[  429]                     MayBeTag2,
[  430]                     mode_target_tag_t<access::mode::read,
[  431]                                       access::target::constant_buffer>>) {
[  432]     return access::mode::read;
[  433]   }
[  434] 
[  435]   if constexpr (std::is_same_v<MayBeTag1,
[  436]                                mode_target_tag_t<access::mode::read,
[  437]                                                  access::target::host_task>> ||
[  438]                 std::is_same_v<MayBeTag2,
[  439]                                mode_target_tag_t<access::mode::read,
[  440]                                                  access::target::host_task>>) {
[  441]     return access::mode::read;
[  442]   }
[  443] 
[  444]   if constexpr (std::is_same_v<MayBeTag1,
[  445]                                mode_target_tag_t<access::mode::write,
[  446]                                                  access::target::host_task>> ||
[  447]                 std::is_same_v<MayBeTag2,
[  448]                                mode_target_tag_t<access::mode::write,
[  449]                                                  access::target::host_task>>) {
[  450]     return access::mode::write;
[  451]   }
[  452] 
[  453]   return access::mode::read_write;
[  454] }
[  455] 
[  456] template <typename MayBeTag1, typename MayBeTag2>
[  457] constexpr access::target deduceAccessTarget(access::target defaultTarget) {
[  458]   if constexpr (std::is_same_v<
[  459]                     MayBeTag1,
[  460]                     mode_target_tag_t<access::mode::read,
[  461]                                       access::target::constant_buffer>> ||
[  462]                 std::is_same_v<
[  463]                     MayBeTag2,
[  464]                     mode_target_tag_t<access::mode::read,
[  465]                                       access::target::constant_buffer>>) {
[  466]     return access::target::constant_buffer;
[  467]   }
[  468] 
[  469]   if constexpr (
[  470]       std::is_same_v<MayBeTag1, mode_target_tag_t<access::mode::read,
[  471]                                                   access::target::host_task>> ||
[  472]       std::is_same_v<MayBeTag2, mode_target_tag_t<access::mode::read,
[  473]                                                   access::target::host_task>> ||
[  474]       std::is_same_v<MayBeTag1, mode_target_tag_t<access::mode::write,
[  475]                                                   access::target::host_task>> ||
[  476]       std::is_same_v<MayBeTag2, mode_target_tag_t<access::mode::write,
[  477]                                                   access::target::host_task>> ||
[  478]       std::is_same_v<MayBeTag1, mode_target_tag_t<access::mode::read_write,
[  479]                                                   access::target::host_task>> ||
[  480]       std::is_same_v<MayBeTag2, mode_target_tag_t<access::mode::read_write,
[  481]                                                   access::target::host_task>>) {
[  482]     return access::target::host_task;
[  483]   }
[  484] 
[  485]   return defaultTarget;
[  486] }
[  487] 
[  488] template <int Dims> class LocalAccessorBaseDevice {
[  489] public:
[  490]   LocalAccessorBaseDevice(sycl::range<Dims> Size)
[  491]       : AccessRange(Size),
[  492]         MemRange(InitializedVal<Dims, range>::template get<0>()) {}
[  493]   // TODO: Actually we need only one field here, but currently compiler requires
[  494]   // all of them.
[  495]   range<Dims> AccessRange;
[  496]   range<Dims> MemRange;
[  497]   id<Dims> Offset;
[  498] 
[  499]   bool operator==(const LocalAccessorBaseDevice &Rhs) const {
[  500]     return (AccessRange == Rhs.AccessRange);
[  501]   }
[  502] };
[  503] 
[  504] // The class describes a requirement to access a SYCL memory object such as
[  505] // sycl::buffer and sycl::image. For example, each accessor used in a kernel,
[  506] // except one with access target "local", adds such requirement for the command
[  507] // group.
[  508] 
[  509] template <int Dims> class AccessorImplDevice {
[  510] public:
[  511]   AccessorImplDevice() = default;
[  512]   AccessorImplDevice(id<Dims> Offset, range<Dims> AccessRange,
[  513]                      range<Dims> MemoryRange)
[  514]       : Offset(Offset), AccessRange(AccessRange), MemRange(MemoryRange) {}
[  515] 
[  516]   id<Dims> Offset;
[  517]   range<Dims> AccessRange;
[  518]   range<Dims> MemRange;
[  519] 
[  520]   bool operator==(const AccessorImplDevice &Rhs) const {
[  521]     return (Offset == Rhs.Offset && AccessRange == Rhs.AccessRange &&
[  522]             MemRange == Rhs.MemRange);
[  523]   }
[  524] };
[  525] 
[  526] class AccessorImplHost;
[  527] 
[  528] void __SYCL_EXPORT addHostAccessorAndWait(AccessorImplHost *Req);
[  529] 
[  530] class SYCLMemObjI;
[  531] 
[  532] using AccessorImplPtr = std::shared_ptr<AccessorImplHost>;
[  533] 
[  534] class __SYCL_EXPORT AccessorBaseHost {
[  535] protected:
[  536]   AccessorBaseHost(const AccessorImplPtr &Impl) : impl{Impl} {}
[  537] 
[  538] public:
[  539]   // TODO: the following function to be removed during next ABI break window
[  540]   AccessorBaseHost(id<3> Offset, range<3> AccessRange, range<3> MemoryRange,
[  541]                    access::mode AccessMode, void *SYCLMemObject, int Dims,
[  542]                    int ElemSize, int OffsetInBytes = 0,
[  543]                    bool IsSubBuffer = false,
[  544]                    const property_list &PropertyList = {});
[  545]   // TODO: the following function to be removed during next ABI break window
[  546]   AccessorBaseHost(id<3> Offset, range<3> AccessRange, range<3> MemoryRange,
[  547]                    access::mode AccessMode, void *SYCLMemObject, int Dims,
[  548]                    int ElemSize, bool IsPlaceH, int OffsetInBytes = 0,
[  549]                    bool IsSubBuffer = false,
[  550]                    const property_list &PropertyList = {});
[  551] 
[  552]   AccessorBaseHost(id<3> Offset, range<3> AccessRange, range<3> MemoryRange,
[  553]                    access::mode AccessMode, void *SYCLMemObject, int Dims,
[  554]                    int ElemSize, size_t OffsetInBytes = 0,
[  555]                    bool IsSubBuffer = false,
[  556]                    const property_list &PropertyList = {});
[  557] 
[  558]   AccessorBaseHost(id<3> Offset, range<3> AccessRange, range<3> MemoryRange,
[  559]                    access::mode AccessMode, void *SYCLMemObject, int Dims,
[  560]                    int ElemSize, bool IsPlaceH, size_t OffsetInBytes = 0,
[  561]                    bool IsSubBuffer = false,
[  562]                    const property_list &PropertyList = {});
[  563] 
[  564] public:
[  565]   id<3> &getOffset();
[  566]   range<3> &getAccessRange();
[  567]   range<3> &getMemoryRange();
[  568]   void *getPtr() noexcept;
[  569]   unsigned int getElemSize() const;
[  570] 
[  571]   const id<3> &getOffset() const;
[  572]   const range<3> &getAccessRange() const;
[  573]   const range<3> &getMemoryRange() const;
[  574]   void *getPtr() const noexcept;
[  575]   bool isPlaceholder() const;
[  576]   bool isMemoryObjectUsedByGraph() const;
[  577] 
[  578]   detail::AccHostDataT &getAccData();
[  579] 
[  580]   const property_list &getPropList() const;
[  581] 
[  582]   void *getMemoryObject() const;
[  583] 
[  584]   template <class Obj>
[  585]   friend decltype(Obj::impl) getSyclObjImpl(const Obj &SyclObject);
[  586] 
[  587]   template <class T>
[  588]   friend T detail::createSyclObjFromImpl(decltype(T::impl) ImplObj);
[  589] 
[  590]   template <typename, int, access::mode, access::target, access::placeholder,
[  591]             typename>
[  592]   friend class accessor;
[  593] 
[  594]   AccessorImplPtr impl;
[  595] 
[  596] private:
[  597]   friend class sycl::ext::intel::esimd::detail::AccessorPrivateProxy;
[  598] };
[  599] 
[  600] class LocalAccessorImplHost;
[  601] using LocalAccessorImplPtr = std::shared_ptr<LocalAccessorImplHost>;
[  602] 
[  603] class __SYCL_EXPORT LocalAccessorBaseHost {
[  604] protected:
[  605]   LocalAccessorBaseHost(const LocalAccessorImplPtr &Impl) : impl{Impl} {}
[  606] 
[  607] public:
[  608]   LocalAccessorBaseHost(sycl::range<3> Size, int Dims, int ElemSize,
[  609]                         const property_list &PropertyList = {});
[  610]   sycl::range<3> &getSize();
[  611]   const sycl::range<3> &getSize() const;
[  612]   void *getPtr();
[  613]   void *getPtr() const;
[  614]   int getNumOfDims();
[  615]   int getElementSize();
[  616]   const property_list &getPropList() const;
[  617] 
[  618] protected:
[  619]   template <class Obj>
[  620]   friend decltype(Obj::impl) detail::getSyclObjImpl(const Obj &SyclObject);
[  621] 
[  622]   template <class T>
[  623]   friend T detail::createSyclObjFromImpl(decltype(T::impl) ImplObj);
[  624] 
[  625]   LocalAccessorImplPtr impl;
[  626] };
[  627] 
[  628] class UnsampledImageAccessorImplHost;
[  629] class SampledImageAccessorImplHost;
[  630] using UnsampledImageAccessorImplPtr =
[  631]     std::shared_ptr<UnsampledImageAccessorImplHost>;
[  632] using SampledImageAccessorImplPtr =
[  633]     std::shared_ptr<SampledImageAccessorImplHost>;
[  634] 
[  635] void __SYCL_EXPORT
[  636] addHostUnsampledImageAccessorAndWait(UnsampledImageAccessorImplHost *Req);
[  637] void __SYCL_EXPORT
[  638] addHostSampledImageAccessorAndWait(SampledImageAccessorImplHost *Req);
[  639] 
[  640] class __SYCL_EXPORT UnsampledImageAccessorBaseHost {
[  641] protected:
[  642]   UnsampledImageAccessorBaseHost(const UnsampledImageAccessorImplPtr &Impl)
[  643]       : impl{Impl} {}
[  644] 
[  645] public:
[  646]   UnsampledImageAccessorBaseHost(sycl::range<3> Size, access_mode AccessMode,
[  647]                                  void *SYCLMemObject, int Dims, int ElemSize,
[  648]                                  id<3> Pitch, image_channel_type ChannelType,
[  649]                                  image_channel_order ChannelOrder,
[  650]                                  const property_list &PropertyList = {});
[  651]   const sycl::range<3> &getSize() const;
[  652]   void *getMemoryObject() const;
[  653]   detail::AccHostDataT &getAccData();
[  654]   void *getPtr();
[  655]   void *getPtr() const;
[  656]   int getNumOfDims() const;
[  657]   int getElementSize() const;
[  658]   id<3> getPitch() const;
[  659]   image_channel_type getChannelType() const;
[  660]   image_channel_order getChannelOrder() const;
[  661]   const property_list &getPropList() const;
[  662] 
[  663] protected:
[  664]   template <class Obj>
[  665]   friend decltype(Obj::impl) detail::getSyclObjImpl(const Obj &SyclObject);
[  666] 
[  667]   template <class T>
[  668]   friend T detail::createSyclObjFromImpl(decltype(T::impl) ImplObj);
[  669] 
[  670]   UnsampledImageAccessorImplPtr impl;
[  671] 
[  672]   // The function references helper methods required by GDB pretty-printers
[  673]   void GDBMethodsAnchor() {
[  674] #ifndef NDEBUG
[  675]     const auto *this_const = this;
[  676]     (void)getSize();
[  677]     (void)this_const->getSize();
[  678]     (void)getPtr();
[  679]     (void)this_const->getPtr();
[  680] #endif
[  681]   }
[  682] 
[  683] #ifndef __SYCL_DEVICE_ONLY__
[  684]   // Reads a pixel of the underlying image at the specified coordinate. It is
[  685]   // the responsibility of the caller to ensure that the coordinate type is
[  686]   // valid.
[  687]   template <typename DataT, typename CoordT>
[  688]   DataT read(const CoordT &Coords) const noexcept {
[  689]     image_sampler Smpl{addressing_mode::none,
[  690]                        coordinate_normalization_mode::unnormalized,
[  691]                        filtering_mode::nearest};
[  692]     return imageReadSamplerHostImpl<CoordT, DataT>(
[  693]         Coords, Smpl, getSize(), getPitch(), getChannelType(),
[  694]         getChannelOrder(), getPtr(), getElementSize());
[  695]   }
[  696] 
[  697]   // Writes to a pixel of the underlying image at the specified coordinate. It
[  698]   // is the responsibility of the caller to ensure that the coordinate type is
[  699]   // valid.
[  700]   template <typename DataT, typename CoordT>
[  701]   void write(const CoordT &Coords, const DataT &Color) const {
[  702]     imageWriteHostImpl(Coords, Color, getPitch(), getElementSize(),
[  703]                        getChannelType(), getChannelOrder(), getPtr());
[  704]   }
[  705] #endif
[  706] };
[  707] 
[  708] class __SYCL_EXPORT SampledImageAccessorBaseHost {
[  709] protected:
[  710]   SampledImageAccessorBaseHost(const SampledImageAccessorImplPtr &Impl)
[  711]       : impl{Impl} {}
[  712] 
[  713] public:
[  714]   SampledImageAccessorBaseHost(sycl::range<3> Size, void *SYCLMemObject,
[  715]                                int Dims, int ElemSize, id<3> Pitch,
[  716]                                image_channel_type ChannelType,
[  717]                                image_channel_order ChannelOrder,
[  718]                                image_sampler Sampler,
[  719]                                const property_list &PropertyList = {});
[  720]   const sycl::range<3> &getSize() const;
[  721]   void *getMemoryObject() const;
[  722]   detail::AccHostDataT &getAccData();
[  723]   void *getPtr();
[  724]   void *getPtr() const;
[  725]   int getNumOfDims() const;
[  726]   int getElementSize() const;
[  727]   id<3> getPitch() const;
[  728]   image_channel_type getChannelType() const;
[  729]   image_channel_order getChannelOrder() const;
[  730]   image_sampler getSampler() const;
[  731]   const property_list &getPropList() const;
[  732] 
[  733] protected:
[  734]   template <class Obj>
[  735]   friend decltype(Obj::impl) detail::getSyclObjImpl(const Obj &SyclObject);
[  736] 
[  737]   template <class T>
[  738]   friend T detail::createSyclObjFromImpl(decltype(T::impl) ImplObj);
[  739] 
[  740]   SampledImageAccessorImplPtr impl;
[  741] 
[  742]   // The function references helper methods required by GDB pretty-printers
[  743]   void GDBMethodsAnchor() {
[  744] #ifndef NDEBUG
[  745]     const auto *this_const = this;
[  746]     (void)getSize();
[  747]     (void)this_const->getSize();
[  748]     (void)getPtr();
[  749]     (void)this_const->getPtr();
[  750] #endif
[  751]   }
[  752] 
[  753] #ifndef __SYCL_DEVICE_ONLY__
[  754]   // Reads a pixel of the underlying image at the specified coordinate. It is
[  755]   // the responsibility of the caller to ensure that the coordinate type is
[  756]   // valid.
[  757]   template <typename DataT, typename CoordT>
[  758]   DataT read(const CoordT &Coords) const {
[  759]     return imageReadSamplerHostImpl<CoordT, DataT>(
[  760]         Coords, getSampler(), getSize(), getPitch(), getChannelType(),
[  761]         getChannelOrder(), getPtr(), getElementSize());
[  762]   }
[  763] #endif
[  764] };
[  765] 
[  766] template <int Dim, typename T> struct IsValidCoordDataT;
[  767] template <typename T> struct IsValidCoordDataT<1, T> {
[  768]   constexpr static bool value = detail::is_contained<
[  769]       T, detail::type_list<opencl::cl_int, opencl::cl_float>>::type::value;
[  770] };
[  771] template <typename T> struct IsValidCoordDataT<2, T> {
[  772]   constexpr static bool value = detail::is_contained<
[  773]       T, detail::type_list<vec<opencl::cl_int, 2>,
[  774]                            vec<opencl::cl_float, 2>>>::type::value;
[  775] };
[  776] template <typename T> struct IsValidCoordDataT<3, T> {
[  777]   constexpr static bool value = detail::is_contained<
[  778]       T, detail::type_list<vec<opencl::cl_int, 4>,
[  779]                            vec<opencl::cl_float, 4>>>::type::value;
[  780] };
[  781] 
[  782] template <int Dim, typename T> struct IsValidUnsampledCoord2020DataT;
[  783] template <typename T> struct IsValidUnsampledCoord2020DataT<1, T> {
[  784]   constexpr static bool value = std::is_same_v<T, int>;
[  785] };
[  786] template <typename T> struct IsValidUnsampledCoord2020DataT<2, T> {
[  787]   constexpr static bool value = std::is_same_v<T, int2>;
[  788] };
[  789] template <typename T> struct IsValidUnsampledCoord2020DataT<3, T> {
[  790]   constexpr static bool value = std::is_same_v<T, int4>;
[  791] };
[  792] 
[  793] template <int Dim, typename T> struct IsValidSampledCoord2020DataT;
[  794] template <typename T> struct IsValidSampledCoord2020DataT<1, T> {
[  795]   constexpr static bool value = std::is_same_v<T, float>;
[  796] };
[  797] template <typename T> struct IsValidSampledCoord2020DataT<2, T> {
[  798]   constexpr static bool value = std::is_same_v<T, float2>;
[  799] };
[  800] template <typename T> struct IsValidSampledCoord2020DataT<3, T> {
[  801]   constexpr static bool value = std::is_same_v<T, float4>;
[  802] };
[  803] 
[  804] template <typename DataT, int Dimensions, access::mode AccessMode,
[  805]           access::placeholder IsPlaceholder>
[  806] class __image_array_slice__;
[  807] 
[  808] // Image accessor
[  809] template <typename DataT, int Dimensions, access::mode AccessMode,
[  810]           access::target AccessTarget, access::placeholder IsPlaceholder>
[  811] class image_accessor
[  812] #ifndef __SYCL_DEVICE_ONLY__
[  813]     : public detail::AccessorBaseHost {
[  814]   size_t MImageCount;
[  815]   image_channel_order MImgChannelOrder;
[  816]   image_channel_type MImgChannelType;
[  817] #else
[  818] {
[  819] 
[  820]   using OCLImageTy = typename detail::opencl_image_type<Dimensions, AccessMode,
[  821]                                                         AccessTarget>::type;
[  822]   OCLImageTy MImageObj;
[  823]   char MPadding[sizeof(detail::AccessorBaseHost) +
[  824]                 sizeof(size_t /*MImageCount*/) + sizeof(image_channel_order) +
[  825]                 sizeof(image_channel_type) - sizeof(OCLImageTy)];
[  826] 
[  827] protected:
[  828]   void imageAccessorInit(OCLImageTy Image) { MImageObj = Image; }
[  829] 
[  830] private:
[  831] #endif
[  832]   template <typename T1, int T2, access::mode T3, access::placeholder T4>
[  833]   friend class __image_array_slice__;
[  834] 
[  835]   constexpr static bool IsHostImageAcc =
[  836]       (AccessTarget == access::target::host_image);
[  837] 
[  838]   constexpr static bool IsImageAcc = (AccessTarget == access::target::image);
[  839] 
[  840]   constexpr static bool IsImageArrayAcc =
[  841]       (AccessTarget == access::target::image_array);
[  842] 
[  843]   constexpr static bool IsImageAccessWriteOnly =
[  844]       (AccessMode == access::mode::write ||
[  845]        AccessMode == access::mode::discard_write);
[  846] 
[  847]   constexpr static bool IsImageAccessAnyWrite =
[  848]       (IsImageAccessWriteOnly || AccessMode == access::mode::read_write);
[  849] 
[  850]   constexpr static bool IsImageAccessReadOnly =
[  851]       (AccessMode == access::mode::read);
[  852] 
[  853]   constexpr static bool IsImageAccessAnyRead =
[  854]       (IsImageAccessReadOnly || AccessMode == access::mode::read_write);
[  855] 
[  856]   static_assert(std::is_same_v<DataT, vec<opencl::cl_int, 4>> ||
[  857]                     std::is_same_v<DataT, vec<opencl::cl_uint, 4>> ||
[  858]                     std::is_same_v<DataT, vec<opencl::cl_float, 4>> ||
[  859]                     std::is_same_v<DataT, vec<opencl::cl_half, 4>>,
[  860]                 "The data type of an image accessor must be only cl_int4, "
[  861]                 "cl_uint4, cl_float4 or cl_half4 from SYCL namespace");
[  862] 
[  863]   static_assert(IsImageAcc || IsHostImageAcc || IsImageArrayAcc,
[  864]                 "Expected image type");
[  865] 
[  866]   static_assert(IsPlaceholder == access::placeholder::false_t,
[  867]                 "Expected false as Placeholder value for image accessor.");
[  868] 
[  869]   static_assert(
[  870]       ((IsImageAcc || IsImageArrayAcc) &&
[  871]        (IsImageAccessWriteOnly || IsImageAccessReadOnly)) ||
[  872]           (IsHostImageAcc && (IsImageAccessAnyWrite || IsImageAccessAnyRead)),
[  873]       "Access modes can be only read/write/discard_write for image/image_array "
[  874]       "target accessor, or they can be only "
[  875]       "read/write/discard_write/read_write for host_image target accessor.");
[  876] 
[  877]   static_assert(Dimensions > 0 && Dimensions <= 3,
[  878]                 "Dimensions can be 1/2/3 for image accessor.");
[  879] 
[  880] #ifdef __SYCL_DEVICE_ONLY__
[  881] 
[  882]   sycl::vec<int, Dimensions> getRangeInternal() const {
[  883]     return __invoke_ImageQuerySize<sycl::vec<int, Dimensions>, OCLImageTy>(
[  884]         MImageObj);
[  885]   }
[  886] 
[  887]   size_t getElementSize() const {
[  888]     int ChannelType = __invoke_ImageQueryFormat<int, OCLImageTy>(MImageObj);
[  889]     int ChannelOrder = __invoke_ImageQueryOrder<int, OCLImageTy>(MImageObj);
[  890]     int ElementSize = getSPIRVElementSize(ChannelType, ChannelOrder);
[  891]     return ElementSize;
[  892]   }
[  893] 
[  894] #else
[  895] 
[  896]   sycl::vec<int, Dimensions> getRangeInternal() const {
[  897]     // TODO: Implement for host.
[  898]     throw sycl::exception(
[  899]         make_error_code(errc::feature_not_supported),
[  900]         "image::getRangeInternal() is not implemented for host");
[  901]     return sycl::vec<int, Dimensions>{1};
[  902]   }
[  903] 
[  904] #endif
[  905] 
[  906] #ifndef __SYCL_DEVICE_ONLY__
[  907] protected:
[  908]   image_accessor(const AccessorImplPtr &Impl) : AccessorBaseHost{Impl} {}
[  909] #endif // __SYCL_DEVICE_ONLY__
[  910] 
[  911] private:
[  912]   friend class sycl::ext::intel::esimd::detail::AccessorPrivateProxy;
[  913] 
[  914] #ifdef __SYCL_DEVICE_ONLY__
[  915]   const OCLImageTy getNativeImageObj() const { return MImageObj; }
[  916] #endif // __SYCL_DEVICE_ONLY__
[  917] 
[  918] public:
[  919]   using value_type = DataT;
[  920]   using reference = DataT &;
[  921]   using const_reference = const DataT &;
[  922] 
[  923]   // image_accessor Constructors.
[  924] 
[  925] #ifdef __SYCL_DEVICE_ONLY__
[  926]   // Default constructor for objects later initialized with __init member.
[  927]   image_accessor() {}
[  928] #endif
[  929] 
[  930]   // Available only when: accessTarget == access::target::host_image
[  931]   // template <typename AllocatorT>
[  932]   // accessor(image<dimensions, AllocatorT> &imageRef);
[  933]   template <
[  934]       typename AllocatorT, int Dims = Dimensions,
[  935]       typename = std::enable_if_t<(Dims > 0 && Dims <= 3) && IsHostImageAcc>>
[  936]   image_accessor(image<Dims, AllocatorT> &ImageRef, int ImageElementSize)
[  937] #ifdef __SYCL_DEVICE_ONLY__
[  938]   {
[  939]     (void)ImageRef;
[  940]     (void)ImageElementSize;
[  941]     // No implementation needed for device. The constructor is only called by
[  942]     // host.
[  943]   }
[  944] #else
[  945]       : AccessorBaseHost({ImageRef.getRowPitch(), ImageRef.getSlicePitch(), 0},
[  946]                          detail::convertToArrayOfN<3, 1>(ImageRef.get_range()),
[  947]                          detail::convertToArrayOfN<3, 1>(ImageRef.get_range()),
[  948]                          AccessMode, detail::getSyclObjImpl(ImageRef).get(),
[  949]                          Dimensions, ImageElementSize, size_t(0)),
[  950]         MImageCount(ImageRef.size()),
[  951]         MImgChannelOrder(ImageRef.getChannelOrder()),
[  952]         MImgChannelType(ImageRef.getChannelType()) {
[  953]     addHostAccessorAndWait(AccessorBaseHost::impl.get());
[  954]   }
[  955] #endif
[  956] 
[  957]   // Available only when: accessTarget == access::target::image
[  958]   // template <typename AllocatorT>
[  959]   // accessor(image<dimensions, AllocatorT> &imageRef,
[  960]   //          handler &commandGroupHandlerRef);
[  961]   template <typename AllocatorT, int Dims = Dimensions,
[  962]             typename = std::enable_if_t<(Dims > 0 && Dims <= 3) && IsImageAcc>>
[  963]   image_accessor(image<Dims, AllocatorT> &ImageRef,
[  964]                  handler &CommandGroupHandlerRef, int ImageElementSize)
[  965] #ifdef __SYCL_DEVICE_ONLY__
[  966]   {
[  967]     (void)ImageRef;
[  968]     (void)CommandGroupHandlerRef;
[  969]     (void)ImageElementSize;
[  970]     // No implementation needed for device. The constructor is only called by
[  971]     // host.
[  972]   }
[  973] #else
[  974]       : AccessorBaseHost({ImageRef.getRowPitch(), ImageRef.getSlicePitch(), 0},
[  975]                          detail::convertToArrayOfN<3, 1>(ImageRef.get_range()),
[  976]                          detail::convertToArrayOfN<3, 1>(ImageRef.get_range()),
[  977]                          AccessMode, detail::getSyclObjImpl(ImageRef).get(),
[  978]                          Dimensions, ImageElementSize, size_t(0)),
[  979]         MImageCount(ImageRef.size()),
[  980]         MImgChannelOrder(ImageRef.getChannelOrder()),
[  981]         MImgChannelType(ImageRef.getChannelType()) {
[  982] 
[  983]     device Device = getDeviceFromHandler(CommandGroupHandlerRef);
[  984]     if (!Device.has(aspect::ext_intel_legacy_image))
[  985]       throw feature_not_supported(
[  986]           "SYCL 1.2.1 images are not supported by this device.",
[  987]           PI_ERROR_INVALID_OPERATION);
[  988]   }
[  989] #endif
[  990] 
[  991]   /* -- common interface members -- */
[  992] 
[  993]   // operator == and != need to be defined only for host application as per the
[  994]   // SYCL spec 1.2.1
[  995] #ifndef __SYCL_DEVICE_ONLY__
[  996]   bool operator==(const image_accessor &Rhs) const { return Rhs.impl == impl; }
[  997] #else
[  998]   // The operator with __SYCL_DEVICE_ONLY__ need to be declared for compilation
[  999]   // of host application with device compiler.
[ 1000]   // Usage of this operator inside the kernel code will give a runtime failure.
[ 1001]   bool operator==(const image_accessor &Rhs) const;
[ 1002] #endif
[ 1003] 
[ 1004]   bool operator!=(const image_accessor &Rhs) const { return !(Rhs == *this); }
[ 1005] 
[ 1006]   // get_count() method : Returns the number of elements of the SYCL image this
[ 1007]   // SYCL accessor is accessing.
[ 1008]   //
[ 1009]   // get_range() method :  Returns a range object which represents the number of
[ 1010]   // elements of dataT per dimension that this accessor may access.
[ 1011]   // The range object returned must equal to the range of the image this
[ 1012]   // accessor is associated with.
[ 1013] 
[ 1014] #ifdef __SYCL_DEVICE_ONLY__
[ 1015] 
[ 1016]   __SYCL2020_DEPRECATED("get_count() is deprecated, please use size() instead")
[ 1017]   size_t get_count() const { return size(); }
[ 1018]   size_t size() const noexcept { return get_range<Dimensions>().size(); }
[ 1019] 
[ 1020]   template <int Dims = Dimensions, typename = std::enable_if_t<Dims == 1>>
[ 1021]   range<1> get_range() const {
[ 1022]     int Range = getRangeInternal();
[ 1023]     return range<1>(Range);
[ 1024]   }
[ 1025]   template <int Dims = Dimensions, typename = std::enable_if_t<Dims == 2>>
[ 1026]   range<2> get_range() const {
[ 1027]     int2 Range = getRangeInternal();
[ 1028]     return range<2>(Range[0], Range[1]);
[ 1029]   }
[ 1030]   template <int Dims = Dimensions, typename = std::enable_if_t<Dims == 3>>
[ 1031]   range<3> get_range() const {
[ 1032]     int3 Range = getRangeInternal();
[ 1033]     return range<3>(Range[0], Range[1], Range[2]);
[ 1034]   }
[ 1035] 
[ 1036] #else
[ 1037]   __SYCL2020_DEPRECATED("get_count() is deprecated, please use size() instead")
[ 1038]   size_t get_count() const { return size(); };
[ 1039]   size_t size() const noexcept { return MImageCount; };
[ 1040] 
[ 1041]   template <int Dims = Dimensions, typename = std::enable_if_t<(Dims > 0)>>
[ 1042]   range<Dims> get_range() const {
[ 1043]     return detail::convertToArrayOfN<Dims, 1>(getAccessRange());
[ 1044]   }
[ 1045] 
[ 1046] #endif
[ 1047] 
[ 1048]   // Available only when:
[ 1049]   // (accessTarget == access::target::image && accessMode == access::mode::read)
[ 1050]   // || (accessTarget == access::target::host_image && ( accessMode ==
[ 1051]   // access::mode::read || accessMode == access::mode::read_write))
[ 1052]   template <typename CoordT, int Dims = Dimensions,
[ 1053]             typename = std::enable_if_t<
[ 1054]                 (Dims > 0) && (IsValidCoordDataT<Dims, CoordT>::value) &&
[ 1055]                 (detail::is_genint_v<CoordT>)&&(
[ 1056]                     (IsImageAcc && IsImageAccessReadOnly) ||
[ 1057]                     (IsHostImageAcc && IsImageAccessAnyRead))>>
[ 1058]   DataT read(const CoordT &Coords) const {
[ 1059] #ifdef __SYCL_DEVICE_ONLY__
[ 1060]     return __invoke__ImageRead<DataT, OCLImageTy, CoordT>(MImageObj, Coords);
[ 1061] #else
[ 1062]     sampler Smpl(coordinate_normalization_mode::unnormalized,
[ 1063]                  addressing_mode::none, filtering_mode::nearest);
[ 1064]     return read<CoordT, Dims>(Coords, Smpl);
[ 1065] #endif
[ 1066]   }
[ 1067] 
[ 1068]   // Available only when:
[ 1069]   // (accessTarget == access::target::image && accessMode == access::mode::read)
[ 1070]   // || (accessTarget == access::target::host_image && ( accessMode ==
[ 1071]   // access::mode::read || accessMode == access::mode::read_write))
[ 1072]   template <typename CoordT, int Dims = Dimensions,
[ 1073]             typename = std::enable_if_t<
[ 1074]                 (Dims > 0) && (IsValidCoordDataT<Dims, CoordT>::value) &&
[ 1075]                 ((IsImageAcc && IsImageAccessReadOnly) ||
[ 1076]                  (IsHostImageAcc && IsImageAccessAnyRead))>>
[ 1077]   DataT read(const CoordT &Coords, const sampler &Smpl) const {
[ 1078] #ifdef __SYCL_DEVICE_ONLY__
[ 1079]     return __invoke__ImageReadSampler<DataT, OCLImageTy, CoordT>(
[ 1080]         MImageObj, Coords, Smpl.impl.m_Sampler);
[ 1081] #else
[ 1082]     return imageReadSamplerHostImpl<CoordT, DataT>(
[ 1083]         Coords, Smpl, getAccessRange() /*Image Range*/,
[ 1084]         getOffset() /*Image Pitch*/, MImgChannelType, MImgChannelOrder,
[ 1085]         AccessorBaseHost::getPtr() /*ptr to image*/,
[ 1086]         AccessorBaseHost::getElemSize());
[ 1087] #endif
[ 1088]   }
[ 1089] 
[ 1090]   // Available only when:
[ 1091]   // (accessTarget == access::target::image && (accessMode ==
[ 1092]   // access::mode::write || accessMode == access::mode::discard_write)) ||
[ 1093]   // (accessTarget == access::target::host_image && (accessMode ==
[ 1094]   // access::mode::write || accessMode == access::mode::discard_write ||
[ 1095]   // accessMode == access::mode::read_write))
[ 1096]   template <
[ 1097]       typename CoordT, int Dims = Dimensions,
[ 1098]       typename = std::enable_if_t<(Dims > 0) &&
[ 1099]                                   (detail::is_genint_v<CoordT>)&&(
[ 1100]                                       IsValidCoordDataT<Dims, CoordT>::value) &&
[ 1101]                                   ((IsImageAcc && IsImageAccessWriteOnly) ||
[ 1102]                                    (IsHostImageAcc && IsImageAccessAnyWrite))>>
[ 1103]   void write(const CoordT &Coords, const DataT &Color) const {
[ 1104] #ifdef __SYCL_DEVICE_ONLY__
[ 1105]     __invoke__ImageWrite<OCLImageTy, CoordT, DataT>(MImageObj, Coords, Color);
[ 1106] #else
[ 1107]     imageWriteHostImpl(Coords, Color, getOffset() /*ImagePitch*/,
[ 1108]                        AccessorBaseHost::getElemSize(), MImgChannelType,
[ 1109]                        MImgChannelOrder,
[ 1110]                        AccessorBaseHost::getPtr() /*Ptr to Image*/);
[ 1111] #endif
[ 1112]   }
[ 1113] };
[ 1114] 
[ 1115] template <typename DataT, int Dimensions, access::mode AccessMode,
[ 1116]           access::placeholder IsPlaceholder>
[ 1117] class __image_array_slice__ {
[ 1118] 
[ 1119]   static_assert(Dimensions < 3,
[ 1120]                 "Image slice cannot have more then 2 dimensions");
[ 1121] 
[ 1122]   constexpr static int AdjustedDims = (Dimensions == 2) ? 4 : Dimensions + 1;
[ 1123] 
[ 1124]   template <typename CoordT,
[ 1125]             typename CoordElemType =
[ 1126]                 typename detail::TryToGetElementType<CoordT>::type>
[ 1127]   sycl::vec<CoordElemType, AdjustedDims>
[ 1128]   getAdjustedCoords(const CoordT &Coords) const {
[ 1129]     CoordElemType LastCoord = 0;
[ 1130] 
[ 1131]     if (std::is_same<float, CoordElemType>::value) {
[ 1132]       sycl::vec<int, Dimensions + 1> Size = MBaseAcc.getRangeInternal();
[ 1133]       LastCoord =
[ 1134]           MIdx / static_cast<float>(Size.template swizzle<Dimensions>());
[ 1135]     } else {
[ 1136]       LastCoord = MIdx;
[ 1137]     }
[ 1138] 
[ 1139]     sycl::vec<CoordElemType, Dimensions> LeftoverCoords{LastCoord};
[ 1140]     sycl::vec<CoordElemType, AdjustedDims> AdjustedCoords{Coords,
[ 1141]                                                           LeftoverCoords};
[ 1142]     return AdjustedCoords;
[ 1143]   }
[ 1144] 
[ 1145] public:
[ 1146]   __image_array_slice__(
[ 1147]       accessor<DataT, Dimensions, AccessMode, access::target::image_array,
[ 1148]                IsPlaceholder, ext::oneapi::accessor_property_list<>>
[ 1149]           BaseAcc,
[ 1150]       size_t Idx)
[ 1151]       : MBaseAcc(BaseAcc), MIdx(Idx) {}
[ 1152] 
[ 1153]   template <typename CoordT, int Dims = Dimensions,
[ 1154]             typename = std::enable_if_t<
[ 1155]                 (Dims > 0) && (IsValidCoordDataT<Dims, CoordT>::value)>>
[ 1156]   DataT read(const CoordT &Coords) const {
[ 1157]     return MBaseAcc.read(getAdjustedCoords(Coords));
[ 1158]   }
[ 1159] 
[ 1160]   template <typename CoordT, int Dims = Dimensions,
[ 1161]             typename = std::enable_if_t<(Dims > 0) &&
[ 1162]                                         IsValidCoordDataT<Dims, CoordT>::value>>
[ 1163]   DataT read(const CoordT &Coords, const sampler &Smpl) const {
[ 1164]     return MBaseAcc.read(getAdjustedCoords(Coords), Smpl);
[ 1165]   }
[ 1166] 
[ 1167]   template <typename CoordT, int Dims = Dimensions,
[ 1168]             typename = std::enable_if_t<(Dims > 0) &&
[ 1169]                                         IsValidCoordDataT<Dims, CoordT>::value>>
[ 1170]   void write(const CoordT &Coords, const DataT &Color) const {
[ 1171]     return MBaseAcc.write(getAdjustedCoords(Coords), Color);
[ 1172]   }
[ 1173] 
[ 1174] #ifdef __SYCL_DEVICE_ONLY__
[ 1175]   __SYCL2020_DEPRECATED("get_count() is deprecated, please use size() instead")
[ 1176]   size_t get_count() const { return size(); }
[ 1177]   size_t size() const noexcept { return get_range<Dimensions>().size(); }
[ 1178] 
[ 1179]   template <int Dims = Dimensions, typename = std::enable_if_t<Dims == 1>>
[ 1180]   range<1> get_range() const {
[ 1181]     int2 Count = MBaseAcc.getRangeInternal();
[ 1182]     return range<1>(Count.x());
[ 1183]   }
[ 1184]   template <int Dims = Dimensions, typename = std::enable_if_t<Dims == 2>>
[ 1185]   range<2> get_range() const {
[ 1186]     int3 Count = MBaseAcc.getRangeInternal();
[ 1187]     return range<2>(Count.x(), Count.y());
[ 1188]   }
[ 1189] 
[ 1190] #else
[ 1191] 
[ 1192]   __SYCL2020_DEPRECATED("get_count() is deprecated, please use size() instead")
[ 1193]   size_t get_count() const { return size(); }
[ 1194]   size_t size() const noexcept {
[ 1195]     return MBaseAcc.MImageCount / MBaseAcc.getAccessRange()[Dimensions];
[ 1196]   }
[ 1197] 
[ 1198]   template <int Dims = Dimensions,
[ 1199]             typename = std::enable_if_t<(Dims == 1 || Dims == 2)>>
[ 1200]   range<Dims> get_range() const {
[ 1201]     return detail::convertToArrayOfN<Dims, 1>(MBaseAcc.getAccessRange());
[ 1202]   }
[ 1203] 
[ 1204] #endif
[ 1205] 
[ 1206] private:
[ 1207]   size_t MIdx;
[ 1208]   accessor<DataT, Dimensions, AccessMode, access::target::image_array,
[ 1209]            IsPlaceholder, ext::oneapi::accessor_property_list<>>
[ 1210]       MBaseAcc;
[ 1211] };
[ 1212] 
[ 1213] } // namespace detail
[ 1214] 
[ 1215] /// Buffer accessor.
[ 1216] ///
[ 1217] /// \sa buffer
[ 1218] ///
[ 1219] /// \ingroup sycl_api_acc
[ 1220] template <typename DataT, int Dimensions, access::mode AccessMode,
[ 1221]           access::target AccessTarget, access::placeholder IsPlaceholder,
[ 1222]           typename PropertyListT>
[ 1223] class __SYCL_EBO __SYCL_SPECIAL_CLASS __SYCL_TYPE(accessor) accessor :
[ 1224] #ifndef __SYCL_DEVICE_ONLY__
[ 1225]     public detail::AccessorBaseHost,
[ 1226] #endif
[ 1227]     public detail::accessor_common<DataT, Dimensions, AccessMode, AccessTarget,
[ 1228]                                    IsPlaceholder, PropertyListT>,
[ 1229]     public detail::OwnerLessBase<
[ 1230]         accessor<DataT, Dimensions, AccessMode, AccessTarget, IsPlaceholder,
[ 1231]                  PropertyListT>> {
[ 1232] protected:
[ 1233]   static_assert((AccessTarget == access::target::global_buffer ||
[ 1234]                  AccessTarget == access::target::constant_buffer ||
[ 1235]                  AccessTarget == access::target::host_buffer ||
[ 1236]                  AccessTarget == access::target::host_task),
[ 1237]                 "Expected buffer type");
[ 1238] 
[ 1239]   static_assert((AccessTarget == access::target::global_buffer ||
[ 1240]                  AccessTarget == access::target::host_buffer ||
[ 1241]                  AccessTarget == access::target::host_task) ||
[ 1242]                     (AccessTarget == access::target::constant_buffer &&
[ 1243]                      AccessMode == access::mode::read),
[ 1244]                 "Access mode can be only read for constant buffers");
[ 1245] 
[ 1246]   static_assert(detail::IsPropertyListT<PropertyListT>::value,
[ 1247]                 "PropertyListT must be accessor_property_list");
[ 1248] 
[ 1249]   using AccessorCommonT =
[ 1250]       detail::accessor_common<DataT, Dimensions, AccessMode, AccessTarget,
[ 1251]                               IsPlaceholder, PropertyListT>;
[ 1252] 
[ 1253]   constexpr static int AdjustedDim = Dimensions == 0 ? 1 : Dimensions;
[ 1254] 
[ 1255]   using AccessorCommonT::AS;
[ 1256]   // Cannot do "using AccessorCommonT::Flag" as it doesn't work with g++ as host
[ 1257]   // compiler, for some reason.
[ 1258]   static constexpr bool IsAccessAnyWrite = AccessorCommonT::IsAccessAnyWrite;
[ 1259]   static constexpr bool IsAccessReadOnly = AccessorCommonT::IsAccessReadOnly;
[ 1260]   static constexpr bool IsConstantBuf = AccessorCommonT::IsConstantBuf;
[ 1261]   static constexpr bool IsGlobalBuf = AccessorCommonT::IsGlobalBuf;
[ 1262]   static constexpr bool IsHostBuf = AccessorCommonT::IsHostBuf;
[ 1263]   static constexpr bool IsPlaceH = AccessorCommonT::IsPlaceH;
[ 1264]   static constexpr bool IsConst = AccessorCommonT::IsConst;
[ 1265]   static constexpr bool IsHostTask = AccessorCommonT::IsHostTask;
[ 1266]   template <int Dims>
[ 1267]   using AccessorSubscript =
[ 1268]       typename AccessorCommonT::template AccessorSubscript<Dims>;
[ 1269] 
[ 1270]   static_assert(
[ 1271]       !IsConst || IsAccessReadOnly,
[ 1272]       "A const qualified DataT is only allowed for a read-only accessor");
[ 1273] 
[ 1274]   using ConcreteASPtrType = typename detail::DecoratedType<
[ 1275]       typename std::conditional_t<IsAccessReadOnly && !IsConstantBuf,
[ 1276]                                   const DataT, DataT>,
[ 1277]       AS>::type *;
[ 1278] 
[ 1279]   using RefType = detail::const_if_const_AS<AS, DataT> &;
[ 1280]   using ConstRefType = const DataT &;
[ 1281]   using PtrType = detail::const_if_const_AS<AS, DataT> *;
[ 1282] 
[ 1283]   template <int Dims = Dimensions> size_t getLinearIndex(id<Dims> Id) const {
[ 1284] 
[ 1285]     size_t Result = 0;
[ 1286]     detail::loop<Dims>([&, this](size_t I) {
[ 1287]       Result = Result * getMemoryRange()[I] + Id[I];
[ 1288]       // We've already adjusted for the accessor's offset in the __init, so
[ 1289]       // don't include it here in case of device.
[ 1290] #ifndef __SYCL_DEVICE_ONLY__
[ 1291]       if constexpr (!(PropertyListT::template has_property<
[ 1292]                         sycl::ext::oneapi::property::no_offset>())) {
[ 1293]         Result += getOffset()[I];
[ 1294]       }
[ 1295] #endif // __SYCL_DEVICE_ONLY__
[ 1296]     });
[ 1297] 
[ 1298]     return Result;
[ 1299]   }
[ 1300] 
[ 1301]   template <typename T, int Dims>
[ 1302]   struct IsSameAsBuffer
[ 1303]       : std::bool_constant<std::is_same_v<T, DataT> && (Dims > 0) &&
[ 1304]                            (Dims == Dimensions)> {};
[ 1305] 
[ 1306]   static access::mode getAdjustedMode(const PropertyListT &PropertyList) {
[ 1307]     access::mode AdjustedMode = AccessMode;
[ 1308] 
[ 1309]     if (PropertyList.template has_property<property::no_init>() ||
[ 1310]         PropertyList.template has_property<property::noinit>()) {
[ 1311]       if (AdjustedMode == access::mode::write) {
[ 1312]         AdjustedMode = access::mode::discard_write;
[ 1313]       } else if (AdjustedMode == access::mode::read_write) {
[ 1314]         AdjustedMode = access::mode::discard_read_write;
[ 1315]       }
[ 1316]     }
[ 1317] 
[ 1318]     return AdjustedMode;
[ 1319]   }
[ 1320] 
[ 1321]   template <typename TagT>
[ 1322]   struct IsValidTag
[ 1323]       : std::disjunction<
[ 1324]             std::is_same<TagT, mode_tag_t<AccessMode>>,
[ 1325]             std::is_same<TagT, mode_target_tag_t<AccessMode, AccessTarget>>> {};
[ 1326] 
[ 1327]   template <typename DataT_, int Dimensions_, access::mode AccessMode_,
[ 1328]             access::target AccessTarget_, access::placeholder IsPlaceholder_,
[ 1329]             typename PropertyListT_>
[ 1330]   friend class accessor;
[ 1331] 
[ 1332] #ifdef __SYCL_DEVICE_ONLY__
[ 1333] 
[ 1334]   id<AdjustedDim> &getOffset() { return impl.Offset; }
[ 1335]   range<AdjustedDim> &getAccessRange() { return impl.AccessRange; }
[ 1336]   range<AdjustedDim> &getMemoryRange() { return impl.MemRange; }
[ 1337] 
[ 1338]   const id<AdjustedDim> &getOffset() const { return impl.Offset; }
[ 1339]   const range<AdjustedDim> &getAccessRange() const { return impl.AccessRange; }
[ 1340]   const range<AdjustedDim> &getMemoryRange() const { return impl.MemRange; }
[ 1341] 
[ 1342]   detail::AccessorImplDevice<AdjustedDim> impl;
[ 1343] 
[ 1344]   union {
[ 1345]     ConcreteASPtrType MData;
[ 1346]   };
[ 1347] 
[ 1348]   void __init(ConcreteASPtrType Ptr, range<AdjustedDim> AccessRange,
[ 1349]               range<AdjustedDim> MemRange, id<AdjustedDim> Offset) {
[ 1350]     MData = Ptr;
[ 1351]     detail::loop<AdjustedDim>([&, this](size_t I) {
[ 1352]       if constexpr (!(PropertyListT::template has_property<
[ 1353]                         sycl::ext::oneapi::property::no_offset>())) {
[ 1354]         getOffset()[I] = Offset[I];
[ 1355]       }
[ 1356]       getAccessRange()[I] = AccessRange[I];
[ 1357]       getMemoryRange()[I] = MemRange[I];
[ 1358]     });
[ 1359] 
[ 1360]     // Adjust for offsets as that part is invariant for all invocations of
[ 1361]     // operator[]. Will have to re-adjust in get_pointer.
[ 1362]     MData += getTotalOffset();
		[0x00108] (W)     shl (1|M0)               r2.0<1>:q     r5.0<0;1,0>:q     3:w               {Compacted,$0.dst}
		[0x00130] (W)     add (1|M0)               r3.0<1>:q     r2.0<0;1,0>:q     r4.4<0;1,0>:q    {Compacted,$1.dst}
		[0x00158] (W)     shl (1|M0)               r5.3<1>:q     r5.1<0;1,0>:q     3:w              
		[0x00168] (W)     shl (1|M0)               r6.0<1>:q     r5.2<0;1,0>:q     3:w               {Compacted}
		[0x00170]         send.ugm (32|M0)         r119     r115    null:0  0x0            0x08400780           {A@3,$3} // wr:4+0, rd:4; load.ugm.d64.a64
		[0x001A0] (W)     add (1|M0)               r41.0<1>:q    r5.3<0;1,0>:q     r4.5<0;1,0>:q    {Compacted,I@3}
		[0x001A8] (W)     add (1|M0)               r41.1<1>:q    r6.0<0;1,0>:q     r4.6<0;1,0>:q    {Compacted,I@3}
[ 1363]   }
[ 1364] 
[ 1365]   // __init variant used by the device compiler for ESIMD kernels.
[ 1366]   // TODO: In ESIMD accessors usage is limited for now - access range, mem
[ 1367]   // range and offset are not supported.
[ 1368]   void __init_esimd(ConcreteASPtrType Ptr) {
[ 1369]     MData = Ptr;
[ 1370] #ifdef __ESIMD_FORCE_STATELESS_MEM
[ 1371]     detail::loop<AdjustedDim>([&, this](size_t I) {
[ 1372]       getOffset()[I] = 0;
[ 1373]       getAccessRange()[I] = 0;
[ 1374]       getMemoryRange()[I] = 0;
[ 1375]     });
[ 1376] #endif
[ 1377]   }
[ 1378] 
[ 1379]   ConcreteASPtrType getQualifiedPtr() const noexcept { return MData; }
[ 1380] 
[ 1381] #ifndef __SYCL_DEVICE_ONLY__
[ 1382]   using AccessorBaseHost::impl;
[ 1383] #endif
[ 1384] 
[ 1385] public:
[ 1386]   // Default constructor for objects later initialized with __init member.
[ 1387]   accessor()
[ 1388]       : impl({}, detail::InitializedVal<AdjustedDim, range>::template get<0>(),
[ 1389]              detail::InitializedVal<AdjustedDim, range>::template get<0>()) {}
[ 1390] 
[ 1391] #else
[ 1392]   accessor(const detail::AccessorImplPtr &Impl)
[ 1393]       : detail::AccessorBaseHost{Impl} {}
[ 1394] 
[ 1395]   void *getPtr() { return AccessorBaseHost::getPtr(); }
[ 1396] 
[ 1397]   const id<3> getOffset() const {
[ 1398]     if constexpr (IsHostBuf)
[ 1399]       return MAccData ? MAccData->MOffset : id<3>();
[ 1400]     else
[ 1401]       return AccessorBaseHost::getOffset();
[ 1402]   }
[ 1403]   const range<3> &getAccessRange() const {
[ 1404]     return AccessorBaseHost::getAccessRange();
[ 1405]   }
[ 1406]   const range<3> getMemoryRange() const {
[ 1407]     if constexpr (IsHostBuf)
[ 1408]       return MAccData ? MAccData->MMemoryRange : range(0, 0, 0);
[ 1409]     else
[ 1410]       return AccessorBaseHost::getMemoryRange();
[ 1411]   }
[ 1412] 
[ 1413]   void *getPtr() const { return AccessorBaseHost::getPtr(); }
[ 1414] 
[ 1415]   void initHostAcc() { MAccData = &getAccData(); }
[ 1416] 
[ 1417]   // The function references helper methods required by GDB pretty-printers
[ 1418]   void GDBMethodsAnchor() {
[ 1419] #ifndef NDEBUG
[ 1420]     const auto *this_const = this;
[ 1421]     (void)getMemoryRange();
[ 1422]     (void)this_const->getMemoryRange();
[ 1423]     (void)getOffset();
[ 1424]     (void)this_const->getOffset();
[ 1425]     (void)getPtr();
[ 1426]     (void)this_const->getPtr();
[ 1427]     (void)getAccessRange();
[ 1428]     (void)this_const->getAccessRange();
[ 1429] #endif
[ 1430]   }
[ 1431] 
[ 1432]   detail::AccHostDataT *MAccData = nullptr;
[ 1433] 
[ 1434]   char padding[sizeof(detail::AccessorImplDevice<AdjustedDim>) +
[ 1435]                sizeof(PtrType) - sizeof(detail::AccessorBaseHost) -
[ 1436]                sizeof(MAccData)];
[ 1437] 
[ 1438]   PtrType getQualifiedPtr() const noexcept {
[ 1439]     if constexpr (IsHostBuf)
[ 1440]       return MAccData ? reinterpret_cast<PtrType>(MAccData->MData) : nullptr;
[ 1441]     else
[ 1442]       return reinterpret_cast<PtrType>(AccessorBaseHost::getPtr());
[ 1443]   }
[ 1444] 
[ 1445] public:
[ 1446]   accessor()
[ 1447]       : AccessorBaseHost(
[ 1448]             /*Offset=*/{0, 0, 0}, /*AccessRange=*/{0, 0, 0},
[ 1449]             /*MemoryRange=*/{0, 0, 0},
[ 1450]             /*AccessMode=*/getAdjustedMode({}),
[ 1451]             /*SYCLMemObject=*/nullptr, /*Dims=*/0, /*ElemSize=*/0,
[ 1452]             /*IsPlaceH=*/false,
[ 1453]             /*OffsetInBytes=*/0, /*IsSubBuffer=*/false, /*PropertyList=*/{}){};
[ 1454] 
[ 1455]   template <typename, int, access_mode> friend class host_accessor;
[ 1456] 
[ 1457] #endif // __SYCL_DEVICE_ONLY__
[ 1458] 
[ 1459] private:
[ 1460]   friend class sycl::stream;
[ 1461]   friend class sycl::ext::intel::esimd::detail::AccessorPrivateProxy;
[ 1462] 
[ 1463]   template <class Obj>
[ 1464]   friend decltype(Obj::impl) detail::getSyclObjImpl(const Obj &SyclObject);
[ 1465] 
[ 1466]   template <class T>
[ 1467]   friend T detail::createSyclObjFromImpl(decltype(T::impl) ImplObj);
[ 1468] 
[ 1469] public:
[ 1470]   // 4.7.6.9.1. Interface for buffer command accessors
[ 1471]   // value_type is defined as const DataT for read_only accessors, DataT
[ 1472]   // otherwise
[ 1473]   using value_type =
[ 1474]       std::conditional_t<AccessMode == access_mode::read, const DataT, DataT>;
[ 1475]   using reference = value_type &;
[ 1476]   using const_reference = const DataT &;
[ 1477] 
[ 1478]   template <access::decorated IsDecorated>
[ 1479]   using accessor_ptr =
[ 1480]       std::conditional_t<AccessTarget == access::target::device,
[ 1481]                          global_ptr<value_type, IsDecorated>, value_type *>;
[ 1482] 
[ 1483]   using iterator = typename detail::accessor_iterator<value_type, AdjustedDim>;
[ 1484]   using const_iterator =
[ 1485]       typename detail::accessor_iterator<const value_type, AdjustedDim>;
[ 1486]   using reverse_iterator = std::reverse_iterator<iterator>;
[ 1487]   using const_reverse_iterator = std::reverse_iterator<const_iterator>;
[ 1488]   using difference_type =
[ 1489]       typename std::iterator_traits<iterator>::difference_type;
[ 1490]   using size_type = std::size_t;
[ 1491] 
[ 1492]   /// If creating a host_accessor this checks to see if the underlying memory
[ 1493]   /// object is currently in use by a command_graph, and throws if it is.
[ 1494]   void throwIfUsedByGraph() const {
[ 1495] #ifndef __SYCL_DEVICE_ONLY__
[ 1496]     if (IsHostBuf && AccessorBaseHost::isMemoryObjectUsedByGraph()) {
[ 1497]       throw sycl::exception(make_error_code(errc::invalid),
[ 1498]                             "Host accessors cannot be created for buffers "
[ 1499]                             "which are currently in use by a command graph.");
[ 1500]     }
[ 1501] #endif
[ 1502]   }
[ 1503] 
[ 1504]   // The list of accessor constructors with their arguments
[ 1505]   // -------+---------+-------+----+-----+--------------
[ 1506]   // Dimensions = 0
[ 1507]   // -------+---------+-------+----+-----+--------------
[ 1508]   // buffer |         |       |    |     | property_list
[ 1509]   // buffer | handler |       |    |     | property_list
[ 1510]   // -------+---------+-------+----+-----+--------------
[ 1511]   // Dimensions >= 1
[ 1512]   // -------+---------+-------+----+-----+--------------
[ 1513]   // buffer |         |       |    |     | property_list
[ 1514]   // buffer |         |       |    | tag | property_list
[ 1515]   // buffer | handler |       |    |     | property_list
[ 1516]   // buffer | handler |       |    | tag | property_list
[ 1517]   // buffer |         | range |    |     | property_list
[ 1518]   // buffer |         | range |    | tag | property_list
[ 1519]   // buffer | handler | range |    |     | property_list
[ 1520]   // buffer | handler | range |    | tag | property_list
[ 1521]   // buffer |         | range | id |     | property_list
[ 1522]   // buffer |         | range | id | tag | property_list
[ 1523]   // buffer | handler | range | id |     | property_list
[ 1524]   // buffer | handler | range | id | tag | property_list
[ 1525]   // -------+---------+-------+----+-----+--------------
[ 1526] 
[ 1527] public:
[ 1528]   // implicit conversion between const / non-const types for read only accessors
[ 1529]   template <typename DataT_,
[ 1530]             typename = std::enable_if_t<
[ 1531]                 IsAccessReadOnly && !std::is_same_v<DataT_, DataT> &&
[ 1532]                 std::is_same_v<std::remove_const_t<DataT_>,
[ 1533]                                std::remove_const_t<DataT>>>>
[ 1534]   accessor(const accessor<DataT_, Dimensions, AccessMode, AccessTarget,
[ 1535]                           IsPlaceholder, PropertyListT> &other)
[ 1536] #ifdef __SYCL_DEVICE_ONLY__
[ 1537]       : impl(other.impl), MData(other.MData) {
[ 1538] #else
[ 1539]       : accessor(other.impl) {
[ 1540] #endif // __SYCL_DEVICE_ONLY__
[ 1541]   }
[ 1542] 
[ 1543]   // implicit conversion from read_write T accessor to read only T (const)
[ 1544]   // accessor
[ 1545]   template <typename DataT_, access::mode AccessMode_,
[ 1546]             typename = std::enable_if_t<
[ 1547]                 (AccessMode_ == access_mode::read_write) && IsAccessReadOnly &&
[ 1548]                 std::is_same_v<std::remove_const_t<DataT_>,
[ 1549]                                std::remove_const_t<DataT>>>>
[ 1550]   accessor(const accessor<DataT_, Dimensions, AccessMode_, AccessTarget,
[ 1551]                           IsPlaceholder, PropertyListT> &other)
[ 1552] #ifdef __SYCL_DEVICE_ONLY__
[ 1553]       : impl(other.impl), MData(other.MData) {
[ 1554] #else
[ 1555]       : accessor(other.impl) {
[ 1556] #endif // __SYCL_DEVICE_ONLY__
[ 1557]   }
[ 1558] 
[ 1559]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1560]             typename std::enable_if_t<
[ 1561]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 1562]                 std::is_same_v<T, DataT> && Dims == 0 &&
[ 1563]                 (IsHostBuf || IsHostTask || (IsGlobalBuf || IsConstantBuf))> * =
[ 1564]                 nullptr>
[ 1565]   accessor(
[ 1566]       buffer<T, 1, AllocatorT> &BufferRef,
[ 1567]       const property_list &PropertyList = {},
[ 1568]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1569] #ifdef __SYCL_DEVICE_ONLY__
[ 1570]       : impl(id<AdjustedDim>(), detail::GetZeroDimAccessRange(BufferRef),
[ 1571]              BufferRef.get_range()) {
[ 1572]     (void)PropertyList;
[ 1573]     (void)CodeLoc;
[ 1574] #else
[ 1575]       : AccessorBaseHost(
[ 1576]             /*Offset=*/{0, 0, 0},
[ 1577]             detail::convertToArrayOfN<3, 1>(
[ 1578]                 detail::GetZeroDimAccessRange(BufferRef)),
[ 1579]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1580]             getAdjustedMode(PropertyList),
[ 1581]             detail::getSyclObjImpl(BufferRef).get(), AdjustedDim, sizeof(DataT),
[ 1582]             IsPlaceH, BufferRef.OffsetInBytes, BufferRef.IsSubBuffer,
[ 1583]             PropertyList) {
[ 1584]     throwIfUsedByGraph();
[ 1585]     preScreenAccessor(PropertyList);
[ 1586]     if (!AccessorBaseHost::isPlaceholder())
[ 1587]       addHostAccessorAndWait(AccessorBaseHost::impl.get());
[ 1588]     initHostAcc();
[ 1589]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 1590]                                     detail::AccessorBaseHost::impl.get(),
[ 1591]                                     AccessTarget, AccessMode, CodeLoc);
[ 1592]     GDBMethodsAnchor();
[ 1593] #endif
[ 1594]   }
[ 1595] 
[ 1596]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1597]             typename... PropTypes,
[ 1598]             typename std::enable_if_t<
[ 1599]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 1600]                 // VS2019 can't compile sycl/test/regression/bit_cast_win.cpp
[ 1601]                 // if std::is_same_v is used here.
[ 1602]                 std::is_same<T, DataT>::value && Dims == 0 &&
[ 1603]                 (IsHostBuf || IsHostTask || (IsGlobalBuf || IsConstantBuf))> * =
[ 1604]                 nullptr>
[ 1605]   accessor(
[ 1606]       buffer<T, 1, AllocatorT> &BufferRef,
[ 1607]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 1608]           {},
[ 1609]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1610] #ifdef __SYCL_DEVICE_ONLY__
[ 1611]       : impl(id<AdjustedDim>(), detail::GetZeroDimAccessRange(BufferRef),
[ 1612]              BufferRef.get_range()) {
[ 1613]     (void)PropertyList;
[ 1614]     (void)CodeLoc;
[ 1615] #else
[ 1616]       : AccessorBaseHost(
[ 1617]             /*Offset=*/{0, 0, 0},
[ 1618]             detail::convertToArrayOfN<3, 1>(
[ 1619]                 detail::GetZeroDimAccessRange(BufferRef)),
[ 1620]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1621]             getAdjustedMode(PropertyList),
[ 1622]             detail::getSyclObjImpl(BufferRef).get(), AdjustedDim, sizeof(DataT),
[ 1623]             IsPlaceH, BufferRef.OffsetInBytes, BufferRef.IsSubBuffer,
[ 1624]             PropertyList) {
[ 1625]     throwIfUsedByGraph();
[ 1626]     preScreenAccessor(PropertyList);
[ 1627]     if (!AccessorBaseHost::isPlaceholder())
[ 1628]       addHostAccessorAndWait(AccessorBaseHost::impl.get());
[ 1629]     initHostAcc();
[ 1630]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 1631]                                     detail::AccessorBaseHost::impl.get(),
[ 1632]                                     AccessTarget, AccessMode, CodeLoc);
[ 1633]     GDBMethodsAnchor();
[ 1634] #endif
[ 1635]   }
[ 1636] 
[ 1637]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1638]             typename = typename std::enable_if_t<
[ 1639]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 1640]                 std::is_same_v<T, DataT> && (Dims == 0) &&
[ 1641]                 (IsGlobalBuf || IsHostBuf || IsConstantBuf || IsHostTask)>>
[ 1642]   accessor(
[ 1643]       buffer<T, 1, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 1644]       const property_list &PropertyList = {},
[ 1645]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1646] #ifdef __SYCL_DEVICE_ONLY__
[ 1647]       : impl(id<AdjustedDim>(), detail::GetZeroDimAccessRange(BufferRef),
[ 1648]              BufferRef.get_range()) {
[ 1649]     (void)CommandGroupHandler;
[ 1650]     (void)PropertyList;
[ 1651]     (void)CodeLoc;
[ 1652]   }
[ 1653] #else
[ 1654]       : AccessorBaseHost(
[ 1655]             /*Offset=*/{0, 0, 0},
[ 1656]             detail::convertToArrayOfN<3, 1>(
[ 1657]                 detail::GetZeroDimAccessRange(BufferRef)),
[ 1658]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1659]             getAdjustedMode(PropertyList),
[ 1660]             detail::getSyclObjImpl(BufferRef).get(), Dimensions, sizeof(DataT),
[ 1661]             BufferRef.OffsetInBytes, BufferRef.IsSubBuffer, PropertyList) {
[ 1662]     throwIfUsedByGraph();
[ 1663]     preScreenAccessor(PropertyList);
[ 1664]     detail::associateWithHandler(CommandGroupHandler, this, AccessTarget);
[ 1665]     initHostAcc();
[ 1666]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 1667]                                     detail::AccessorBaseHost::impl.get(),
[ 1668]                                     AccessTarget, AccessMode, CodeLoc);
[ 1669]     GDBMethodsAnchor();
[ 1670]   }
[ 1671] #endif
[ 1672] 
[ 1673]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1674]             typename... PropTypes,
[ 1675]             typename = typename std::enable_if_t<
[ 1676]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 1677]                 std::is_same_v<T, DataT> && (Dims == 0) &&
[ 1678]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 1679]   accessor(
[ 1680]       buffer<T, 1, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 1681]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 1682]           {},
[ 1683]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1684] #ifdef __SYCL_DEVICE_ONLY__
[ 1685]       : impl(id<AdjustedDim>(), detail::GetZeroDimAccessRange(BufferRef),
[ 1686]              BufferRef.get_range()) {
[ 1687]     (void)CommandGroupHandler;
[ 1688]     (void)PropertyList;
[ 1689]     (void)CodeLoc;
[ 1690]   }
[ 1691] #else
[ 1692]       : AccessorBaseHost(
[ 1693]             /*Offset=*/{0, 0, 0},
[ 1694]             detail::convertToArrayOfN<3, 1>(
[ 1695]                 detail::GetZeroDimAccessRange(BufferRef)),
[ 1696]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1697]             getAdjustedMode(PropertyList),
[ 1698]             detail::getSyclObjImpl(BufferRef).get(), Dimensions, sizeof(DataT),
[ 1699]             BufferRef.OffsetInBytes, BufferRef.IsSubBuffer, PropertyList) {
[ 1700]     throwIfUsedByGraph();
[ 1701]     preScreenAccessor(PropertyList);
[ 1702]     detail::associateWithHandler(CommandGroupHandler, this, AccessTarget);
[ 1703]     initHostAcc();
[ 1704]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 1705]                                     detail::AccessorBaseHost::impl.get(),
[ 1706]                                     AccessTarget, AccessMode, CodeLoc);
[ 1707]     GDBMethodsAnchor();
[ 1708]   }
[ 1709] #endif
[ 1710] 
[ 1711]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1712]             typename = std::enable_if_t<
[ 1713]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 1714]                 IsSameAsBuffer<T, Dims>::value &&
[ 1715]                 (IsHostBuf || IsHostTask || (IsGlobalBuf || IsConstantBuf))>>
[ 1716]   accessor(
[ 1717]       buffer<T, Dims, AllocatorT> &BufferRef,
[ 1718]       const property_list &PropertyList = {},
[ 1719]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1720] #ifdef __SYCL_DEVICE_ONLY__
[ 1721]       : impl(id<Dimensions>(), BufferRef.get_range(), BufferRef.get_range()) {
[ 1722]     (void)PropertyList;
[ 1723]     (void)CodeLoc;
[ 1724]   }
[ 1725] #else
[ 1726]       : AccessorBaseHost(
[ 1727]             /*Offset=*/{0, 0, 0},
[ 1728]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1729]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1730]             getAdjustedMode(PropertyList),
[ 1731]             detail::getSyclObjImpl(BufferRef).get(), Dimensions, sizeof(DataT),
[ 1732]             IsPlaceH, BufferRef.OffsetInBytes, BufferRef.IsSubBuffer,
[ 1733]             PropertyList) {
[ 1734]     throwIfUsedByGraph();
[ 1735]     preScreenAccessor(PropertyList);
[ 1736]     if (!AccessorBaseHost::isPlaceholder())
[ 1737]       addHostAccessorAndWait(AccessorBaseHost::impl.get());
[ 1738]     initHostAcc();
[ 1739]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 1740]                                     detail::AccessorBaseHost::impl.get(),
[ 1741]                                     AccessTarget, AccessMode, CodeLoc);
[ 1742]     GDBMethodsAnchor();
[ 1743]   }
[ 1744] #endif
[ 1745] 
[ 1746]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1747]             typename... PropTypes,
[ 1748]             typename = std::enable_if_t<
[ 1749]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 1750]                 IsSameAsBuffer<T, Dims>::value &&
[ 1751]                 (IsHostBuf || IsHostTask || (IsGlobalBuf || IsConstantBuf))>>
[ 1752]   accessor(
[ 1753]       buffer<T, Dims, AllocatorT> &BufferRef,
[ 1754]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 1755]           {},
[ 1756]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1757] #ifdef __SYCL_DEVICE_ONLY__
[ 1758]       : impl(id<Dimensions>(), BufferRef.get_range(), BufferRef.get_range()) {
[ 1759]     (void)PropertyList;
[ 1760]     (void)CodeLoc;
[ 1761]   }
[ 1762] #else
[ 1763]       : AccessorBaseHost(
[ 1764]             /*Offset=*/{0, 0, 0},
[ 1765]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1766]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1767]             getAdjustedMode(PropertyList),
[ 1768]             detail::getSyclObjImpl(BufferRef).get(), Dimensions, sizeof(DataT),
[ 1769]             IsPlaceH, BufferRef.OffsetInBytes, BufferRef.IsSubBuffer,
[ 1770]             PropertyList) {
[ 1771]     throwIfUsedByGraph();
[ 1772]     preScreenAccessor(PropertyList);
[ 1773]     if (!AccessorBaseHost::isPlaceholder())
[ 1774]       addHostAccessorAndWait(AccessorBaseHost::impl.get());
[ 1775]     initHostAcc();
[ 1776]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 1777]                                     detail::AccessorBaseHost::impl.get(),
[ 1778]                                     AccessTarget, AccessMode, CodeLoc);
[ 1779]     GDBMethodsAnchor();
[ 1780]   }
[ 1781] #endif
[ 1782] 
[ 1783]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1784]             typename TagT,
[ 1785]             typename = std::enable_if_t<
[ 1786]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 1787]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 1788]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 1789]   accessor(
[ 1790]       buffer<T, Dims, AllocatorT> &BufferRef, TagT,
[ 1791]       const property_list &PropertyList = {},
[ 1792]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1793]       : accessor(BufferRef, PropertyList, CodeLoc) {
[ 1794]     adjustAccPropsInBuf(BufferRef);
[ 1795]   }
[ 1796] 
[ 1797]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1798]             typename TagT, typename... PropTypes,
[ 1799]             typename = std::enable_if_t<
[ 1800]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 1801]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 1802]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 1803]   accessor(
[ 1804]       buffer<T, Dims, AllocatorT> &BufferRef, TagT,
[ 1805]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 1806]           {},
[ 1807]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1808]       : accessor(BufferRef, PropertyList, CodeLoc) {
[ 1809]     adjustAccPropsInBuf(BufferRef);
[ 1810]   }
[ 1811] 
[ 1812]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1813]             typename = std::enable_if_t<
[ 1814]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 1815]                 IsSameAsBuffer<T, Dims>::value &&
[ 1816]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 1817]   accessor(
[ 1818]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 1819]       const property_list &PropertyList = {},
[ 1820]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1821] #ifdef __SYCL_DEVICE_ONLY__
[ 1822]       : impl(id<AdjustedDim>(), BufferRef.get_range(), BufferRef.get_range()) {
[ 1823]     (void)CommandGroupHandler;
[ 1824]     (void)PropertyList;
[ 1825]     (void)CodeLoc;
[ 1826]   }
[ 1827] #else
[ 1828]       : AccessorBaseHost(
[ 1829]             /*Offset=*/{0, 0, 0},
[ 1830]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1831]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1832]             getAdjustedMode(PropertyList),
[ 1833]             detail::getSyclObjImpl(BufferRef).get(), Dimensions, sizeof(DataT),
[ 1834]             BufferRef.OffsetInBytes, BufferRef.IsSubBuffer, PropertyList) {
[ 1835]     throwIfUsedByGraph();
[ 1836]     preScreenAccessor(PropertyList);
[ 1837]     detail::associateWithHandler(CommandGroupHandler, this, AccessTarget);
[ 1838]     initHostAcc();
[ 1839]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 1840]                                     detail::AccessorBaseHost::impl.get(),
[ 1841]                                     AccessTarget, AccessMode, CodeLoc);
[ 1842]     GDBMethodsAnchor();
[ 1843]   }
[ 1844] #endif
[ 1845] 
[ 1846]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1847]             typename... PropTypes,
[ 1848]             typename = std::enable_if_t<
[ 1849]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 1850]                 IsSameAsBuffer<T, Dims>::value &&
[ 1851]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 1852]   accessor(
[ 1853]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 1854]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 1855]           {},
[ 1856]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1857] #ifdef __SYCL_DEVICE_ONLY__
[ 1858]       : impl(id<AdjustedDim>(), BufferRef.get_range(), BufferRef.get_range()) {
[ 1859]     (void)CommandGroupHandler;
[ 1860]     (void)PropertyList;
[ 1861]     (void)CodeLoc;
[ 1862]   }
[ 1863] #else
[ 1864]       : AccessorBaseHost(
[ 1865]             /*Offset=*/{0, 0, 0},
[ 1866]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1867]             detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 1868]             getAdjustedMode(PropertyList),
[ 1869]             detail::getSyclObjImpl(BufferRef).get(), Dimensions, sizeof(DataT),
[ 1870]             BufferRef.OffsetInBytes, BufferRef.IsSubBuffer, PropertyList) {
[ 1871]     throwIfUsedByGraph();
[ 1872]     preScreenAccessor(PropertyList);
[ 1873]     initHostAcc();
[ 1874]     detail::associateWithHandler(CommandGroupHandler, this, AccessTarget);
[ 1875]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 1876]                                     detail::AccessorBaseHost::impl.get(),
[ 1877]                                     AccessTarget, AccessMode, CodeLoc);
[ 1878]     GDBMethodsAnchor();
[ 1879]   }
[ 1880] #endif
[ 1881] 
[ 1882]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1883]             typename TagT,
[ 1884]             typename = std::enable_if_t<
[ 1885]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 1886]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 1887]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 1888]   accessor(
[ 1889]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 1890]       TagT, const property_list &PropertyList = {},
[ 1891]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1892]       : accessor(BufferRef, CommandGroupHandler, PropertyList, CodeLoc) {
[ 1893]     adjustAccPropsInBuf(BufferRef);
[ 1894]   }
[ 1895] 
[ 1896]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1897]             typename TagT, typename... PropTypes,
[ 1898]             typename = std::enable_if_t<
[ 1899]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 1900]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 1901]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 1902]   accessor(
[ 1903]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 1904]       TagT,
[ 1905]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 1906]           {},
[ 1907]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1908]       : accessor(BufferRef, CommandGroupHandler, PropertyList, CodeLoc) {
[ 1909]     adjustAccPropsInBuf(BufferRef);
[ 1910]   }
[ 1911] 
[ 1912]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1913]             typename = std::enable_if_t<
[ 1914]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 1915]                 IsSameAsBuffer<T, Dims>::value &&
[ 1916]                 (IsHostBuf || IsHostTask || (IsGlobalBuf || IsConstantBuf))>>
[ 1917]   accessor(
[ 1918]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 1919]       const property_list &PropertyList = {},
[ 1920]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1921]       : accessor(BufferRef, AccessRange, {}, PropertyList, CodeLoc) {}
[ 1922] 
[ 1923]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1924]             typename... PropTypes,
[ 1925]             typename = std::enable_if_t<
[ 1926]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 1927]                 IsSameAsBuffer<T, Dims>::value &&
[ 1928]                 (IsHostBuf || IsHostTask || (IsGlobalBuf || IsConstantBuf))>>
[ 1929]   accessor(
[ 1930]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 1931]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 1932]           {},
[ 1933]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1934]       : accessor(BufferRef, AccessRange, {}, PropertyList, CodeLoc) {}
[ 1935] 
[ 1936]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1937]             typename TagT,
[ 1938]             typename = std::enable_if_t<
[ 1939]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 1940]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 1941]                 (IsGlobalBuf || IsConstantBuf || IsHostTask)>>
[ 1942]   accessor(
[ 1943]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 1944]       TagT, const property_list &PropertyList = {},
[ 1945]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1946]       : accessor(BufferRef, AccessRange, {}, PropertyList, CodeLoc) {
[ 1947]     adjustAccPropsInBuf(BufferRef);
[ 1948]   }
[ 1949] 
[ 1950]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1951]             typename TagT, typename... PropTypes,
[ 1952]             typename = std::enable_if_t<
[ 1953]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 1954]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 1955]                 (IsGlobalBuf || IsConstantBuf || IsHostTask)>>
[ 1956]   accessor(
[ 1957]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 1958]       TagT,
[ 1959]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 1960]           {},
[ 1961]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1962]       : accessor(BufferRef, AccessRange, {}, PropertyList, CodeLoc) {
[ 1963]     adjustAccPropsInBuf(BufferRef);
[ 1964]   }
[ 1965] 
[ 1966]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1967]             typename = std::enable_if_t<
[ 1968]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 1969]                 IsSameAsBuffer<T, Dims>::value &&
[ 1970]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 1971]   accessor(
[ 1972]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 1973]       range<Dimensions> AccessRange, const property_list &PropertyList = {},
[ 1974]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1975]       : accessor(BufferRef, CommandGroupHandler, AccessRange, {}, PropertyList,
[ 1976]                  CodeLoc) {}
[ 1977] 
[ 1978]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1979]             typename... PropTypes,
[ 1980]             typename = std::enable_if_t<
[ 1981]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 1982]                 IsSameAsBuffer<T, Dims>::value &&
[ 1983]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 1984]   accessor(
[ 1985]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 1986]       range<Dimensions> AccessRange,
[ 1987]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 1988]           {},
[ 1989]       const detail::code_location CodeLoc = detail::code_location::current())
[ 1990]       : accessor(BufferRef, CommandGroupHandler, AccessRange, {}, PropertyList,
[ 1991]                  CodeLoc) {}
[ 1992] 
[ 1993]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 1994]             typename TagT,
[ 1995]             typename = std::enable_if_t<
[ 1996]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 1997]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 1998]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 1999]   accessor(
[ 2000]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 2001]       range<Dimensions> AccessRange, TagT,
[ 2002]       const property_list &PropertyList = {},
[ 2003]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2004]       : accessor(BufferRef, CommandGroupHandler, AccessRange, {}, PropertyList,
[ 2005]                  CodeLoc) {
[ 2006]     adjustAccPropsInBuf(BufferRef);
[ 2007]   }
[ 2008] 
[ 2009]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 2010]             typename TagT, typename... PropTypes,
[ 2011]             typename = std::enable_if_t<
[ 2012]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 2013]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 2014]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 2015]   accessor(
[ 2016]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 2017]       range<Dimensions> AccessRange, TagT,
[ 2018]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 2019]           {},
[ 2020]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2021]       : accessor(BufferRef, CommandGroupHandler, AccessRange, {}, PropertyList,
[ 2022]                  CodeLoc) {
[ 2023]     adjustAccPropsInBuf(BufferRef);
[ 2024]   }
[ 2025] 
[ 2026]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 2027]             typename = std::enable_if_t<
[ 2028]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 2029]                 IsSameAsBuffer<T, Dims>::value &&
[ 2030]                 (IsHostBuf || IsHostTask || (IsGlobalBuf || IsConstantBuf))>>
[ 2031]   accessor(
[ 2032]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 2033]       id<Dimensions> AccessOffset, const property_list &PropertyList = {},
[ 2034]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2035] #ifdef __SYCL_DEVICE_ONLY__
[ 2036]       : impl(AccessOffset, AccessRange, BufferRef.get_range()) {
[ 2037]     (void)PropertyList;
[ 2038]     (void)CodeLoc;
[ 2039]   }
[ 2040] #else
[ 2041]       : AccessorBaseHost(detail::convertToArrayOfN<3, 0>(AccessOffset),
[ 2042]                          detail::convertToArrayOfN<3, 1>(AccessRange),
[ 2043]                          detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 2044]                          getAdjustedMode(PropertyList),
[ 2045]                          detail::getSyclObjImpl(BufferRef).get(), Dimensions,
[ 2046]                          sizeof(DataT), IsPlaceH, BufferRef.OffsetInBytes,
[ 2047]                          BufferRef.IsSubBuffer, PropertyList) {
[ 2048]     throwIfUsedByGraph();
[ 2049]     preScreenAccessor(PropertyList);
[ 2050]     if (!AccessorBaseHost::isPlaceholder())
[ 2051]       addHostAccessorAndWait(AccessorBaseHost::impl.get());
[ 2052]     if (BufferRef.isOutOfBounds(AccessOffset, AccessRange,
[ 2053]                                 BufferRef.get_range()))
[ 2054]       throw sycl::invalid_object_error(
[ 2055]           "accessor with requested offset and range would exceed the bounds of "
[ 2056]           "the buffer",
[ 2057]           PI_ERROR_INVALID_VALUE);
[ 2058] 
[ 2059]     initHostAcc();
[ 2060]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 2061]                                     detail::AccessorBaseHost::impl.get(),
[ 2062]                                     AccessTarget, AccessMode, CodeLoc);
[ 2063]     GDBMethodsAnchor();
[ 2064]   }
[ 2065] #endif
[ 2066] 
[ 2067]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 2068]             typename... PropTypes,
[ 2069]             typename = std::enable_if_t<
[ 2070]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 2071]                 IsSameAsBuffer<T, Dims>::value &&
[ 2072]                 (IsHostBuf || IsHostTask || (IsGlobalBuf || IsConstantBuf))>>
[ 2073]   accessor(
[ 2074]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 2075]       id<Dimensions> AccessOffset,
[ 2076]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 2077]           {},
[ 2078]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2079] #ifdef __SYCL_DEVICE_ONLY__
[ 2080]       : impl(AccessOffset, AccessRange, BufferRef.get_range()) {
[ 2081]     (void)PropertyList;
[ 2082]     (void)CodeLoc;
[ 2083]   }
[ 2084] #else
[ 2085]       : AccessorBaseHost(detail::convertToArrayOfN<3, 0>(AccessOffset),
[ 2086]                          detail::convertToArrayOfN<3, 1>(AccessRange),
[ 2087]                          detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 2088]                          getAdjustedMode(PropertyList),
[ 2089]                          detail::getSyclObjImpl(BufferRef).get(), Dimensions,
[ 2090]                          sizeof(DataT), IsPlaceH, BufferRef.OffsetInBytes,
[ 2091]                          BufferRef.IsSubBuffer, PropertyList) {
[ 2092]     throwIfUsedByGraph();
[ 2093]     preScreenAccessor(PropertyList);
[ 2094]     if (!AccessorBaseHost::isPlaceholder())
[ 2095]       addHostAccessorAndWait(AccessorBaseHost::impl.get());
[ 2096]     if (BufferRef.isOutOfBounds(AccessOffset, AccessRange,
[ 2097]                                 BufferRef.get_range()))
[ 2098]       throw sycl::invalid_object_error(
[ 2099]           "accessor with requested offset and range would exceed the bounds of "
[ 2100]           "the buffer",
[ 2101]           PI_ERROR_INVALID_VALUE);
[ 2102] 
[ 2103]     initHostAcc();
[ 2104]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 2105]                                     detail::AccessorBaseHost::impl.get(),
[ 2106]                                     AccessTarget, AccessMode, CodeLoc);
[ 2107]     GDBMethodsAnchor();
[ 2108]   }
[ 2109] #endif
[ 2110] 
[ 2111]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 2112]             typename TagT,
[ 2113]             typename = std::enable_if_t<
[ 2114]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 2115]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 2116]                 (IsGlobalBuf || IsConstantBuf || IsHostTask)>>
[ 2117]   accessor(
[ 2118]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 2119]       id<Dimensions> AccessOffset, TagT, const property_list &PropertyList = {},
[ 2120]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2121]       : accessor(BufferRef, AccessRange, AccessOffset, PropertyList, CodeLoc) {
[ 2122]     adjustAccPropsInBuf(BufferRef);
[ 2123]   }
[ 2124] 
[ 2125]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 2126]             typename TagT, typename... PropTypes,
[ 2127]             typename = std::enable_if_t<
[ 2128]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 2129]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 2130]                 (IsGlobalBuf || IsConstantBuf || IsHostTask)>>
[ 2131]   accessor(
[ 2132]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 2133]       id<Dimensions> AccessOffset, TagT,
[ 2134]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 2135]           {},
[ 2136]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2137]       : accessor(BufferRef, AccessRange, AccessOffset, PropertyList, CodeLoc) {
[ 2138]     adjustAccPropsInBuf(BufferRef);
[ 2139]   }
[ 2140] 
[ 2141]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 2142]             typename = std::enable_if_t<
[ 2143]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 2144]                 IsSameAsBuffer<T, Dims>::value &&
[ 2145]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 2146]   accessor(
[ 2147]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 2148]       range<Dimensions> AccessRange, id<Dimensions> AccessOffset,
[ 2149]       const property_list &PropertyList = {},
[ 2150]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2151] #ifdef __SYCL_DEVICE_ONLY__
[ 2152]       : impl(AccessOffset, AccessRange, BufferRef.get_range()) {
[ 2153]     (void)CommandGroupHandler;
[ 2154]     (void)PropertyList;
[ 2155]     (void)CodeLoc;
[ 2156]   }
[ 2157] #else
[ 2158]       : AccessorBaseHost(detail::convertToArrayOfN<3, 0>(AccessOffset),
[ 2159]                          detail::convertToArrayOfN<3, 1>(AccessRange),
[ 2160]                          detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 2161]                          getAdjustedMode(PropertyList),
[ 2162]                          detail::getSyclObjImpl(BufferRef).get(), Dimensions,
[ 2163]                          sizeof(DataT), BufferRef.OffsetInBytes,
[ 2164]                          BufferRef.IsSubBuffer, PropertyList) {
[ 2165]     throwIfUsedByGraph();
[ 2166]     preScreenAccessor(PropertyList);
[ 2167]     if (BufferRef.isOutOfBounds(AccessOffset, AccessRange,
[ 2168]                                 BufferRef.get_range()))
[ 2169]       throw sycl::invalid_object_error(
[ 2170]           "accessor with requested offset and range would exceed the bounds of "
[ 2171]           "the buffer",
[ 2172]           PI_ERROR_INVALID_VALUE);
[ 2173] 
[ 2174]     initHostAcc();
[ 2175]     detail::associateWithHandler(CommandGroupHandler, this, AccessTarget);
[ 2176]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 2177]                                     detail::AccessorBaseHost::impl.get(),
[ 2178]                                     AccessTarget, AccessMode, CodeLoc);
[ 2179]     GDBMethodsAnchor();
[ 2180]   }
[ 2181] #endif
[ 2182] 
[ 2183]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 2184]             typename... PropTypes,
[ 2185]             typename = std::enable_if_t<
[ 2186]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 2187]                 IsSameAsBuffer<T, Dims>::value &&
[ 2188]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 2189]   accessor(
[ 2190]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 2191]       range<Dimensions> AccessRange, id<Dimensions> AccessOffset,
[ 2192]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 2193]           {},
[ 2194]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2195] #ifdef __SYCL_DEVICE_ONLY__
[ 2196]       : impl(AccessOffset, AccessRange, BufferRef.get_range()) {
[ 2197]     (void)CommandGroupHandler;
[ 2198]     (void)PropertyList;
[ 2199]     (void)CodeLoc;
[ 2200]   }
[ 2201] #else
[ 2202]       : AccessorBaseHost(detail::convertToArrayOfN<3, 0>(AccessOffset),
[ 2203]                          detail::convertToArrayOfN<3, 1>(AccessRange),
[ 2204]                          detail::convertToArrayOfN<3, 1>(BufferRef.get_range()),
[ 2205]                          getAdjustedMode(PropertyList),
[ 2206]                          detail::getSyclObjImpl(BufferRef).get(), Dimensions,
[ 2207]                          sizeof(DataT), BufferRef.OffsetInBytes,
[ 2208]                          BufferRef.IsSubBuffer, PropertyList) {
[ 2209]     throwIfUsedByGraph();
[ 2210]     preScreenAccessor(PropertyList);
[ 2211]     if (BufferRef.isOutOfBounds(AccessOffset, AccessRange,
[ 2212]                                 BufferRef.get_range()))
[ 2213]       throw sycl::invalid_object_error(
[ 2214]           "accessor with requested offset and range would exceed the bounds of "
[ 2215]           "the buffer",
[ 2216]           PI_ERROR_INVALID_VALUE);
[ 2217] 
[ 2218]     initHostAcc();
[ 2219]     detail::associateWithHandler(CommandGroupHandler, this, AccessTarget);
[ 2220]     detail::constructorNotification(detail::getSyclObjImpl(BufferRef).get(),
[ 2221]                                     detail::AccessorBaseHost::impl.get(),
[ 2222]                                     AccessTarget, AccessMode, CodeLoc);
[ 2223]     GDBMethodsAnchor();
[ 2224]   }
[ 2225] #endif
[ 2226] 
[ 2227]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 2228]             typename TagT,
[ 2229]             typename = std::enable_if_t<
[ 2230]                 detail::IsRunTimePropertyListT<PropertyListT>::value &&
[ 2231]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 2232]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 2233]   accessor(
[ 2234]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 2235]       range<Dimensions> AccessRange, id<Dimensions> AccessOffset, TagT,
[ 2236]       const property_list &PropertyList = {},
[ 2237]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2238]       : accessor(BufferRef, CommandGroupHandler, AccessRange, AccessOffset,
[ 2239]                  PropertyList, CodeLoc) {
[ 2240]     adjustAccPropsInBuf(BufferRef);
[ 2241]   }
[ 2242] 
[ 2243]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 2244]             typename TagT, typename... PropTypes,
[ 2245]             typename = std::enable_if_t<
[ 2246]                 detail::IsCxPropertyList<PropertyListT>::value &&
[ 2247]                 IsSameAsBuffer<T, Dims>::value && IsValidTag<TagT>::value &&
[ 2248]                 (IsGlobalBuf || IsConstantBuf || IsHostBuf || IsHostTask)>>
[ 2249]   accessor(
[ 2250]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 2251]       range<Dimensions> AccessRange, id<Dimensions> AccessOffset, TagT,
[ 2252]       const ext::oneapi::accessor_property_list<PropTypes...> &PropertyList =
[ 2253]           {},
[ 2254]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2255]       : accessor(BufferRef, CommandGroupHandler, AccessRange, AccessOffset,
[ 2256]                  PropertyList, CodeLoc) {
[ 2257]     adjustAccPropsInBuf(BufferRef);
[ 2258]   }
[ 2259] 
[ 2260]   template <typename... NewPropsT>
[ 2261]   accessor(
[ 2262]       const accessor<DataT, Dimensions, AccessMode, AccessTarget, IsPlaceholder,
[ 2263]                      ext::oneapi::accessor_property_list<NewPropsT...>> &Other,
[ 2264]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2265] #ifdef __SYCL_DEVICE_ONLY__
[ 2266]       : impl(Other.impl), MData(Other.MData)
[ 2267] #else
[ 2268]       : detail::AccessorBaseHost(Other), MAccData(Other.MAccData)
[ 2269] #endif
[ 2270]   {
[ 2271]     static_assert(detail::IsCxPropertyList<PropertyListT>::value,
[ 2272]                   "Conversion is only available for accessor_property_list");
[ 2273]     static_assert(
[ 2274]         PropertyListT::template areSameCompileTimeProperties<NewPropsT...>(),
[ 2275]         "Compile-time-constant properties must be the same");
[ 2276]     (void)CodeLoc;
[ 2277] #ifndef __SYCL_DEVICE_ONLY__
[ 2278]     detail::constructorNotification(getMemoryObject(), impl.get(), AccessTarget,
[ 2279]                                     AccessMode, CodeLoc);
[ 2280] #endif
[ 2281]   }
[ 2282] 
[ 2283]   void swap(accessor &other) {
[ 2284]     std::swap(impl, other.impl);
[ 2285] #ifdef __SYCL_DEVICE_ONLY__
[ 2286]     std::swap(MData, other.MData);
[ 2287] #else
[ 2288]     std::swap(MAccData, other.MAccData);
[ 2289] #endif
[ 2290]   }
[ 2291] 
[ 2292]   bool is_placeholder() const {
[ 2293] #ifdef __SYCL_DEVICE_ONLY__
[ 2294]     return false;
[ 2295] #else
[ 2296]     return detail::AccessorBaseHost::isPlaceholder();
[ 2297] #endif
[ 2298]   }
[ 2299] 
[ 2300]   size_t get_size() const { return getAccessRange().size() * sizeof(DataT); }
[ 2301] 
[ 2302]   __SYCL2020_DEPRECATED("get_count() is deprecated, please use size() instead")
[ 2303]   size_t get_count() const { return size(); }
[ 2304]   size_type size() const noexcept { return getAccessRange().size(); }
[ 2305] 
[ 2306]   size_type byte_size() const noexcept { return size() * sizeof(DataT); }
[ 2307] 
[ 2308]   size_type max_size() const noexcept {
[ 2309]     return empty() ? 0 : (std::numeric_limits<difference_type>::max)();
[ 2310]   }
[ 2311] 
[ 2312]   bool empty() const noexcept { return size() == 0; }
[ 2313] 
[ 2314]   template <int Dims = Dimensions,
[ 2315]             typename = std::enable_if_t<Dims == Dimensions && (Dims > 0)>>
[ 2316]   range<Dimensions> get_range() const {
[ 2317]     return getRange<Dims>();
[ 2318]   }
[ 2319] 
[ 2320]   template <int Dims = Dimensions,
[ 2321]             typename = std::enable_if_t<Dims == Dimensions && (Dims > 0)>>
[ 2322]   id<Dimensions> get_offset() const {
[ 2323]     return getOffset<Dims>();
[ 2324]   }
[ 2325] 
[ 2326]   template <int Dims = Dimensions, typename RefT = RefType,
[ 2327]             typename = std::enable_if_t<Dims == 0 &&
[ 2328]                                         (IsAccessAnyWrite || IsAccessReadOnly)>>
[ 2329]   operator reference() const {
[ 2330]     const size_t LinearIndex = getLinearIndex(id<AdjustedDim>());
[ 2331]     return *(getQualifiedPtr() + LinearIndex);
[ 2332]   }
[ 2333] 
[ 2334]   template <int Dims = Dimensions,
[ 2335]             typename = std::enable_if_t<AccessMode != access_mode::atomic &&
[ 2336]                                         !IsAccessReadOnly && Dims == 0>>
[ 2337]   const accessor &operator=(const value_type &Other) const {
[ 2338]     *getQualifiedPtr() = Other;
[ 2339]     return *this;
[ 2340]   }
[ 2341] 
[ 2342]   template <int Dims = Dimensions,
[ 2343]             typename = std::enable_if_t<AccessMode != access_mode::atomic &&
[ 2344]                                         !IsAccessReadOnly && Dims == 0>>
[ 2345]   const accessor &operator=(value_type &&Other) const {
[ 2346]     *getQualifiedPtr() = std::move(Other);
[ 2347]     return *this;
[ 2348]   }
[ 2349] 
[ 2350]   template <int Dims = Dimensions,
[ 2351]             typename = std::enable_if_t<(Dims > 0) &&
[ 2352]                                         (IsAccessAnyWrite || IsAccessReadOnly)>>
[ 2353]   reference operator[](id<Dimensions> Index) const {
[ 2354]     const size_t LinearIndex = getLinearIndex(Index);
[ 2355]     return getQualifiedPtr()[LinearIndex];
		[0x00120]         mov (16|M0)              r10.0<2>:ud   r8.0<1;1,0>:ud                   {Compacted,I@1}
		[0x00128]         mov (16|M16)             r14.0<2>:ud   r9.0<1;1,0>:ud                   {Compacted}
		[0x00138]         shl (16|M0)              r12.0<1>:q    r10.0<2;1,0>:ud   3:w               {Compacted,I@3}
		[0x00140]         shl (16|M16)             r16.0<1>:q    r14.0<2;1,0>:ud   3:w               {Compacted,I@3}
		[0x00148]         add (16|M0)              r115.0<1>:q   r3.0<0;1,0>:q     r12.0<1;1,0>:q   {Compacted,I@2}
		[0x00150]         add (16|M16)             r117.0<1>:q   r3.0<0;1,0>:q     r16.0<1;1,0>:q   {Compacted,I@2}
		[0x001B0] (W)     add (1|M0)               r2.0<1>:d     r4.14<0;1,0>:d    -r41.6<0;1,0>:d  {I@3}
		[0x001C0] (W)     shl (1|M0)               r3.0<1>:q     r41.6<0;1,0>:ud   3:w               {Compacted}
		[0x001C8] (W)     shl (1|M0)               r6.0<1>:q     r2.0<0;1,0>:d     3:w               {Compacted,I@2}
		[0x001D0] (W)     add (1|M0)               r7.0<1>:q     r41.1<0;1,0>:q    r3.0<0;1,0>:q    {Compacted,I@2}
		[0x001D8]         sync.nop                             null                             {Compacted,I@2}
		[0x001E0] (W)     add (1|M0)               r9.0<1>:q     r41.0<0;1,0>:q    r6.0<0;1,0>:q    {Compacted,$7.src}
		[0x00230] (W)     add (1|M0)               r12.0<1>:q    r7.0<0;1,0>:q     8:w               {Compacted}
		[0x00238] (W)     add (1|M0)               r8.0<1>:d     r4.15<0;1,0>:d    r4.14<0;1,0>:d   {I@2}
		[0x00248] (W)     add (1|M0)               r30.0<1>:q    r9.0<0;1,0>:q     -16:w               {Compacted}
		[0x00250] (W)     shl (1|M0)               r11.0<1>:q    r8.0<0;1,0>:d     3:w               {Compacted,I@2}
		[0x00258] (W)     add (1|M0)               r14.0<1>:q    r7.0<0;1,0>:q     16:w               {Compacted}
		[0x00260] (W)     add (1|M0)               r28.0<1>:q    r41.0<0;1,0>:q    r11.0<0;1,0>:q   {Compacted,I@2}
		[0x00268] (W)     add (1|M0)               r32.0<1>:q    r9.0<0;1,0>:q     -24:w               {Compacted}
		[0x00270] (W)     add (1|M0)               r16.0<1>:q    r7.0<0;1,0>:q     24:w               {Compacted}
		[0x00278] (W)     add (1|M0)               r18.0<1>:q    r7.0<0;1,0>:q     32:w               {Compacted}
		[0x00280] (W)     add (1|M0)               r20.0<1>:q    r7.0<0;1,0>:q     40:w               {Compacted}
		[0x00288] (W)     add (1|M0)               r22.0<1>:q    r7.0<0;1,0>:q     48:w               {Compacted}
		[0x00290] (W)     add (1|M0)               r24.0<1>:q    r7.0<0;1,0>:q     56:w               {Compacted}
		[0x00298] (W)     add (1|M0)               r46.0<1>:q    r7.0<0;1,0>:q     64:w               {Compacted}
		[0x002A0] (W)     add (1|M0)               r50.0<1>:q    r7.0<0;1,0>:q     72:w               {Compacted}
		[0x002A8] (W)     add (1|M0)               r54.0<1>:q    r7.0<0;1,0>:q     80:w               {Compacted,$8.src}
		[0x002B0] (W)     add (1|M0)               r58.0<1>:q    r7.0<0;1,0>:q     88:w               {Compacted}
		[0x002B8] (W)     add (1|M0)               r62.0<1>:q    r7.0<0;1,0>:q     96:w               {Compacted}
		[0x002C0] (W)     add (1|M0)               r66.0<1>:q    r7.0<0;1,0>:q     104:w               {Compacted}
		[0x002C8] (W)     add (1|M0)               r70.0<1>:q    r7.0<0;1,0>:q     112:w               {Compacted}
		[0x002D0] (W)     add (1|M0)               r74.0<1>:q    r7.0<0;1,0>:q     120:w               {Compacted}
		[0x002D8] (W)     add (1|M0)               r34.0<1>:q    r9.0<0;1,0>:q     -32:w               {Compacted}
		[0x002E0] (W)     add (1|M0)               r36.0<1>:q    r9.0<0;1,0>:q     -40:w               {Compacted}
		[0x002E8] (W)     add (1|M0)               r38.0<1>:q    r9.0<0;1,0>:q     -48:w               {Compacted,$6.src}
		[0x002F0] (W)     add (1|M0)               r40.0<1>:q    r9.0<0;1,0>:q     -56:w               {Compacted}
		[0x002F8] (W)     add (1|M0)               r42.0<1>:q    r9.0<0;1,0>:q     -64:w               {Compacted}
		[0x00300] (W)     add (1|M0)               r48.0<1>:q    r9.0<0;1,0>:q     -72:w               {Compacted}
		[0x00308] (W)     add (1|M0)               r52.0<1>:q    r9.0<0;1,0>:q     -80:w               {Compacted}
		[0x00310] (W)     add (1|M0)               r56.0<1>:q    r9.0<0;1,0>:q     -88:w               {Compacted}
		[0x00318] (W)     add (1|M0)               r60.0<1>:q    r9.0<0;1,0>:q     -96:w               {Compacted}
		[0x00320] (W)     add (1|M0)               r64.0<1>:q    r9.0<0;1,0>:q     -104:w               {Compacted}
		[0x00328] (W)     add (1|M0)               r68.0<1>:q    r9.0<0;1,0>:q     -112:w               {Compacted}
		[0x00330] (W)     add (1|M0)               r72.0<1>:q    r9.0<0;1,0>:q     -120:w               {Compacted}
[ 2356]   }
[ 2357] 
[ 2358]   template <int Dims = Dimensions>
[ 2359]   operator typename std::enable_if_t<Dims == 0 &&
[ 2360]                                          AccessMode == access::mode::atomic,
[ 2361] #ifdef __ENABLE_USM_ADDR_SPACE__
[ 2362]                                      atomic<DataT>
[ 2363] #else
[ 2364]                                      atomic<DataT, AS>
[ 2365] #endif
[ 2366]                                      >() const {
[ 2367]     const size_t LinearIndex = getLinearIndex(id<AdjustedDim>());
[ 2368]     return atomic<DataT, AS>(multi_ptr<DataT, AS, access::decorated::yes>(
[ 2369]         getQualifiedPtr() + LinearIndex));
[ 2370]   }
[ 2371] 
[ 2372]   template <int Dims = Dimensions>
[ 2373]   typename std::enable_if_t<(Dims > 0) && AccessMode == access::mode::atomic,
[ 2374]                             atomic<DataT, AS>>
[ 2375]   operator[](id<Dimensions> Index) const {
[ 2376]     const size_t LinearIndex = getLinearIndex(Index);
[ 2377]     return atomic<DataT, AS>(multi_ptr<DataT, AS, access::decorated::yes>(
[ 2378]         getQualifiedPtr() + LinearIndex));
[ 2379]   }
[ 2380] 
[ 2381]   template <int Dims = Dimensions>
[ 2382]   typename std::enable_if_t<Dims == 1 && AccessMode == access::mode::atomic,
[ 2383]                             atomic<DataT, AS>>
[ 2384]   operator[](size_t Index) const {
[ 2385]     const size_t LinearIndex = getLinearIndex(id<AdjustedDim>(Index));
[ 2386]     return atomic<DataT, AS>(multi_ptr<DataT, AS, access::decorated::yes>(
[ 2387]         getQualifiedPtr() + LinearIndex));
[ 2388]   }
[ 2389]   template <int Dims = Dimensions, typename = std::enable_if_t<(Dims > 1)>>
[ 2390]   auto operator[](size_t Index) const {
[ 2391]     return AccessorSubscript<Dims - 1>(*this, Index);
[ 2392]   }
[ 2393] 
[ 2394]   template <access::target AccessTarget_ = AccessTarget,
[ 2395]             typename = std::enable_if_t<
[ 2396]                 (AccessTarget_ == access::target::host_buffer) ||
[ 2397]                 (AccessTarget_ == access::target::host_task)>>
[ 2398]   std::add_pointer_t<value_type> get_pointer() const noexcept {
[ 2399]     return getPointerAdjusted();
[ 2400]   }
[ 2401] 
[ 2402]   template <
[ 2403]       access::target AccessTarget_ = AccessTarget,
[ 2404]       typename = std::enable_if_t<(AccessTarget_ == access::target::device)>>
[ 2405]   __SYCL2020_DEPRECATED(
[ 2406]       "accessor::get_pointer() is deprecated, please use get_multi_ptr()")
[ 2407]   global_ptr<DataT> get_pointer() const noexcept {
[ 2408]     return global_ptr<DataT>(
[ 2409]         const_cast<typename detail::DecoratedType<DataT, AS>::type *>(
[ 2410]             getPointerAdjusted()));
[ 2411]   }
[ 2412] 
[ 2413]   template <access::target AccessTarget_ = AccessTarget,
[ 2414]             typename = std::enable_if_t<AccessTarget_ ==
[ 2415]                                         access::target::constant_buffer>>
[ 2416]   constant_ptr<DataT> get_pointer() const {
[ 2417]     return constant_ptr<DataT>(getPointerAdjusted());
[ 2418]   }
[ 2419] 
[ 2420]   template <access::decorated IsDecorated>
[ 2421]   accessor_ptr<IsDecorated> get_multi_ptr() const noexcept {
[ 2422]     return accessor_ptr<IsDecorated>(getPointerAdjusted());
[ 2423]   }
[ 2424] 
[ 2425]   // accessor::has_property for runtime properties is only available in host
[ 2426]   // code. This restriction is not listed in the core spec and will be added in
[ 2427]   // future versions.
[ 2428]   template <typename Property>
[ 2429]   typename std::enable_if_t<
[ 2430]       !ext::oneapi::is_compile_time_property<Property>::value, bool>
[ 2431]   has_property() const noexcept {
[ 2432] #ifndef __SYCL_DEVICE_ONLY__
[ 2433]     return getPropList().template has_property<Property>();
[ 2434] #else
[ 2435]     return false;
[ 2436] #endif
[ 2437]   }
[ 2438] 
[ 2439]   // accessor::get_property for runtime properties is only available in host
[ 2440]   // code. This restriction is not listed in the core spec and will be added in
[ 2441]   // future versions.
[ 2442]   template <typename Property,
[ 2443]             typename = typename std::enable_if_t<
[ 2444]                 !ext::oneapi::is_compile_time_property<Property>::value>>
[ 2445]   Property get_property() const {
[ 2446] #ifndef __SYCL_DEVICE_ONLY__
[ 2447]     return getPropList().template get_property<Property>();
[ 2448] #else
[ 2449]     return Property();
[ 2450] #endif
[ 2451]   }
[ 2452] 
[ 2453]   template <typename Property>
[ 2454]   static constexpr bool has_property(
[ 2455]       typename std::enable_if_t<
[ 2456]           ext::oneapi::is_compile_time_property<Property>::value> * = 0) {
[ 2457]     return PropertyListT::template has_property<Property>();
[ 2458]   }
[ 2459] 
[ 2460]   template <typename Property>
[ 2461]   static constexpr auto get_property(
[ 2462]       typename std::enable_if_t<
[ 2463]           ext::oneapi::is_compile_time_property<Property>::value> * = 0) {
[ 2464]     return PropertyListT::template get_property<Property>();
[ 2465]   }
[ 2466] 
[ 2467]   bool operator==(const accessor &Rhs) const { return impl == Rhs.impl; }
[ 2468]   bool operator!=(const accessor &Rhs) const { return !(*this == Rhs); }
[ 2469] 
[ 2470]   iterator begin() const noexcept {
[ 2471]     return iterator::getBegin(
[ 2472]         get_pointer(),
[ 2473]         detail::convertToArrayOfN<AdjustedDim, 1>(getMemoryRange()),
[ 2474]         getRange<AdjustedDim>(), getOffset<AdjustedDim>());
[ 2475]   }
[ 2476] 
[ 2477]   iterator end() const noexcept {
[ 2478]     return iterator::getEnd(
[ 2479]         get_pointer(),
[ 2480]         detail::convertToArrayOfN<AdjustedDim, 1>(getMemoryRange()),
[ 2481]         getRange<AdjustedDim>(), getOffset<AdjustedDim>());
[ 2482]   }
[ 2483] 
[ 2484]   const_iterator cbegin() const noexcept {
[ 2485]     return const_iterator::getBegin(
[ 2486]         get_pointer(),
[ 2487]         detail::convertToArrayOfN<AdjustedDim, 1>(getMemoryRange()),
[ 2488]         getRange<AdjustedDim>(), getOffset<AdjustedDim>());
[ 2489]   }
[ 2490] 
[ 2491]   const_iterator cend() const noexcept {
[ 2492]     return const_iterator::getEnd(
[ 2493]         get_pointer(),
[ 2494]         detail::convertToArrayOfN<AdjustedDim, 1>(getMemoryRange()),
[ 2495]         getRange<AdjustedDim>(), getOffset<AdjustedDim>());
[ 2496]   }
[ 2497] 
[ 2498]   reverse_iterator rbegin() const noexcept { return reverse_iterator(end()); }
[ 2499]   reverse_iterator rend() const noexcept { return reverse_iterator(begin()); }
[ 2500] 
[ 2501]   const_reverse_iterator crbegin() const noexcept {
[ 2502]     return const_reverse_iterator(cend());
[ 2503]   }
[ 2504]   const_reverse_iterator crend() const noexcept {
[ 2505]     return const_reverse_iterator(cbegin());
[ 2506]   }
[ 2507] 
[ 2508] private:
[ 2509]   template <int Dims, typename = std::enable_if_t<(Dims > 0)>>
[ 2510]   range<Dims> getRange() const {
[ 2511]     return detail::convertToArrayOfN<AdjustedDim, 1>(getAccessRange());
[ 2512]   }
[ 2513] 
[ 2514]   template <int Dims = Dimensions, typename = std::enable_if_t<(Dims > 0)>>
[ 2515]   id<Dims> getOffset() const {
[ 2516]     static_assert(
[ 2517]         !(PropertyListT::template has_property<
[ 2518]             sycl::ext::oneapi::property::no_offset>()),
[ 2519]         "Accessor has no_offset property, get_offset() can not be used");
[ 2520]     return detail::convertToArrayOfN<Dims, 0>(getOffset());
[ 2521]   }
[ 2522] 
[ 2523] #ifdef __SYCL_DEVICE_ONLY__
[ 2524]   size_t getTotalOffset() const noexcept {
[ 2525]     size_t TotalOffset = 0;
[ 2526]     detail::loop<Dimensions>([&, this](size_t I) {
[ 2527]       TotalOffset = TotalOffset * impl.MemRange[I];
[ 2528]       if constexpr (!(PropertyListT::template has_property<
[ 2529]                         sycl::ext::oneapi::property::no_offset>())) {
[ 2530]         TotalOffset += impl.Offset[I];
[ 2531]       }
[ 2532]     });
[ 2533] 
[ 2534]     return TotalOffset;
[ 2535]   }
[ 2536] #endif
[ 2537] 
[ 2538]   // supporting function for get_pointer()
[ 2539]   // MData has been preadjusted with offset for faster access with []
[ 2540]   // but for get_pointer() we must return the original pointer.
[ 2541]   // On device, getQualifiedPtr() returns MData, so we need to backjust it.
[ 2542]   // On host, getQualifiedPtr() does not return MData, no need to adjust.
[ 2543]   auto getPointerAdjusted() const noexcept {
[ 2544] #ifdef __SYCL_DEVICE_ONLY__
[ 2545]     return getQualifiedPtr() - getTotalOffset();
[ 2546] #else
[ 2547]     return getQualifiedPtr();
[ 2548] #endif
[ 2549]   }
[ 2550] 
[ 2551]   void preScreenAccessor(const PropertyListT &PropertyList) {
[ 2552]     // check that no_init property is compatible with access mode
[ 2553]     if (PropertyList.template has_property<property::no_init>() &&
[ 2554]         AccessMode == access::mode::read) {
[ 2555]       throw sycl::invalid_object_error(
[ 2556]           "accessor would cannot be both read_only and no_init",
[ 2557]           PI_ERROR_INVALID_VALUE);
[ 2558]     }
[ 2559]   }
[ 2560] 
[ 2561]   template <typename BufT, typename... PropTypes>
[ 2562]   void adjustAccPropsInBuf(BufT &Buffer) {
[ 2563]     if constexpr (PropertyListT::template has_property<
[ 2564]                       sycl::ext::intel::property::buffer_location>()) {
[ 2565]       auto location = (PropertyListT::template get_property<
[ 2566]                            sycl::ext::intel::property::buffer_location>())
[ 2567]                           .get_location();
[ 2568]       property_list PropList{
[ 2569]           sycl::property::buffer::detail::buffer_location(location)};
[ 2570]       Buffer.addOrReplaceAccessorProperties(PropList);
[ 2571]     } else {
[ 2572]       deleteAccPropsFromBuf(Buffer);
[ 2573]     }
[ 2574]   }
[ 2575] 
[ 2576]   template <typename BufT> void deleteAccPropsFromBuf(BufT &Buffer) {
[ 2577]     Buffer.deleteAccProps(
[ 2578]         sycl::detail::PropWithDataKind::AccPropBufferLocation);
[ 2579]   }
[ 2580] };
[ 2581] 
[ 2582] template <typename DataT, int Dimensions, typename AllocatorT>
[ 2583] accessor(buffer<DataT, Dimensions, AllocatorT>)
[ 2584]     -> accessor<DataT, Dimensions, access::mode::read_write, target::device,
[ 2585]                 access::placeholder::true_t>;
[ 2586] 
[ 2587] template <typename DataT, int Dimensions, typename AllocatorT,
[ 2588]           typename... PropsT>
[ 2589] accessor(buffer<DataT, Dimensions, AllocatorT>,
[ 2590]          const ext::oneapi::accessor_property_list<PropsT...> &)
[ 2591]     -> accessor<DataT, Dimensions, access::mode::read_write, target::device,
[ 2592]                 access::placeholder::true_t,
[ 2593]                 ext::oneapi::accessor_property_list<PropsT...>>;
[ 2594] 
[ 2595] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1>
[ 2596] accessor(buffer<DataT, Dimensions, AllocatorT>, Type1)
[ 2597]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type1, Type1>(),
[ 2598]                 detail::deduceAccessTarget<Type1, Type1>(target::device),
[ 2599]                 access::placeholder::true_t>;
[ 2600] 
[ 2601] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2602]           typename... PropsT>
[ 2603] accessor(buffer<DataT, Dimensions, AllocatorT>, Type1,
[ 2604]          const ext::oneapi::accessor_property_list<PropsT...> &)
[ 2605]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type1, Type1>(),
[ 2606]                 detail::deduceAccessTarget<Type1, Type1>(target::device),
[ 2607]                 access::placeholder::true_t,
[ 2608]                 ext::oneapi::accessor_property_list<PropsT...>>;
[ 2609] 
[ 2610] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2611]           typename Type2>
[ 2612] accessor(buffer<DataT, Dimensions, AllocatorT>, Type1, Type2)
[ 2613]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type1, Type2>(),
[ 2614]                 detail::deduceAccessTarget<Type1, Type2>(target::device),
[ 2615]                 access::placeholder::true_t>;
[ 2616] 
[ 2617] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2618]           typename Type2, typename... PropsT>
[ 2619] accessor(buffer<DataT, Dimensions, AllocatorT>, Type1, Type2,
[ 2620]          const ext::oneapi::accessor_property_list<PropsT...> &)
[ 2621]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type1, Type2>(),
[ 2622]                 detail::deduceAccessTarget<Type1, Type2>(target::device),
[ 2623]                 access::placeholder::true_t,
[ 2624]                 ext::oneapi::accessor_property_list<PropsT...>>;
[ 2625] 
[ 2626] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2627]           typename Type2, typename Type3>
[ 2628] accessor(buffer<DataT, Dimensions, AllocatorT>, Type1, Type2, Type3)
[ 2629]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type2, Type3>(),
[ 2630]                 detail::deduceAccessTarget<Type2, Type3>(target::device),
[ 2631]                 access::placeholder::true_t>;
[ 2632] 
[ 2633] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2634]           typename Type2, typename Type3, typename... PropsT>
[ 2635] accessor(buffer<DataT, Dimensions, AllocatorT>, Type1, Type2, Type3,
[ 2636]          const ext::oneapi::accessor_property_list<PropsT...> &)
[ 2637]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type2, Type3>(),
[ 2638]                 detail::deduceAccessTarget<Type2, Type3>(target::device),
[ 2639]                 access::placeholder::true_t,
[ 2640]                 ext::oneapi::accessor_property_list<PropsT...>>;
[ 2641] 
[ 2642] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2643]           typename Type2, typename Type3, typename Type4>
[ 2644] accessor(buffer<DataT, Dimensions, AllocatorT>, Type1, Type2, Type3, Type4)
[ 2645]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type3, Type4>(),
[ 2646]                 detail::deduceAccessTarget<Type3, Type4>(target::device),
[ 2647]                 access::placeholder::true_t>;
[ 2648] 
[ 2649] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2650]           typename Type2, typename Type3, typename Type4, typename... PropsT>
[ 2651] accessor(buffer<DataT, Dimensions, AllocatorT>, Type1, Type2, Type3, Type4,
[ 2652]          const ext::oneapi::accessor_property_list<PropsT...> &)
[ 2653]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type3, Type4>(),
[ 2654]                 detail::deduceAccessTarget<Type3, Type4>(target::device),
[ 2655]                 access::placeholder::true_t,
[ 2656]                 ext::oneapi::accessor_property_list<PropsT...>>;
[ 2657] 
[ 2658] template <typename DataT, int Dimensions, typename AllocatorT>
[ 2659] accessor(buffer<DataT, Dimensions, AllocatorT>, handler &)
[ 2660]     -> accessor<DataT, Dimensions, access::mode::read_write, target::device,
[ 2661]                 access::placeholder::false_t>;
[ 2662] 
[ 2663] template <typename DataT, int Dimensions, typename AllocatorT,
[ 2664]           typename... PropsT>
[ 2665] accessor(buffer<DataT, Dimensions, AllocatorT>, handler &,
[ 2666]          const ext::oneapi::accessor_property_list<PropsT...> &)
[ 2667]     -> accessor<DataT, Dimensions, access::mode::read_write, target::device,
[ 2668]                 access::placeholder::false_t,
[ 2669]                 ext::oneapi::accessor_property_list<PropsT...>>;
[ 2670] 
[ 2671] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1>
[ 2672] accessor(buffer<DataT, Dimensions, AllocatorT>, handler &, Type1)
[ 2673]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type1, Type1>(),
[ 2674]                 detail::deduceAccessTarget<Type1, Type1>(target::device),
[ 2675]                 access::placeholder::false_t>;
[ 2676] 
[ 2677] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2678]           typename... PropsT>
[ 2679] accessor(buffer<DataT, Dimensions, AllocatorT>, handler &, Type1,
[ 2680]          const ext::oneapi::accessor_property_list<PropsT...> &)
[ 2681]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type1, Type1>(),
[ 2682]                 detail::deduceAccessTarget<Type1, Type1>(target::device),
[ 2683]                 access::placeholder::false_t,
[ 2684]                 ext::oneapi::accessor_property_list<PropsT...>>;
[ 2685] 
[ 2686] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2687]           typename Type2>
[ 2688] accessor(buffer<DataT, Dimensions, AllocatorT>, handler &, Type1, Type2)
[ 2689]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type1, Type2>(),
[ 2690]                 detail::deduceAccessTarget<Type1, Type2>(target::device),
[ 2691]                 access::placeholder::false_t>;
[ 2692] 
[ 2693] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2694]           typename Type2, typename... PropsT>
[ 2695] accessor(buffer<DataT, Dimensions, AllocatorT>, handler &, Type1, Type2,
[ 2696]          const ext::oneapi::accessor_property_list<PropsT...> &)
[ 2697]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type1, Type2>(),
[ 2698]                 detail::deduceAccessTarget<Type1, Type2>(target::device),
[ 2699]                 access::placeholder::false_t,
[ 2700]                 ext::oneapi::accessor_property_list<PropsT...>>;
[ 2701] 
[ 2702] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2703]           typename Type2, typename Type3>
[ 2704] accessor(buffer<DataT, Dimensions, AllocatorT>, handler &, Type1, Type2, Type3)
[ 2705]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type2, Type3>(),
[ 2706]                 detail::deduceAccessTarget<Type2, Type3>(target::device),
[ 2707]                 access::placeholder::false_t>;
[ 2708] 
[ 2709] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2710]           typename Type2, typename Type3, typename... PropsT>
[ 2711] accessor(buffer<DataT, Dimensions, AllocatorT>, handler &, Type1, Type2, Type3,
[ 2712]          const ext::oneapi::accessor_property_list<PropsT...> &)
[ 2713]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type2, Type3>(),
[ 2714]                 detail::deduceAccessTarget<Type2, Type3>(target::device),
[ 2715]                 access::placeholder::false_t,
[ 2716]                 ext::oneapi::accessor_property_list<PropsT...>>;
[ 2717] 
[ 2718] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2719]           typename Type2, typename Type3, typename Type4>
[ 2720] accessor(buffer<DataT, Dimensions, AllocatorT>, handler &, Type1, Type2, Type3,
[ 2721]          Type4)
[ 2722]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type3, Type4>(),
[ 2723]                 detail::deduceAccessTarget<Type3, Type4>(target::device),
[ 2724]                 access::placeholder::false_t>;
[ 2725] 
[ 2726] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 2727]           typename Type2, typename Type3, typename Type4, typename... PropsT>
[ 2728] accessor(buffer<DataT, Dimensions, AllocatorT>, handler &, Type1, Type2, Type3,
[ 2729]          Type4, const ext::oneapi::accessor_property_list<PropsT...> &)
[ 2730]     -> accessor<DataT, Dimensions, detail::deduceAccessMode<Type3, Type4>(),
[ 2731]                 detail::deduceAccessTarget<Type3, Type4>(target::device),
[ 2732]                 access::placeholder::false_t,
[ 2733]                 ext::oneapi::accessor_property_list<PropsT...>>;
[ 2734] 
[ 2735] /// Local accessor
[ 2736] ///
[ 2737] /// \ingroup sycl_api_acc
[ 2738] template <typename DataT, int Dimensions, access::mode AccessMode,
[ 2739]           access::placeholder IsPlaceholder>
[ 2740] class __SYCL_SPECIAL_CLASS local_accessor_base :
[ 2741] #ifndef __SYCL_DEVICE_ONLY__
[ 2742]     public detail::LocalAccessorBaseHost,
[ 2743] #endif
[ 2744]     public detail::accessor_common<DataT, Dimensions, AccessMode,
[ 2745]                                    access::target::local, IsPlaceholder> {
[ 2746] protected:
[ 2747]   constexpr static int AdjustedDim = Dimensions == 0 ? 1 : Dimensions;
[ 2748] 
[ 2749]   using AccessorCommonT =
[ 2750]       detail::accessor_common<DataT, Dimensions, AccessMode,
[ 2751]                               access::target::local, IsPlaceholder>;
[ 2752] 
[ 2753]   using AccessorCommonT::AS;
[ 2754] 
[ 2755]   // Cannot do "using AccessorCommonT::Flag" as it doesn't work with g++ as host
[ 2756]   // compiler, for some reason.
[ 2757]   static constexpr bool IsAccessAnyWrite = AccessorCommonT::IsAccessAnyWrite;
[ 2758]   static constexpr bool IsAccessReadOnly = AccessorCommonT::IsAccessReadOnly;
[ 2759]   static constexpr bool IsConst = AccessorCommonT::IsConst;
[ 2760] 
[ 2761]   template <int Dims>
[ 2762]   using AccessorSubscript =
[ 2763]       typename AccessorCommonT::template AccessorSubscript<
[ 2764]           Dims,
[ 2765]           local_accessor_base<DataT, Dimensions, AccessMode, IsPlaceholder>>;
[ 2766] 
[ 2767]   using ConcreteASPtrType = typename detail::DecoratedType<DataT, AS>::type *;
[ 2768] 
[ 2769]   using RefType = detail::const_if_const_AS<AS, DataT> &;
[ 2770]   using PtrType = detail::const_if_const_AS<AS, DataT> *;
[ 2771] 
[ 2772] #ifdef __SYCL_DEVICE_ONLY__
[ 2773]   detail::LocalAccessorBaseDevice<AdjustedDim> impl;
[ 2774] 
[ 2775]   sycl::range<AdjustedDim> &getSize() { return impl.MemRange; }
[ 2776]   const sycl::range<AdjustedDim> &getSize() const { return impl.MemRange; }
[ 2777] 
[ 2778]   void __init(ConcreteASPtrType Ptr, range<AdjustedDim> AccessRange,
[ 2779]               range<AdjustedDim>, id<AdjustedDim>) {
[ 2780]     MData = Ptr;
[ 2781]     detail::loop<AdjustedDim>(
[ 2782]         [&, this](size_t I) { getSize()[I] = AccessRange[I]; });
[ 2783]   }
[ 2784] 
[ 2785]   // __init variant used by the device compiler for ESIMD kernels.
[ 2786]   // TODO: In ESIMD accessors usage is limited for now - access range, mem
[ 2787]   // range and offset are not supported.
[ 2788]   void __init_esimd(ConcreteASPtrType Ptr) {
[ 2789]     MData = Ptr;
[ 2790]     detail::loop<AdjustedDim>([&, this](size_t I) { getSize()[I] = 0; });
[ 2791]   }
[ 2792] 
[ 2793] public:
[ 2794]   // Default constructor for objects later initialized with __init member.
[ 2795]   local_accessor_base()
[ 2796]       : impl(detail::InitializedVal<AdjustedDim, range>::template get<0>()) {}
[ 2797] 
[ 2798] protected:
[ 2799]   ConcreteASPtrType getQualifiedPtr() const { return MData; }
[ 2800] 
[ 2801]   ConcreteASPtrType MData;
[ 2802] 
[ 2803] #else
[ 2804] public:
[ 2805]   local_accessor_base()
[ 2806]       : detail::LocalAccessorBaseHost{/*Size*/ sycl::range<3>{0, 0, 0},
[ 2807]                                       /*Dims*/ 0, /*ElemSize*/ sizeof(DataT)} {}
[ 2808] 
[ 2809] protected:
[ 2810]   local_accessor_base(const detail::LocalAccessorImplPtr &Impl)
[ 2811]       : detail::LocalAccessorBaseHost{Impl} {}
[ 2812] 
[ 2813]   char padding[sizeof(detail::LocalAccessorBaseDevice<AdjustedDim>) +
[ 2814]                sizeof(PtrType) - sizeof(detail::LocalAccessorBaseHost)];
[ 2815]   using detail::LocalAccessorBaseHost::getSize;
[ 2816] 
[ 2817]   PtrType getQualifiedPtr() const {
[ 2818]     return reinterpret_cast<PtrType>(LocalAccessorBaseHost::getPtr());
[ 2819]   }
[ 2820] 
[ 2821]   void *getPtr() { return detail::LocalAccessorBaseHost::getPtr(); }
[ 2822]   void *getPtr() const { return detail::LocalAccessorBaseHost::getPtr(); }
[ 2823]   const range<3> &getSize() const {
[ 2824]     return detail::LocalAccessorBaseHost::getSize();
[ 2825]   }
[ 2826]   range<3> &getSize() { return detail::LocalAccessorBaseHost::getSize(); }
[ 2827] 
[ 2828]   // The function references helper methods required by GDB pretty-printers
[ 2829]   void GDBMethodsAnchor() {
[ 2830] #ifndef NDEBUG
[ 2831]     const auto *this_const = this;
[ 2832]     (void)getSize();
[ 2833]     (void)this_const->getSize();
[ 2834]     (void)getPtr();
[ 2835]     (void)this_const->getPtr();
[ 2836] #endif
[ 2837]   }
[ 2838] 
[ 2839] #endif // __SYCL_DEVICE_ONLY__
[ 2840] 
[ 2841]   // Method which calculates linear offset for the ID using Range and Offset.
[ 2842]   template <int Dims = AdjustedDim> size_t getLinearIndex(id<Dims> Id) const {
[ 2843]     size_t Result = 0;
[ 2844]     detail::loop<Dims>(
[ 2845]         [&, this](size_t I) { Result = Result * getSize()[I] + Id[I]; });
[ 2846]     return Result;
[ 2847]   }
[ 2848] 
[ 2849]   template <class Obj>
[ 2850]   friend decltype(Obj::impl) detail::getSyclObjImpl(const Obj &SyclObject);
[ 2851] 
[ 2852]   template <class T>
[ 2853]   friend T detail::createSyclObjFromImpl(decltype(T::impl) ImplObj);
[ 2854] 
[ 2855]   template <typename DataT_, int Dimensions_> friend class local_accessor;
[ 2856] 
[ 2857] public:
[ 2858]   using value_type = DataT;
[ 2859]   using reference = DataT &;
[ 2860]   using const_reference = const DataT &;
[ 2861] 
[ 2862]   template <int Dims = Dimensions, typename = std::enable_if_t<Dims == 0>>
[ 2863]   local_accessor_base(handler &, const detail::code_location CodeLoc =
[ 2864]                                      detail::code_location::current())
[ 2865] #ifdef __SYCL_DEVICE_ONLY__
[ 2866]       : impl(range<AdjustedDim>{1}) {
[ 2867]     (void)CodeLoc;
[ 2868]   }
[ 2869] #else
[ 2870]       : LocalAccessorBaseHost(range<3>{1, 1, 1}, AdjustedDim, sizeof(DataT)) {
[ 2871]     detail::constructorNotification(nullptr, LocalAccessorBaseHost::impl.get(),
[ 2872]                                     access::target::local, AccessMode, CodeLoc);
[ 2873]     GDBMethodsAnchor();
[ 2874]   }
[ 2875] #endif
[ 2876] 
[ 2877]         template <int Dims = Dimensions, typename = std::enable_if_t<Dims == 0>>
[ 2878]         local_accessor_base(handler &, const property_list &propList,
[ 2879]                             const detail::code_location CodeLoc =
[ 2880]                                 detail::code_location::current())
[ 2881] #ifdef __SYCL_DEVICE_ONLY__
[ 2882]       : impl(range<AdjustedDim>{1}) {
[ 2883]     (void)propList;
[ 2884]     (void)CodeLoc;
[ 2885]   }
[ 2886] #else
[ 2887]       : LocalAccessorBaseHost(range<3>{1, 1, 1}, AdjustedDim, sizeof(DataT),
[ 2888]                               propList) {
[ 2889]     detail::constructorNotification(nullptr, LocalAccessorBaseHost::impl.get(),
[ 2890]                                     access::target::local, AccessMode, CodeLoc);
[ 2891]     GDBMethodsAnchor();
[ 2892]   }
[ 2893] #endif
[ 2894] 
[ 2895]   template <int Dims = Dimensions, typename = std::enable_if_t<(Dims > 0)>>
[ 2896]   local_accessor_base(
[ 2897]       range<Dimensions> AllocationSize, handler &,
[ 2898]       const detail::code_location CodeLoc = detail::code_location::current())
[ 2899] #ifdef __SYCL_DEVICE_ONLY__
[ 2900]       : impl(AllocationSize) {
[ 2901]     (void)CodeLoc;
[ 2902]   }
[ 2903] #else
[ 2904]       : LocalAccessorBaseHost(detail::convertToArrayOfN<3, 1>(AllocationSize),
[ 2905]                               AdjustedDim, sizeof(DataT)) {
[ 2906]     detail::constructorNotification(nullptr, LocalAccessorBaseHost::impl.get(),
[ 2907]                                     access::target::local, AccessMode, CodeLoc);
[ 2908]     GDBMethodsAnchor();
[ 2909]   }
[ 2910] #endif
[ 2911] 
[ 2912]         template <int Dims = Dimensions,
[ 2913]                   typename = std::enable_if_t<(Dims > 0)>>
[ 2914]         local_accessor_base(range<Dimensions> AllocationSize, handler &,
[ 2915]                             const property_list &propList,
[ 2916]                             const detail::code_location CodeLoc =
[ 2917]                                 detail::code_location::current())
[ 2918] #ifdef __SYCL_DEVICE_ONLY__
[ 2919]       : impl(AllocationSize) {
[ 2920]     (void)propList;
[ 2921]     (void)CodeLoc;
[ 2922]   }
[ 2923] #else
[ 2924]       : LocalAccessorBaseHost(detail::convertToArrayOfN<3, 1>(AllocationSize),
[ 2925]                               AdjustedDim, sizeof(DataT), propList) {
[ 2926]     detail::constructorNotification(nullptr, LocalAccessorBaseHost::impl.get(),
[ 2927]                                     access::target::local, AccessMode, CodeLoc);
[ 2928]     GDBMethodsAnchor();
[ 2929]   }
[ 2930] #endif
[ 2931] 
[ 2932]   size_t get_size() const { return getSize().size() * sizeof(DataT); }
[ 2933] 
[ 2934]   __SYCL2020_DEPRECATED("get_count() is deprecated, please use size() instead")
[ 2935]   size_t get_count() const { return size(); }
[ 2936]   size_t size() const noexcept { return getSize().size(); }
[ 2937] 
[ 2938]   template <int Dims = Dimensions, typename = std::enable_if_t<(Dims > 0)>>
[ 2939]   range<Dims> get_range() const {
[ 2940]     return detail::convertToArrayOfN<Dims, 1>(getSize());
[ 2941]   }
[ 2942] 
[ 2943]   template <int Dims = Dimensions,
[ 2944]             typename = std::enable_if_t<Dims == 0 &&
[ 2945]                                         (IsAccessAnyWrite || IsAccessReadOnly)>>
[ 2946]   operator RefType() const {
[ 2947]     return *getQualifiedPtr();
[ 2948]   }
[ 2949] 
[ 2950]   template <int Dims = Dimensions,
[ 2951]             typename = std::enable_if_t<(Dims > 0) &&
[ 2952]                                         (IsAccessAnyWrite || IsAccessReadOnly)>>
[ 2953]   RefType operator[](id<Dimensions> Index) const {
[ 2954]     const size_t LinearIndex = getLinearIndex(Index);
[ 2955]     return getQualifiedPtr()[LinearIndex];
[ 2956]   }
[ 2957] 
[ 2958]   template <int Dims = Dimensions,
[ 2959]             typename = std::enable_if_t<Dims == 1 &&
[ 2960]                                         (IsAccessAnyWrite || IsAccessReadOnly)>>
[ 2961]   RefType operator[](size_t Index) const {
[ 2962]     return getQualifiedPtr()[Index];
[ 2963]   }
[ 2964] 
[ 2965]   template <int Dims = Dimensions>
[ 2966]   operator typename std::enable_if_t<
[ 2967]       Dims == 0 && AccessMode == access::mode::atomic, atomic<DataT, AS>>()
[ 2968]       const {
[ 2969]     return atomic<DataT, AS>(
[ 2970]         multi_ptr<DataT, AS, access::decorated::yes>(getQualifiedPtr()));
[ 2971]   }
[ 2972] 
[ 2973]   template <int Dims = Dimensions>
[ 2974]   typename std::enable_if_t<(Dims > 0) && AccessMode == access::mode::atomic,
[ 2975]                             atomic<DataT, AS>>
[ 2976]   operator[](id<Dimensions> Index) const {
[ 2977]     const size_t LinearIndex = getLinearIndex(Index);
[ 2978]     return atomic<DataT, AS>(multi_ptr<DataT, AS, access::decorated::yes>(
[ 2979]         getQualifiedPtr() + LinearIndex));
[ 2980]   }
[ 2981] 
[ 2982]   template <int Dims = Dimensions>
[ 2983]   typename std::enable_if_t<Dims == 1 && AccessMode == access::mode::atomic,
[ 2984]                             atomic<DataT, AS>>
[ 2985]   operator[](size_t Index) const {
[ 2986]     return atomic<DataT, AS>(multi_ptr<DataT, AS, access::decorated::yes>(
[ 2987]         getQualifiedPtr() + Index));
[ 2988]   }
[ 2989] 
[ 2990]   template <int Dims = Dimensions, typename = std::enable_if_t<(Dims > 1)>>
[ 2991]   typename AccessorCommonT::template AccessorSubscript<
[ 2992]       Dims - 1,
[ 2993]       local_accessor_base<DataT, Dimensions, AccessMode, IsPlaceholder>>
[ 2994]   operator[](size_t Index) const {
[ 2995]     return AccessorSubscript<Dims - 1>(*this, Index);
[ 2996]   }
[ 2997] 
[ 2998]   bool operator==(const local_accessor_base &Rhs) const {
[ 2999]     return impl == Rhs.impl;
[ 3000]   }
[ 3001]   bool operator!=(const local_accessor_base &Rhs) const {
[ 3002]     return !(*this == Rhs);
[ 3003]   }
[ 3004] };
[ 3005] 
[ 3006] // TODO: Remove deprecated specialization once no longer needed
[ 3007] template <typename DataT, int Dimensions, access::mode AccessMode,
[ 3008]           access::placeholder IsPlaceholder>
[ 3009] class __SYCL_EBO __SYCL_SPECIAL_CLASS accessor<
[ 3010]     DataT, Dimensions, AccessMode, access::target::local, IsPlaceholder>
[ 3011]     : public local_accessor_base<DataT, Dimensions, AccessMode, IsPlaceholder>,
[ 3012]       public detail::OwnerLessBase<
[ 3013]           accessor<DataT, Dimensions, AccessMode, access::target::local,
[ 3014]                    IsPlaceholder>> {
[ 3015] 
[ 3016]   using local_acc =
[ 3017]       local_accessor_base<DataT, Dimensions, AccessMode, IsPlaceholder>;
[ 3018] 
[ 3019]   static_assert(
[ 3020]       !local_acc::IsConst || local_acc::IsAccessReadOnly,
[ 3021]       "A const qualified DataT is only allowed for a read-only accessor");
[ 3022] 
[ 3023]   // Use base classes constructors
[ 3024]   using local_acc::local_acc;
[ 3025] 
[ 3026] public:
[ 3027]   local_ptr<DataT> get_pointer() const {
[ 3028]     return local_ptr<DataT>(local_acc::getQualifiedPtr());
[ 3029]   }
[ 3030] 
[ 3031] #ifdef __SYCL_DEVICE_ONLY__
[ 3032] 
[ 3033]   // __init needs to be defined within the class not through inheritance.
[ 3034]   // Map this function to inherited func.
[ 3035]   void __init(typename local_acc::ConcreteASPtrType Ptr,
[ 3036]               range<local_acc::AdjustedDim> AccessRange,
[ 3037]               range<local_acc::AdjustedDim> range,
[ 3038]               id<local_acc::AdjustedDim> id) {
[ 3039]     local_acc::__init(Ptr, AccessRange, range, id);
[ 3040]   }
[ 3041] 
[ 3042]   // __init variant used by the device compiler for ESIMD kernels.
[ 3043]   // TODO: In ESIMD accessors usage is limited for now - access range, mem
[ 3044]   // range and offset are not supported.
[ 3045]   void __init_esimd(typename local_acc::ConcreteASPtrType Ptr) {
[ 3046]     local_acc::__init_esimd(Ptr);
[ 3047]   }
[ 3048] 
[ 3049] public:
[ 3050]   // Default constructor for objects later initialized with __init member.
[ 3051]   accessor() {
[ 3052]     local_acc::impl = detail::InitializedVal<local_acc::AdjustedDim,
[ 3053]                                              range>::template get<0>();
[ 3054]   }
[ 3055] 
[ 3056] #else
[ 3057] private:
[ 3058]   accessor(const detail::AccessorImplPtr &Impl) : local_acc{Impl} {}
[ 3059] #endif
[ 3060] };
[ 3061] 
[ 3062] template <typename DataT, int Dimensions = 1>
[ 3063] class __SYCL_EBO __SYCL_SPECIAL_CLASS __SYCL_TYPE(local_accessor) local_accessor
[ 3064]     : public local_accessor_base<DataT, Dimensions,
[ 3065]                                  detail::accessModeFromConstness<DataT>(),
[ 3066]                                  access::placeholder::false_t>,
[ 3067]       public detail::OwnerLessBase<local_accessor<DataT, Dimensions>> {
[ 3068] 
[ 3069]   using local_acc =
[ 3070]       local_accessor_base<DataT, Dimensions,
[ 3071]                           detail::accessModeFromConstness<DataT>(),
[ 3072]                           access::placeholder::false_t>;
[ 3073] 
[ 3074]   static_assert(
[ 3075]       !local_acc::IsConst || local_acc::IsAccessReadOnly,
[ 3076]       "A const qualified DataT is only allowed for a read-only accessor");
[ 3077] 
[ 3078]   // Use base classes constructors
[ 3079]   using local_acc::local_acc;
[ 3080] 
[ 3081] #ifdef __SYCL_DEVICE_ONLY__
[ 3082] 
[ 3083]   // __init needs to be defined within the class not through inheritance.
[ 3084]   // Map this function to inherited func.
[ 3085]   void __init(typename local_acc::ConcreteASPtrType Ptr,
[ 3086]               range<local_acc::AdjustedDim> AccessRange,
[ 3087]               range<local_acc::AdjustedDim> range,
[ 3088]               id<local_acc::AdjustedDim> id) {
[ 3089]     local_acc::__init(Ptr, AccessRange, range, id);
[ 3090]   }
[ 3091] 
[ 3092]   // __init variant used by the device compiler for ESIMD kernels.
[ 3093]   // TODO: In ESIMD accessors usage is limited for now - access range, mem
[ 3094]   // range and offset are not supported.
[ 3095]   void __init_esimd(typename local_acc::ConcreteASPtrType Ptr) {
[ 3096]     local_acc::__init_esimd(Ptr);
[ 3097]   }
[ 3098] 
[ 3099] public:
[ 3100]   // Default constructor for objects later initialized with __init member.
[ 3101]   local_accessor() {
[ 3102]     local_acc::impl = detail::InitializedVal<local_acc::AdjustedDim,
[ 3103]                                              range>::template get<0>();
[ 3104]   }
[ 3105] 
[ 3106] #else
[ 3107]   local_accessor(const detail::AccessorImplPtr &Impl) : local_acc{Impl} {}
[ 3108] #endif
[ 3109] 
[ 3110]   // implicit conversion between non-const read-write accessor to const
[ 3111]   // read-only accessor
[ 3112] public:
[ 3113]   template <typename DataT_,
[ 3114]             typename = std::enable_if_t<
[ 3115]                 std::is_const_v<DataT> &&
[ 3116]                 std::is_same_v<DataT_, std::remove_const_t<DataT>>>>
[ 3117]   local_accessor(const local_accessor<DataT_, Dimensions> &other) {
[ 3118]     local_acc::impl = other.impl;
[ 3119] #ifdef __SYCL_DEVICE_ONLY__
[ 3120]     local_acc::MData = other.MData;
[ 3121] #endif
[ 3122]   }
[ 3123] 
[ 3124]   using value_type = DataT;
[ 3125]   using iterator = value_type *;
[ 3126]   using const_iterator = const value_type *;
[ 3127]   using reverse_iterator = std::reverse_iterator<iterator>;
[ 3128]   using const_reverse_iterator = std::reverse_iterator<const_iterator>;
[ 3129]   using difference_type =
[ 3130]       typename std::iterator_traits<iterator>::difference_type;
[ 3131]   using size_type = std::size_t;
[ 3132] 
[ 3133]   template <access::decorated IsDecorated>
[ 3134]   using accessor_ptr = local_ptr<value_type, IsDecorated>;
[ 3135] 
[ 3136]   template <typename DataT_>
[ 3137]   bool operator==(const local_accessor<DataT_, Dimensions> &Rhs) const {
[ 3138]     return local_acc::impl == Rhs.impl;
[ 3139]   }
[ 3140] 
[ 3141]   template <typename DataT_>
[ 3142]   bool operator!=(const local_accessor<DataT_, Dimensions> &Rhs) const {
[ 3143]     return !(*this == Rhs);
[ 3144]   }
[ 3145] 
[ 3146]   void swap(local_accessor &other) { std::swap(this->impl, other.impl); }
[ 3147] 
[ 3148]   size_type byte_size() const noexcept { return this->size() * sizeof(DataT); }
[ 3149] 
[ 3150]   size_type max_size() const noexcept {
[ 3151]     return empty() ? 0 : (std::numeric_limits<difference_type>::max)();
[ 3152]   }
[ 3153] 
[ 3154]   bool empty() const noexcept { return this->size() == 0; }
[ 3155] 
[ 3156]   iterator begin() const noexcept {
[ 3157]     if constexpr (Dimensions == 0)
[ 3158]       return local_acc::getQualifiedPtr();
[ 3159]     else
[ 3160]       return &this->operator[](id<Dimensions>());
[ 3161]   }
[ 3162]   iterator end() const noexcept {
[ 3163]     if constexpr (Dimensions == 0)
[ 3164]       return begin() + 1;
[ 3165]     else
[ 3166]       return begin() + this->size();
[ 3167]   }
[ 3168] 
[ 3169]   const_iterator cbegin() const noexcept { return const_iterator(begin()); }
[ 3170]   const_iterator cend() const noexcept { return const_iterator(end()); }
[ 3171] 
[ 3172]   reverse_iterator rbegin() const noexcept { return reverse_iterator(end()); }
[ 3173]   reverse_iterator rend() const noexcept { return reverse_iterator(begin()); }
[ 3174] 
[ 3175]   const_reverse_iterator crbegin() const noexcept {
[ 3176]     return const_reverse_iterator(end());
[ 3177]   }
[ 3178]   const_reverse_iterator crend() const noexcept {
[ 3179]     return const_reverse_iterator(begin());
[ 3180]   }
[ 3181] 
[ 3182]   __SYCL2020_DEPRECATED(
[ 3183]       "local_accessor::get_pointer() is deprecated, please use get_multi_ptr()")
[ 3184]   local_ptr<DataT> get_pointer() const noexcept {
[ 3185]     return local_ptr<DataT>(local_acc::getQualifiedPtr());
[ 3186]   }
[ 3187] 
[ 3188]   template <access::decorated IsDecorated>
[ 3189]   accessor_ptr<IsDecorated> get_multi_ptr() const noexcept {
[ 3190]     return accessor_ptr<IsDecorated>(local_acc::getQualifiedPtr());
[ 3191]   }
[ 3192] 
[ 3193]   template <typename Property> bool has_property() const noexcept {
[ 3194] #ifndef __SYCL_DEVICE_ONLY__
[ 3195]     return this->getPropList().template has_property<Property>();
[ 3196] #else
[ 3197]     return false;
[ 3198] #endif
[ 3199]   }
[ 3200] 
[ 3201]   template <typename Property> Property get_property() const {
[ 3202] #ifndef __SYCL_DEVICE_ONLY__
[ 3203]     return this->getPropList().template get_property<Property>();
[ 3204] #else
[ 3205]     return Property();
[ 3206] #endif
[ 3207]   }
[ 3208] 
[ 3209]   template <int Dims = Dimensions,
[ 3210]             typename = std::enable_if_t<!std::is_const_v<DataT> && Dims == 0>>
[ 3211]   const local_accessor &operator=(const value_type &Other) const {
[ 3212]     *local_acc::getQualifiedPtr() = Other;
[ 3213]     return *this;
[ 3214]   }
[ 3215] 
[ 3216]   template <int Dims = Dimensions,
[ 3217]             typename = std::enable_if_t<!std::is_const_v<DataT> && Dims == 0>>
[ 3218]   const local_accessor &operator=(value_type &&Other) const {
[ 3219]     *local_acc::getQualifiedPtr() = std::move(Other);
[ 3220]     return *this;
[ 3221]   }
[ 3222] 
[ 3223] private:
[ 3224]   friend class sycl::ext::intel::esimd::detail::AccessorPrivateProxy;
[ 3225] };
[ 3226] 
[ 3227] /// Image accessors.
[ 3228] ///
[ 3229] /// Available only when accessTarget == access::target::image.
[ 3230] ///
[ 3231] /// \ingroup sycl_api_acc
[ 3232] template <typename DataT, int Dimensions, access::mode AccessMode,
[ 3233]           access::placeholder IsPlaceholder>
[ 3234] class __SYCL_EBO __SYCL_SPECIAL_CLASS __SYCL_TYPE(accessor) accessor<
[ 3235]     DataT, Dimensions, AccessMode, access::target::image, IsPlaceholder>
[ 3236]     : public detail::image_accessor<DataT, Dimensions, AccessMode,
[ 3237]                                     access::target::image, IsPlaceholder>,
[ 3238]       public detail::OwnerLessBase<
[ 3239]           accessor<DataT, Dimensions, AccessMode, access::target::image,
[ 3240]                    IsPlaceholder>> {
[ 3241] private:
[ 3242]   accessor(const detail::AccessorImplPtr &Impl)
[ 3243]       : detail::image_accessor<DataT, Dimensions, AccessMode,
[ 3244]                                access::target::image, IsPlaceholder>{Impl} {}
[ 3245] 
[ 3246] public:
[ 3247]   template <typename AllocatorT>
[ 3248]   accessor(sycl::image<Dimensions, AllocatorT> &Image,
[ 3249]            handler &CommandGroupHandler)
[ 3250]       : detail::image_accessor<DataT, Dimensions, AccessMode,
[ 3251]                                access::target::image, IsPlaceholder>(
[ 3252]             Image, CommandGroupHandler, Image.getElementSize()) {
[ 3253] #ifndef __SYCL_DEVICE_ONLY__
[ 3254]     detail::associateWithHandler(CommandGroupHandler, this,
[ 3255]                                  access::target::image);
[ 3256] #endif
[ 3257]   }
[ 3258] 
[ 3259]   template <typename AllocatorT>
[ 3260]   accessor(sycl::image<Dimensions, AllocatorT> &Image,
[ 3261]            handler &CommandGroupHandler, const property_list &propList)
[ 3262]       : detail::image_accessor<DataT, Dimensions, AccessMode,
[ 3263]                                access::target::image, IsPlaceholder>(
[ 3264]             Image, CommandGroupHandler, Image.getElementSize()) {
[ 3265]     (void)propList;
[ 3266] #ifndef __SYCL_DEVICE_ONLY__
[ 3267]     detail::associateWithHandler(CommandGroupHandler, this,
[ 3268]                                  access::target::image);
[ 3269] #endif
[ 3270]   }
[ 3271] #ifdef __SYCL_DEVICE_ONLY__
[ 3272] private:
[ 3273]   using OCLImageTy =
[ 3274]       typename detail::opencl_image_type<Dimensions, AccessMode,
[ 3275]                                          access::target::image>::type;
[ 3276] 
[ 3277]   // Front End requires this method to be defined in the accessor class.
[ 3278]   // It does not call the base class's init method.
[ 3279]   void __init(OCLImageTy Image) { this->imageAccessorInit(Image); }
[ 3280] 
[ 3281]   // __init variant used by the device compiler for ESIMD kernels.
[ 3282]   void __init_esimd(OCLImageTy Image) { this->imageAccessorInit(Image); }
[ 3283] 
[ 3284] public:
[ 3285]   // Default constructor for objects later initialized with __init member.
[ 3286]   accessor() = default;
[ 3287] #endif
[ 3288] };
[ 3289] 
[ 3290] /// Host image accessor.
[ 3291] ///
[ 3292] /// Available only when accessTarget == access::target::host_image.
[ 3293] ///
[ 3294] /// \sa image
[ 3295] ///
[ 3296] /// \ingroup sycl_api_acc
[ 3297] template <typename DataT, int Dimensions, access::mode AccessMode,
[ 3298]           access::placeholder IsPlaceholder>
[ 3299] class __SYCL_EBO accessor<DataT, Dimensions, AccessMode,
[ 3300]                           access::target::host_image, IsPlaceholder>
[ 3301]     : public detail::image_accessor<DataT, Dimensions, AccessMode,
[ 3302]                                     access::target::host_image, IsPlaceholder>,
[ 3303]       public detail::OwnerLessBase<
[ 3304]           accessor<DataT, Dimensions, AccessMode, access::target::host_image,
[ 3305]                    IsPlaceholder>> {
[ 3306] public:
[ 3307]   template <typename AllocatorT>
[ 3308]   accessor(sycl::image<Dimensions, AllocatorT> &Image)
[ 3309]       : detail::image_accessor<DataT, Dimensions, AccessMode,
[ 3310]                                access::target::host_image, IsPlaceholder>(
[ 3311]             Image, Image.getElementSize()) {}
[ 3312] 
[ 3313]   template <typename AllocatorT>
[ 3314]   accessor(sycl::image<Dimensions, AllocatorT> &Image,
[ 3315]            const property_list &propList)
[ 3316]       : detail::image_accessor<DataT, Dimensions, AccessMode,
[ 3317]                                access::target::host_image, IsPlaceholder>(
[ 3318]             Image, Image.getElementSize()) {
[ 3319]     (void)propList;
[ 3320]   }
[ 3321] };
[ 3322] 
[ 3323] /// Image array accessor.
[ 3324] ///
[ 3325] /// Available only when accessTarget == access::target::image_array and
[ 3326] /// dimensions < 3.
[ 3327] ///
[ 3328] /// \sa image
[ 3329] ///
[ 3330] /// \ingroup sycl_api_acc
[ 3331] template <typename DataT, int Dimensions, access::mode AccessMode,
[ 3332]           access::placeholder IsPlaceholder>
[ 3333] class __SYCL_EBO __SYCL_SPECIAL_CLASS __SYCL_TYPE(accessor) accessor<
[ 3334]     DataT, Dimensions, AccessMode, access::target::image_array, IsPlaceholder>
[ 3335]     : public detail::image_accessor<DataT, Dimensions + 1, AccessMode,
[ 3336]                                     access::target::image, IsPlaceholder>,
[ 3337]       public detail::OwnerLessBase<
[ 3338]           accessor<DataT, Dimensions, AccessMode, access::target::image_array,
[ 3339]                    IsPlaceholder>> {
[ 3340] #ifdef __SYCL_DEVICE_ONLY__
[ 3341] private:
[ 3342]   using OCLImageTy =
[ 3343]       typename detail::opencl_image_type<Dimensions + 1, AccessMode,
[ 3344]                                          access::target::image>::type;
[ 3345] 
[ 3346]   // Front End requires this method to be defined in the accessor class.
[ 3347]   // It does not call the base class's init method.
[ 3348]   void __init(OCLImageTy Image) { this->imageAccessorInit(Image); }
[ 3349] 
[ 3350]   // __init variant used by the device compiler for ESIMD kernels.
[ 3351]   void __init_esimd(OCLImageTy Image) { this->imageAccessorInit(Image); }
[ 3352] 
[ 3353] public:
[ 3354]   // Default constructor for objects later initialized with __init member.
[ 3355]   accessor() = default;
[ 3356] #endif
[ 3357] public:
[ 3358]   template <typename AllocatorT>
[ 3359]   accessor(sycl::image<Dimensions + 1, AllocatorT> &Image,
[ 3360]            handler &CommandGroupHandler)
[ 3361]       : detail::image_accessor<DataT, Dimensions + 1, AccessMode,
[ 3362]                                access::target::image, IsPlaceholder>(
[ 3363]             Image, CommandGroupHandler, Image.getElementSize()) {
[ 3364] #ifndef __SYCL_DEVICE_ONLY__
[ 3365]     detail::associateWithHandler(CommandGroupHandler, this,
[ 3366]                                  access::target::image_array);
[ 3367] #endif
[ 3368]   }
[ 3369] 
[ 3370]   template <typename AllocatorT>
[ 3371]   accessor(sycl::image<Dimensions + 1, AllocatorT> &Image,
[ 3372]            handler &CommandGroupHandler, const property_list &propList)
[ 3373]       : detail::image_accessor<DataT, Dimensions + 1, AccessMode,
[ 3374]                                access::target::image, IsPlaceholder>(
[ 3375]             Image, CommandGroupHandler, Image.getElementSize()) {
[ 3376]     (void)propList;
[ 3377] #ifndef __SYCL_DEVICE_ONLY__
[ 3378]     detail::associateWithHandler(CommandGroupHandler, this,
[ 3379]                                  access::target::image_array);
[ 3380] #endif
[ 3381]   }
[ 3382] 
[ 3383]   detail::__image_array_slice__<DataT, Dimensions, AccessMode, IsPlaceholder>
[ 3384]   operator[](size_t Index) const {
[ 3385]     return detail::__image_array_slice__<DataT, Dimensions, AccessMode,
[ 3386]                                          IsPlaceholder>(*this, Index);
[ 3387]   }
[ 3388] };
[ 3389] 
[ 3390] template <typename DataT, int Dimensions = 1,
[ 3391]           access_mode AccessMode = access_mode::read_write>
[ 3392] class __SYCL_EBO host_accessor
[ 3393]     : public accessor<DataT, Dimensions, AccessMode, target::host_buffer,
[ 3394]                       access::placeholder::false_t> {
[ 3395] protected:
[ 3396]   using AccessorT = accessor<DataT, Dimensions, AccessMode, target::host_buffer,
[ 3397]                              access::placeholder::false_t>;
[ 3398] 
[ 3399]   constexpr static int AdjustedDim = Dimensions == 0 ? 1 : Dimensions;
[ 3400]   constexpr static bool IsAccessReadOnly = AccessMode == access::mode::read;
[ 3401] 
[ 3402]   template <typename T, int Dims>
[ 3403]   struct IsSameAsBuffer
[ 3404]       : std::bool_constant<std::is_same_v<T, DataT> && (Dims > 0) &&
[ 3405]                            (Dims == Dimensions)> {};
[ 3406] 
[ 3407]   void
[ 3408]   __init(typename accessor<DataT, Dimensions, AccessMode, target::host_buffer,
[ 3409]                            access::placeholder::false_t>::ConcreteASPtrType Ptr,
[ 3410]          range<AdjustedDim> AccessRange, range<AdjustedDim> MemRange,
[ 3411]          id<AdjustedDim> Offset) {
[ 3412]     AccessorT::__init(Ptr, AccessRange, MemRange, Offset);
[ 3413]   }
[ 3414] 
[ 3415] #ifndef __SYCL_DEVICE_ONLY__
[ 3416]   host_accessor(const detail::AccessorImplPtr &Impl)
[ 3417]       : accessor<DataT, Dimensions, AccessMode, target::host_buffer,
[ 3418]                  access::placeholder::false_t>{Impl} {}
[ 3419] 
[ 3420]   template <class Obj>
[ 3421]   friend decltype(Obj::impl) getSyclObjImpl(const Obj &SyclObject);
[ 3422] 
[ 3423]   template <class T>
[ 3424]   friend T detail::createSyclObjFromImpl(decltype(T::impl) ImplObj);
[ 3425] #endif // __SYCL_DEVICE_ONLY__
[ 3426] 
[ 3427] public:
[ 3428]   host_accessor() : AccessorT() {}
[ 3429] 
[ 3430]   // The list of host_accessor constructors with their arguments
[ 3431]   // -------+---------+-------+----+----------+--------------
[ 3432]   // Dimensions = 0
[ 3433]   // -------+---------+-------+----+----------+--------------
[ 3434]   // buffer |         |       |    |          | property_list
[ 3435]   // buffer | handler |       |    |          | property_list
[ 3436]   // -------+---------+-------+----+----------+--------------
[ 3437]   // Dimensions >= 1
[ 3438]   // -------+---------+-------+----+----------+--------------
[ 3439]   // buffer |         |       |    |          | property_list
[ 3440]   // buffer |         |       |    | mode_tag | property_list
[ 3441]   // buffer | handler |       |    |          | property_list
[ 3442]   // buffer | handler |       |    | mode_tag | property_list
[ 3443]   // buffer |         | range |    |          | property_list
[ 3444]   // buffer |         | range |    | mode_tag | property_list
[ 3445]   // buffer | handler | range |    |          | property_list
[ 3446]   // buffer | handler | range |    | mode_tag | property_list
[ 3447]   // buffer |         | range | id |          | property_list
[ 3448]   // buffer |         | range | id | mode_tag | property_list
[ 3449]   // buffer | handler | range | id |          | property_list
[ 3450]   // buffer | handler | range | id | mode_tag | property_list
[ 3451]   // -------+---------+-------+----+----------+--------------
[ 3452] 
[ 3453]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3454]             typename = typename std::enable_if_t<std::is_same_v<T, DataT> &&
[ 3455]                                                  Dims == 0>>
[ 3456]   host_accessor(
[ 3457]       buffer<T, 1, AllocatorT> &BufferRef,
[ 3458]       const property_list &PropertyList = {},
[ 3459]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3460]       : AccessorT(BufferRef, PropertyList, CodeLoc) {}
[ 3461] 
[ 3462]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3463]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3464]   host_accessor(
[ 3465]       buffer<T, Dims, AllocatorT> &BufferRef,
[ 3466]       const property_list &PropertyList = {},
[ 3467]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3468]       : AccessorT(BufferRef, PropertyList, CodeLoc) {}
[ 3469] 
[ 3470]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3471]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3472]   host_accessor(
[ 3473]       buffer<T, Dims, AllocatorT> &BufferRef, mode_tag_t<AccessMode>,
[ 3474]       const property_list &PropertyList = {},
[ 3475]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3476]       : host_accessor(BufferRef, PropertyList, CodeLoc) {}
[ 3477] 
[ 3478]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3479]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3480]   host_accessor(
[ 3481]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 3482]       const property_list &PropertyList = {},
[ 3483]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3484]       : AccessorT(BufferRef, CommandGroupHandler, PropertyList, CodeLoc) {}
[ 3485] 
[ 3486]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3487]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3488]   host_accessor(
[ 3489]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 3490]       mode_tag_t<AccessMode>, const property_list &PropertyList = {},
[ 3491]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3492]       : host_accessor(BufferRef, CommandGroupHandler, PropertyList, CodeLoc) {}
[ 3493] 
[ 3494]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3495]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3496]   host_accessor(
[ 3497]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 3498]       const property_list &PropertyList = {},
[ 3499]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3500]       : AccessorT(BufferRef, AccessRange, {}, PropertyList, CodeLoc) {}
[ 3501] 
[ 3502]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3503]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3504]   host_accessor(
[ 3505]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 3506]       mode_tag_t<AccessMode>, const property_list &PropertyList = {},
[ 3507]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3508]       : host_accessor(BufferRef, AccessRange, {}, PropertyList, CodeLoc) {}
[ 3509] 
[ 3510]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3511]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3512]   host_accessor(
[ 3513]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 3514]       range<Dimensions> AccessRange, const property_list &PropertyList = {},
[ 3515]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3516]       : AccessorT(BufferRef, CommandGroupHandler, AccessRange, {}, PropertyList,
[ 3517]                   CodeLoc) {}
[ 3518] 
[ 3519]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3520]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3521]   host_accessor(
[ 3522]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 3523]       range<Dimensions> AccessRange, mode_tag_t<AccessMode>,
[ 3524]       const property_list &PropertyList = {},
[ 3525]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3526]       : host_accessor(BufferRef, CommandGroupHandler, AccessRange, {},
[ 3527]                       PropertyList, CodeLoc) {}
[ 3528] 
[ 3529]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3530]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3531]   host_accessor(
[ 3532]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 3533]       id<Dimensions> AccessOffset, const property_list &PropertyList = {},
[ 3534]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3535]       : AccessorT(BufferRef, AccessRange, AccessOffset, PropertyList, CodeLoc) {
[ 3536]   }
[ 3537] 
[ 3538]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3539]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3540]   host_accessor(
[ 3541]       buffer<T, Dims, AllocatorT> &BufferRef, range<Dimensions> AccessRange,
[ 3542]       id<Dimensions> AccessOffset, mode_tag_t<AccessMode>,
[ 3543]       const property_list &PropertyList = {},
[ 3544]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3545]       : host_accessor(BufferRef, AccessRange, AccessOffset, PropertyList,
[ 3546]                       CodeLoc) {}
[ 3547] 
[ 3548]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3549]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3550]   host_accessor(
[ 3551]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 3552]       range<Dimensions> AccessRange, id<Dimensions> AccessOffset,
[ 3553]       const property_list &PropertyList = {},
[ 3554]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3555]       : AccessorT(BufferRef, CommandGroupHandler, AccessRange, AccessOffset,
[ 3556]                   PropertyList, CodeLoc) {}
[ 3557] 
[ 3558]   template <typename T = DataT, int Dims = Dimensions, typename AllocatorT,
[ 3559]             typename = std::enable_if_t<IsSameAsBuffer<T, Dims>::value>>
[ 3560]   host_accessor(
[ 3561]       buffer<T, Dims, AllocatorT> &BufferRef, handler &CommandGroupHandler,
[ 3562]       range<Dimensions> AccessRange, id<Dimensions> AccessOffset,
[ 3563]       mode_tag_t<AccessMode>, const property_list &PropertyList = {},
[ 3564]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3565]       : host_accessor(BufferRef, CommandGroupHandler, AccessRange, AccessOffset,
[ 3566]                       PropertyList, CodeLoc) {}
[ 3567] 
[ 3568]   template <int Dims = Dimensions,
[ 3569]             typename = std::enable_if_t<AccessMode != access_mode::atomic &&
[ 3570]                                         !IsAccessReadOnly && Dims == 0>>
[ 3571]   const host_accessor &
[ 3572]   operator=(const typename AccessorT::value_type &Other) const {
[ 3573]     *AccessorT::getQualifiedPtr() = Other;
[ 3574]     return *this;
[ 3575]   }
[ 3576] 
[ 3577]   template <int Dims = Dimensions,
[ 3578]             typename = std::enable_if_t<AccessMode != access_mode::atomic &&
[ 3579]                                         !IsAccessReadOnly && Dims == 0>>
[ 3580]   const host_accessor &operator=(typename AccessorT::value_type &&Other) const {
[ 3581]     *AccessorT::getQualifiedPtr() = std::move(Other);
[ 3582]     return *this;
[ 3583]   }
[ 3584] 
[ 3585]   // implicit conversion between const / non-const types for read only accessors
[ 3586]   template <typename DataT_,
[ 3587]             typename = std::enable_if_t<
[ 3588]                 IsAccessReadOnly && !std::is_same_v<DataT_, DataT> &&
[ 3589]                 std::is_same_v<std::remove_const_t<DataT_>,
[ 3590]                                std::remove_const_t<DataT>>>>
[ 3591]   host_accessor(const host_accessor<DataT_, Dimensions, AccessMode> &other)
[ 3592] #ifndef __SYCL_DEVICE_ONLY__
[ 3593]       : host_accessor(other.impl) {
[ 3594]     AccessorT::MAccData = other.MAccData;
[ 3595] #else
[ 3596]   {
[ 3597]     (void)other;
[ 3598] #endif // __SYCL_DEVICE_ONLY__
[ 3599]   }
[ 3600] 
[ 3601]   // implicit conversion from read_write T accessor to read only T (const)
[ 3602]   // accessor
[ 3603]   template <typename DataT_, access::mode AccessMode_,
[ 3604]             typename = std::enable_if_t<
[ 3605]                 (AccessMode_ == access_mode::read_write) && IsAccessReadOnly &&
[ 3606]                 std::is_same_v<DataT_, std::remove_const_t<DataT>>>>
[ 3607]   host_accessor(const host_accessor<DataT_, Dimensions, AccessMode_> &other)
[ 3608] #ifndef __SYCL_DEVICE_ONLY__
[ 3609]       : host_accessor(other.impl) {
[ 3610]     AccessorT::MAccData = other.MAccData;
[ 3611] #else
[ 3612]   {
[ 3613]     (void)other;
[ 3614] #endif // __SYCL_DEVICE_ONLY__
[ 3615]   }
[ 3616] 
[ 3617]   // host_accessor needs to explicitly define the owner_before member functions
[ 3618]   // as inheriting from OwnerLessBase causes base class conflicts.
[ 3619]   // TODO: Once host_accessor is detached from accessor, inherit from
[ 3620]   // OwnerLessBase instead.
[ 3621] #ifndef __SYCL_DEVICE_ONLY__
[ 3622]   bool ext_oneapi_owner_before(
[ 3623]       const ext::oneapi::detail::weak_object_base<host_accessor> &Other)
[ 3624]       const noexcept {
[ 3625]     return this->impl.owner_before(
[ 3626]         ext::oneapi::detail::getSyclWeakObjImpl(Other));
[ 3627]   }
[ 3628] 
[ 3629]   bool ext_oneapi_owner_before(const host_accessor &Other) const noexcept {
[ 3630]     return this->impl.owner_before(Other.impl);
[ 3631]   }
[ 3632] #else
[ 3633]   bool ext_oneapi_owner_before(
[ 3634]       const ext::oneapi::detail::weak_object_base<host_accessor> &Other)
[ 3635]       const noexcept;
[ 3636]   bool ext_oneapi_owner_before(const host_accessor &Other) const noexcept;
[ 3637] #endif
[ 3638] };
[ 3639] 
[ 3640] template <typename DataT, int Dimensions, typename AllocatorT>
[ 3641] host_accessor(buffer<DataT, Dimensions, AllocatorT>)
[ 3642]     -> host_accessor<DataT, Dimensions, access::mode::read_write>;
[ 3643] 
[ 3644] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1>
[ 3645] host_accessor(buffer<DataT, Dimensions, AllocatorT>, Type1)
[ 3646]     -> host_accessor<DataT, Dimensions,
[ 3647]                      detail::deduceAccessMode<Type1, Type1>()>;
[ 3648] 
[ 3649] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 3650]           typename Type2>
[ 3651] host_accessor(buffer<DataT, Dimensions, AllocatorT>, Type1, Type2)
[ 3652]     -> host_accessor<DataT, Dimensions,
[ 3653]                      detail::deduceAccessMode<Type1, Type2>()>;
[ 3654] 
[ 3655] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 3656]           typename Type2, typename Type3>
[ 3657] host_accessor(buffer<DataT, Dimensions, AllocatorT>, Type1, Type2, Type3)
[ 3658]     -> host_accessor<DataT, Dimensions,
[ 3659]                      detail::deduceAccessMode<Type2, Type3>()>;
[ 3660] 
[ 3661] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 3662]           typename Type2, typename Type3, typename Type4>
[ 3663] host_accessor(buffer<DataT, Dimensions, AllocatorT>, Type1, Type2, Type3, Type4)
[ 3664]     -> host_accessor<DataT, Dimensions,
[ 3665]                      detail::deduceAccessMode<Type3, Type4>()>;
[ 3666] 
[ 3667] template <typename DataT, int Dimensions, typename AllocatorT, typename Type1,
[ 3668]           typename Type2, typename Type3, typename Type4, typename Type5>
[ 3669] host_accessor(buffer<DataT, Dimensions, AllocatorT>, Type1, Type2, Type3, Type4,
[ 3670]               Type5) -> host_accessor<DataT, Dimensions,
[ 3671]                                       detail::deduceAccessMode<Type4, Type5>()>;
[ 3672] 
[ 3673] // SYCL 2020 image accessors
[ 3674] 
[ 3675] template <typename DataT, int Dimensions, access_mode AccessMode,
[ 3676]           image_target AccessTarget = image_target::device>
[ 3677] class __SYCL_EBO unsampled_image_accessor :
[ 3678] #ifndef __SYCL_DEVICE_ONLY__
[ 3679]     private detail::UnsampledImageAccessorBaseHost,
[ 3680] #endif // __SYCL_DEVICE_ONLY__
[ 3681]     public detail::OwnerLessBase<
[ 3682]         unsampled_image_accessor<DataT, Dimensions, AccessMode, AccessTarget>> {
[ 3683]   static_assert(std::is_same_v<DataT, int4> || std::is_same_v<DataT, uint4> ||
[ 3684]                     std::is_same_v<DataT, float4> ||
[ 3685]                     std::is_same_v<DataT, half4>,
[ 3686]                 "The data type of an image accessor must be only int4, "
[ 3687]                 "uint4, float4 or half4 from SYCL namespace");
[ 3688]   static_assert(AccessMode == access_mode::read ||
[ 3689]                     AccessMode == access_mode::write,
[ 3690]                 "Access mode must be either read or write.");
[ 3691] 
[ 3692] #ifdef __SYCL_DEVICE_ONLY__
[ 3693]   char MPadding[sizeof(detail::UnsampledImageAccessorBaseHost)];
[ 3694] #else
[ 3695]   using host_base_class = detail::UnsampledImageAccessorBaseHost;
[ 3696] #endif // __SYCL_DEVICE_ONLY__
[ 3697] 
[ 3698] public:
[ 3699]   using value_type = typename std::conditional<AccessMode == access_mode::read,
[ 3700]                                                const DataT, DataT>::type;
[ 3701]   using reference = value_type &;
[ 3702]   using const_reference = const DataT &;
[ 3703] 
[ 3704]   template <typename AllocatorT>
[ 3705]   unsampled_image_accessor(
[ 3706]       unsampled_image<Dimensions, AllocatorT> &ImageRef,
[ 3707]       handler &CommandGroupHandlerRef, const property_list &PropList = {},
[ 3708]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3709] #ifdef __SYCL_DEVICE_ONLY__
[ 3710]   {
[ 3711]     (void)ImageRef;
[ 3712]     (void)CommandGroupHandlerRef;
[ 3713]     (void)PropList;
[ 3714]     (void)CodeLoc;
[ 3715]   }
[ 3716] #else
[ 3717]       : host_base_class(detail::convertToArrayOfN<3, 1>(ImageRef.get_range()),
[ 3718]                         AccessMode, detail::getSyclObjImpl(ImageRef).get(),
[ 3719]                         Dimensions, ImageRef.getElementSize(),
[ 3720]                         {ImageRef.getRowPitch(), ImageRef.getSlicePitch(), 0},
[ 3721]                         ImageRef.getChannelType(), ImageRef.getChannelOrder(),
[ 3722]                         PropList) {
[ 3723]     device Device = detail::getDeviceFromHandler(CommandGroupHandlerRef);
[ 3724]     // Avoid aspect::image warning.
[ 3725]     aspect ImageAspect = aspect::image;
[ 3726]     if (AccessTarget == image_target::device && !Device.has(ImageAspect))
[ 3727]       throw sycl::exception(
[ 3728]           sycl::make_error_code(sycl::errc::feature_not_supported),
[ 3729]           "Device associated with command group handler does not have "
[ 3730]           "aspect::image.");
[ 3731] 
[ 3732]     detail::unsampledImageConstructorNotification(
[ 3733]         detail::getSyclObjImpl(ImageRef).get(), this->impl.get(), AccessTarget,
[ 3734]         AccessMode, (const void *)typeid(DataT).name(), sizeof(DataT), CodeLoc);
[ 3735]     detail::associateWithHandler(CommandGroupHandlerRef, this, AccessTarget);
[ 3736]     GDBMethodsAnchor();
[ 3737]   }
[ 3738] #endif // __SYCL_DEVICE_ONLY__
[ 3739] 
[ 3740]   /* -- common interface members -- */
[ 3741] 
[ 3742]   unsampled_image_accessor(const unsampled_image_accessor &Rhs) = default;
[ 3743] 
[ 3744]   unsampled_image_accessor(unsampled_image_accessor &&Rhs) = default;
[ 3745] 
[ 3746]   unsampled_image_accessor &
[ 3747]   operator=(const unsampled_image_accessor &Rhs) = default;
[ 3748] 
[ 3749]   unsampled_image_accessor &operator=(unsampled_image_accessor &&Rhs) = default;
[ 3750] 
[ 3751]   ~unsampled_image_accessor() = default;
[ 3752] 
[ 3753] #ifdef __SYCL_DEVICE_ONLY__
[ 3754]   bool operator==(const unsampled_image_accessor &Rhs) const;
[ 3755] #else
[ 3756]   bool operator==(const unsampled_image_accessor &Rhs) const {
[ 3757]     return Rhs.impl == impl;
[ 3758]   }
[ 3759] #endif // __SYCL_DEVICE_ONLY__
[ 3760] 
[ 3761]   bool operator!=(const unsampled_image_accessor &Rhs) const {
[ 3762]     return !(Rhs == *this);
[ 3763]   }
[ 3764] 
[ 3765]   /* -- property interface members -- */
[ 3766] 
[ 3767]   size_t size() const noexcept {
[ 3768] #ifdef __SYCL_DEVICE_ONLY__
[ 3769]     // Currently not reachable on device.
[ 3770]     return 0;
[ 3771] #else
[ 3772]     return host_base_class::getSize().size();
[ 3773] #endif // __SYCL_DEVICE_ONLY__
[ 3774]   }
[ 3775] 
[ 3776]   /* Available only when: AccessMode == access_mode::read
[ 3777]   if Dimensions == 1, CoordT = int
[ 3778]   if Dimensions == 2, CoordT = int2
[ 3779]   if Dimensions == 3, CoordT = int4 */
[ 3780]   template <typename CoordT,
[ 3781]             typename = std::enable_if_t<AccessMode == access_mode::read &&
[ 3782]                                         detail::IsValidUnsampledCoord2020DataT<
[ 3783]                                             Dimensions, CoordT>::value>>
[ 3784]   DataT read(const CoordT &Coords) const noexcept {
[ 3785] #ifdef __SYCL_DEVICE_ONLY__
[ 3786]     // Currently not reachable on device.
[ 3787]     std::ignore = Coords;
[ 3788]     return {0, 0, 0, 0};
[ 3789] #else
[ 3790]     return host_base_class::read<DataT>(Coords);
[ 3791] #endif // __SYCL_DEVICE_ONLY__
[ 3792]   }
[ 3793] 
[ 3794]   /* Available only when: AccessMode == access_mode::write
[ 3795]   if Dimensions == 1, CoordT = int
[ 3796]   if Dimensions == 2, CoordT = int2
[ 3797]   if Dimensions == 3, CoordT = int4 */
[ 3798]   template <typename CoordT,
[ 3799]             typename = std::enable_if_t<AccessMode == access_mode::write &&
[ 3800]                                         detail::IsValidUnsampledCoord2020DataT<
[ 3801]                                             Dimensions, CoordT>::value>>
[ 3802]   void write(const CoordT &Coords, const DataT &Color) const {
[ 3803] #ifdef __SYCL_DEVICE_ONLY__
[ 3804]     // Currently not reachable on device.
[ 3805]     std::ignore = Coords;
[ 3806]     std::ignore = Color;
[ 3807] #else
[ 3808]     host_base_class::write<DataT>(Coords, Color);
[ 3809] #endif // __SYCL_DEVICE_ONLY__
[ 3810]   }
[ 3811] 
[ 3812] private:
[ 3813]   unsampled_image_accessor(const detail::UnsampledImageAccessorImplPtr &Impl)
[ 3814] #ifndef __SYCL_DEVICE_ONLY__
[ 3815]       : host_base_class{Impl}
[ 3816] #endif // __SYCL_DEVICE_ONLY__
[ 3817]   {
[ 3818]     std::ignore = Impl;
[ 3819]   }
[ 3820] 
[ 3821]   template <class Obj>
[ 3822]   friend decltype(Obj::impl) detail::getSyclObjImpl(const Obj &SyclObject);
[ 3823] 
[ 3824]   template <class T>
[ 3825]   friend T detail::createSyclObjFromImpl(decltype(T::impl) ImplObj);
[ 3826] };
[ 3827] 
[ 3828] template <typename DataT, int Dimensions = 1,
[ 3829]           access_mode AccessMode =
[ 3830]               (std::is_const_v<DataT> ? access_mode::read
[ 3831]                                       : access_mode::read_write)>
[ 3832] class __SYCL_EBO host_unsampled_image_accessor
[ 3833]     : private detail::UnsampledImageAccessorBaseHost,
[ 3834]       public detail::OwnerLessBase<
[ 3835]           host_unsampled_image_accessor<DataT, Dimensions, AccessMode>> {
[ 3836]   static_assert(std::is_same_v<DataT, int4> || std::is_same_v<DataT, uint4> ||
[ 3837]                     std::is_same_v<DataT, float4> ||
[ 3838]                     std::is_same_v<DataT, half4>,
[ 3839]                 "The data type of an image accessor must be only int4, "
[ 3840]                 "uint4, float4 or half4 from SYCL namespace");
[ 3841] 
[ 3842]   using base_class = detail::UnsampledImageAccessorBaseHost;
[ 3843] 
[ 3844] public:
[ 3845]   using value_type = typename std::conditional<AccessMode == access_mode::read,
[ 3846]                                                const DataT, DataT>::type;
[ 3847]   using reference = value_type &;
[ 3848]   using const_reference = const DataT &;
[ 3849] 
[ 3850]   template <typename AllocatorT>
[ 3851]   host_unsampled_image_accessor(
[ 3852]       unsampled_image<Dimensions, AllocatorT> &ImageRef,
[ 3853]       const property_list &PropList = {},
[ 3854]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3855]       : base_class(detail::convertToArrayOfN<3, 1>(ImageRef.get_range()),
[ 3856]                    AccessMode, detail::getSyclObjImpl(ImageRef).get(),
[ 3857]                    Dimensions, ImageRef.getElementSize(),
[ 3858]                    {ImageRef.getRowPitch(), ImageRef.getSlicePitch(), 0},
[ 3859]                    ImageRef.getChannelType(), ImageRef.getChannelOrder(),
[ 3860]                    PropList) {
[ 3861]     addHostUnsampledImageAccessorAndWait(base_class::impl.get());
[ 3862] 
[ 3863]     detail::unsampledImageConstructorNotification(
[ 3864]         detail::getSyclObjImpl(ImageRef).get(), this->impl.get(), std::nullopt,
[ 3865]         AccessMode, (const void *)typeid(DataT).name(), sizeof(DataT), CodeLoc);
[ 3866]   }
[ 3867] 
[ 3868]   /* -- common interface members -- */
[ 3869] 
[ 3870]   host_unsampled_image_accessor(const host_unsampled_image_accessor &Rhs) =
[ 3871]       default;
[ 3872] 
[ 3873]   host_unsampled_image_accessor(host_unsampled_image_accessor &&Rhs) = default;
[ 3874] 
[ 3875]   host_unsampled_image_accessor &
[ 3876]   operator=(const host_unsampled_image_accessor &Rhs) = default;
[ 3877] 
[ 3878]   host_unsampled_image_accessor &
[ 3879]   operator=(host_unsampled_image_accessor &&Rhs) = default;
[ 3880] 
[ 3881]   ~host_unsampled_image_accessor() = default;
[ 3882] 
[ 3883]   bool operator==(const host_unsampled_image_accessor &Rhs) const {
[ 3884]     return Rhs.impl == impl;
[ 3885]   }
[ 3886]   bool operator!=(const host_unsampled_image_accessor &Rhs) const {
[ 3887]     return !(Rhs == *this);
[ 3888]   }
[ 3889] 
[ 3890]   /* -- property interface members -- */
[ 3891] 
[ 3892]   size_t size() const noexcept { return base_class::getSize().size(); }
[ 3893] 
[ 3894]   /* Available only when: (AccessMode == access_mode::read ||
[ 3895]                            AccessMode == access_mode::read_write)
[ 3896]   if Dimensions == 1, CoordT = int
[ 3897]   if Dimensions == 2, CoordT = int2
[ 3898]   if Dimensions == 3, CoordT = int4 */
[ 3899]   template <
[ 3900]       typename CoordT,
[ 3901]       typename = std::enable_if_t<
[ 3902]           (AccessMode == access_mode::read ||
[ 3903]            AccessMode == access_mode::read_write) &&
[ 3904]           detail::IsValidUnsampledCoord2020DataT<Dimensions, CoordT>::value>>
[ 3905]   DataT read(const CoordT &Coords) const noexcept
[ 3906] #ifdef __SYCL_DEVICE_ONLY__
[ 3907]       ;
[ 3908] #else
[ 3909]   {
[ 3910]     // Host implementation is only available in host code. Device is not allowed
[ 3911]     // to use host_unsampled_image_accessor.
[ 3912]     return base_class::read<DataT>(Coords);
[ 3913]   }
[ 3914] #endif
[ 3915] 
[ 3916]   /* Available only when: (AccessMode == access_mode::write ||
[ 3917]                            AccessMode == access_mode::read_write)
[ 3918]   if Dimensions == 1, CoordT = int
[ 3919]   if Dimensions == 2, CoordT = int2
[ 3920]   if Dimensions == 3, CoordT = int4 */
[ 3921]   template <
[ 3922]       typename CoordT,
[ 3923]       typename = std::enable_if_t<
[ 3924]           (AccessMode == access_mode::write ||
[ 3925]            AccessMode == access_mode::read_write) &&
[ 3926]           detail::IsValidUnsampledCoord2020DataT<Dimensions, CoordT>::value>>
[ 3927]   void write(const CoordT &Coords, const DataT &Color) const
[ 3928] #ifdef __SYCL_DEVICE_ONLY__
[ 3929]       ;
[ 3930] #else
[ 3931]   {
[ 3932]     // Host implementation is only available in host code. Device is not allowed
[ 3933]     // to use host_unsampled_image_accessor.
[ 3934]     base_class::write<DataT>(Coords, Color);
[ 3935]   }
[ 3936] #endif
[ 3937] 
[ 3938] private:
[ 3939]   host_unsampled_image_accessor(
[ 3940]       const detail::UnsampledImageAccessorImplPtr &Impl)
[ 3941]       : base_class{Impl} {}
[ 3942] 
[ 3943]   template <class Obj>
[ 3944]   friend decltype(Obj::impl) detail::getSyclObjImpl(const Obj &SyclObject);
[ 3945] 
[ 3946]   template <class T>
[ 3947]   friend T detail::createSyclObjFromImpl(decltype(T::impl) ImplObj);
[ 3948] };
[ 3949] 
[ 3950] template <typename DataT, int Dimensions,
[ 3951]           image_target AccessTarget = image_target::device>
[ 3952] class __SYCL_EBO sampled_image_accessor :
[ 3953] #ifndef __SYCL_DEVICE_ONLY__
[ 3954]     private detail::SampledImageAccessorBaseHost,
[ 3955] #endif // __SYCL_DEVICE_ONLY__
[ 3956]     public detail::OwnerLessBase<
[ 3957]         sampled_image_accessor<DataT, Dimensions, AccessTarget>> {
[ 3958]   static_assert(std::is_same_v<DataT, int4> || std::is_same_v<DataT, uint4> ||
[ 3959]                     std::is_same_v<DataT, float4> ||
[ 3960]                     std::is_same_v<DataT, half4>,
[ 3961]                 "The data type of an image accessor must be only int4, "
[ 3962]                 "uint4, float4 or half4 from SYCL namespace");
[ 3963] 
[ 3964] #ifdef __SYCL_DEVICE_ONLY__
[ 3965]   char MPadding[sizeof(detail::SampledImageAccessorBaseHost)];
[ 3966] #else
[ 3967]   using host_base_class = detail::SampledImageAccessorBaseHost;
[ 3968] #endif // __SYCL_DEVICE_ONLY__
[ 3969] 
[ 3970] public:
[ 3971]   using value_type = const DataT;
[ 3972]   using reference = const DataT &;
[ 3973]   using const_reference = const DataT &;
[ 3974] 
[ 3975]   template <typename AllocatorT>
[ 3976]   sampled_image_accessor(
[ 3977]       sampled_image<Dimensions, AllocatorT> &ImageRef,
[ 3978]       handler &CommandGroupHandlerRef, const property_list &PropList = {},
[ 3979]       const detail::code_location CodeLoc = detail::code_location::current())
[ 3980] #ifdef __SYCL_DEVICE_ONLY__
[ 3981]   {
[ 3982]     (void)ImageRef;
[ 3983]     (void)CommandGroupHandlerRef;
[ 3984]     (void)PropList;
[ 3985]     (void)CodeLoc;
[ 3986]   }
[ 3987] #else
[ 3988]       : host_base_class(detail::convertToArrayOfN<3, 1>(ImageRef.get_range()),
[ 3989]                         detail::getSyclObjImpl(ImageRef).get(), Dimensions,
[ 3990]                         ImageRef.getElementSize(),
[ 3991]                         {ImageRef.getRowPitch(), ImageRef.getSlicePitch(), 0},
[ 3992]                         ImageRef.getChannelType(), ImageRef.getChannelOrder(),
[ 3993]                         ImageRef.getSampler(), PropList) {
[ 3994]     device Device = detail::getDeviceFromHandler(CommandGroupHandlerRef);
[ 3995]     // Avoid aspect::image warning.
[ 3996]     aspect ImageAspect = aspect::image;
[ 3997]     if (AccessTarget == image_target::device && !Device.has(ImageAspect))
[ 3998]       throw sycl::exception(
[ 3999]           sycl::make_error_code(sycl::errc::feature_not_supported),
[ 4000]           "Device associated with command group handler does not have "
[ 4001]           "aspect::image.");
[ 4002] 
[ 4003]     detail::sampledImageConstructorNotification(
[ 4004]         detail::getSyclObjImpl(ImageRef).get(), this->impl.get(), AccessTarget,
[ 4005]         (const void *)typeid(DataT).name(), sizeof(DataT), CodeLoc);
[ 4006]     detail::associateWithHandler(CommandGroupHandlerRef, this, AccessTarget);
[ 4007]     GDBMethodsAnchor();
[ 4008]   }
[ 4009] #endif // __SYCL_DEVICE_ONLY__
[ 4010] 
[ 4011]   /* -- common interface members -- */
[ 4012] 
[ 4013]   sampled_image_accessor(const sampled_image_accessor &Rhs) = default;
[ 4014] 
[ 4015]   sampled_image_accessor(sampled_image_accessor &&Rhs) = default;
[ 4016] 
[ 4017]   sampled_image_accessor &
[ 4018]   operator=(const sampled_image_accessor &Rhs) = default;
[ 4019] 
[ 4020]   sampled_image_accessor &operator=(sampled_image_accessor &&Rhs) = default;
[ 4021] 
[ 4022]   ~sampled_image_accessor() = default;
[ 4023] 
[ 4024] #ifdef __SYCL_DEVICE_ONLY__
[ 4025]   bool operator==(const sampled_image_accessor &Rhs) const;
[ 4026] #else
[ 4027]   bool operator==(const sampled_image_accessor &Rhs) const {
[ 4028]     return Rhs.impl == impl;
[ 4029]   }
[ 4030] #endif // __SYCL_DEVICE_ONLY__
[ 4031] 
[ 4032]   bool operator!=(const sampled_image_accessor &Rhs) const {
[ 4033]     return !(Rhs == *this);
[ 4034]   }
[ 4035] 
[ 4036]   /* -- property interface members -- */
[ 4037] 
[ 4038]   size_t size() const noexcept {
[ 4039] #ifdef __SYCL_DEVICE_ONLY__
[ 4040]     // Currently not reachable on device.
[ 4041]     return 0;
[ 4042] #else
[ 4043]     return host_base_class::getSize().size();
[ 4044] #endif // __SYCL_DEVICE_ONLY__
[ 4045]   }
[ 4046] 
[ 4047]   /* if Dimensions == 1, CoordT = float
[ 4048]      if Dimensions == 2, CoordT = float2
[ 4049]      if Dimensions == 3, CoordT = float4 */
[ 4050]   template <typename CoordT,
[ 4051]             typename = std::enable_if_t<detail::IsValidSampledCoord2020DataT<
[ 4052]                 Dimensions, CoordT>::value>>
[ 4053]   DataT read(const CoordT &Coords) const noexcept {
[ 4054] #ifdef __SYCL_DEVICE_ONLY__
[ 4055]     // Currently not reachable on device.
[ 4056]     std::ignore = Coords;
[ 4057]     return {0, 0, 0, 0};
[ 4058] #else
[ 4059]     return host_base_class::read<DataT>(Coords);
[ 4060] #endif // __SYCL_DEVICE_ONLY__
[ 4061]   }
[ 4062] 
[ 4063] private:
[ 4064]   sampled_image_accessor(const detail::SampledImageAccessorImplPtr &Impl)
[ 4065] #ifndef __SYCL_DEVICE_ONLY__
[ 4066]       : host_base_class{Impl}
[ 4067] #endif // __SYCL_DEVICE_ONLY__
[ 4068]   {
[ 4069]     std::ignore = Impl;
[ 4070]   }
[ 4071] 
[ 4072]   template <class Obj>
[ 4073]   friend decltype(Obj::impl) detail::getSyclObjImpl(const Obj &SyclObject);
[ 4074] 
[ 4075]   template <class T>
[ 4076]   friend T detail::createSyclObjFromImpl(decltype(T::impl) ImplObj);
[ 4077] };
[ 4078] 
[ 4079] template <typename DataT, int Dimensions>
[ 4080] class __SYCL_EBO host_sampled_image_accessor
[ 4081]     : private detail::SampledImageAccessorBaseHost,
[ 4082]       public detail::OwnerLessBase<
[ 4083]           host_sampled_image_accessor<DataT, Dimensions>> {
[ 4084]   static_assert(std::is_same_v<DataT, int4> || std::is_same_v<DataT, uint4> ||
[ 4085]                     std::is_same_v<DataT, float4> ||
[ 4086]                     std::is_same_v<DataT, half4>,
[ 4087]                 "The data type of an image accessor must be only int4, "
[ 4088]                 "uint4, float4 or half4 from SYCL namespace");
[ 4089] 
[ 4090]   using base_class = detail::SampledImageAccessorBaseHost;
[ 4091] 
[ 4092] public:
[ 4093]   using value_type = const DataT;
[ 4094]   using reference = const DataT &;
[ 4095]   using const_reference = const DataT &;
[ 4096] 
[ 4097]   template <typename AllocatorT>
[ 4098]   host_sampled_image_accessor(
[ 4099]       sampled_image<Dimensions, AllocatorT> &ImageRef,
[ 4100]       const property_list &PropList = {},
[ 4101]       const detail::code_location CodeLoc = detail::code_location::current())
[ 4102]       : base_class(detail::convertToArrayOfN<3, 1>(ImageRef.get_range()),
[ 4103]                    detail::getSyclObjImpl(ImageRef).get(), Dimensions,
[ 4104]                    ImageRef.getElementSize(),
[ 4105]                    {ImageRef.getRowPitch(), ImageRef.getSlicePitch(), 0},
[ 4106]                    ImageRef.getChannelType(), ImageRef.getChannelOrder(),
[ 4107]                    ImageRef.getSampler(), PropList) {
[ 4108]     addHostSampledImageAccessorAndWait(base_class::impl.get());
[ 4109] 
[ 4110]     detail::sampledImageConstructorNotification(
[ 4111]         detail::getSyclObjImpl(ImageRef).get(), this->impl.get(), std::nullopt,
[ 4112]         (const void *)typeid(DataT).name(), sizeof(DataT), CodeLoc);
[ 4113]   }
[ 4114] 
[ 4115]   /* -- common interface members -- */
[ 4116] 
[ 4117]   host_sampled_image_accessor(const host_sampled_image_accessor &Rhs) = default;
[ 4118] 
[ 4119]   host_sampled_image_accessor(host_sampled_image_accessor &&Rhs) = default;
[ 4120] 
[ 4121]   host_sampled_image_accessor &
[ 4122]   operator=(const host_sampled_image_accessor &Rhs) = default;
[ 4123] 
[ 4124]   host_sampled_image_accessor &
[ 4125]   operator=(host_sampled_image_accessor &&Rhs) = default;
[ 4126] 
[ 4127]   ~host_sampled_image_accessor() = default;
[ 4128] 
[ 4129]   bool operator==(const host_sampled_image_accessor &Rhs) const {
[ 4130]     return Rhs.impl == impl;
[ 4131]   }
[ 4132]   bool operator!=(const host_sampled_image_accessor &Rhs) const {
[ 4133]     return !(Rhs == *this);
[ 4134]   }
[ 4135] 
[ 4136]   /* -- property interface members -- */
[ 4137] 
[ 4138]   size_t size() const noexcept { return base_class::getSize().size(); }
[ 4139] 
[ 4140]   /* if Dimensions == 1, CoordT = float
[ 4141]      if Dimensions == 2, CoordT = float2
[ 4142]      if Dimensions == 3, CoordT = float4 */
[ 4143]   template <typename CoordT,
[ 4144]             typename = std::enable_if_t<detail::IsValidSampledCoord2020DataT<
[ 4145]                 Dimensions, CoordT>::value>>
[ 4146]   DataT read(const CoordT &Coords) const
[ 4147] #ifdef __SYCL_DEVICE_ONLY__
[ 4148]       ;
[ 4149] #else
[ 4150]   {
[ 4151]     // Host implementation is only available in host code. Device is not allowed
[ 4152]     // to use host_sampled_image_accessor.
[ 4153]     return base_class::read<DataT>(Coords);
[ 4154]   }
[ 4155] #endif
[ 4156] 
[ 4157] private:
[ 4158]   host_sampled_image_accessor(const detail::SampledImageAccessorImplPtr &Impl)
[ 4159]       : base_class{Impl} {}
[ 4160] 
[ 4161]   template <class Obj>
[ 4162]   friend decltype(Obj::impl) detail::getSyclObjImpl(const Obj &SyclObject);
[ 4163] 
[ 4164]   template <class T>
[ 4165]   friend T detail::createSyclObjFromImpl(decltype(T::impl) ImplObj);
[ 4166] };
[ 4167] 
[ 4168] } // namespace _V1
[ 4169] } // namespace sycl
[ 4170] 
[ 4171] namespace std {
[ 4172] template <typename DataT, int Dimensions, sycl::access::mode AccessMode,
[ 4173]           sycl::access::target AccessTarget,
[ 4174]           sycl::access::placeholder IsPlaceholder>
[ 4175] struct hash<sycl::accessor<DataT, Dimensions, AccessMode, AccessTarget,
[ 4176]                            IsPlaceholder>> {
[ 4177]   using AccType = sycl::accessor<DataT, Dimensions, AccessMode, AccessTarget,
[ 4178]                                  IsPlaceholder>;
[ 4179] 
[ 4180]   size_t operator()(const AccType &A) const {
[ 4181] #ifdef __SYCL_DEVICE_ONLY__
[ 4182]     // Hash is not supported on DEVICE. Just return 0 here.
[ 4183]     (void)A;
[ 4184]     return 0;
[ 4185] #else
[ 4186]     // getSyclObjImpl() here returns a pointer to either AccessorImplHost
[ 4187]     // or LocalAccessorImplHost depending on the AccessTarget.
[ 4188]     auto AccImplPtr = sycl::detail::getSyclObjImpl(A);
[ 4189]     return hash<decltype(AccImplPtr)>()(AccImplPtr);
[ 4190] #endif
[ 4191]   }
[ 4192] };
[ 4193] 
[ 4194] template <typename DataT, int Dimensions, sycl::access_mode AccessMode>
[ 4195] struct hash<sycl::host_accessor<DataT, Dimensions, AccessMode>> {
[ 4196]   using AccType = sycl::host_accessor<DataT, Dimensions, AccessMode>;
[ 4197] 
[ 4198]   size_t operator()(const AccType &A) const {
[ 4199] #ifdef __SYCL_DEVICE_ONLY__
[ 4200]     // Hash is not supported on DEVICE. Just return 0 here.
[ 4201]     (void)A;
[ 4202]     return 0;
[ 4203] #else
[ 4204]     // getSyclObjImpl() here returns a pointer to AccessorImplHost.
[ 4205]     auto AccImplPtr = sycl::detail::getSyclObjImpl(A);
[ 4206]     return hash<decltype(AccImplPtr)>()(AccImplPtr);
[ 4207] #endif
[ 4208]   }
[ 4209] };
[ 4210] 
[ 4211] template <typename DataT, int Dimensions>
[ 4212] struct hash<sycl::local_accessor<DataT, Dimensions>> {
[ 4213]   using AccType = sycl::local_accessor<DataT, Dimensions>;
[ 4214] 
[ 4215]   size_t operator()(const AccType &A) const {
[ 4216] #ifdef __SYCL_DEVICE_ONLY__
[ 4217]     // Hash is not supported on DEVICE. Just return 0 here.
[ 4218]     (void)A;
[ 4219]     return 0;
[ 4220] #else
[ 4221]     // getSyclObjImpl() here returns a pointer to LocalAccessorImplHost.
[ 4222]     auto AccImplPtr = sycl::detail::getSyclObjImpl(A);
[ 4223]     return hash<decltype(AccImplPtr)>()(AccImplPtr);
[ 4224] #endif
[ 4225]   }
[ 4226] };
[ 4227] 
[ 4228] template <typename DataT, int Dimensions, sycl::access_mode AccessMode,
[ 4229]           sycl::image_target AccessTarget>
[ 4230] struct hash<sycl::unsampled_image_accessor<DataT, Dimensions, AccessMode,
[ 4231]                                            AccessTarget>> {
[ 4232]   using AccType = sycl::unsampled_image_accessor<DataT, Dimensions, AccessMode,
[ 4233]                                                  AccessTarget>;
[ 4234] 
[ 4235]   size_t operator()(const AccType &A) const {
[ 4236] #ifdef __SYCL_DEVICE_ONLY__
[ 4237]     // Hash is not supported on DEVICE. Just return 0 here.
[ 4238]     (void)A;
[ 4239]     return 0;
[ 4240] #else
[ 4241]     auto AccImplPtr = sycl::detail::getSyclObjImpl(A);
[ 4242]     return hash<decltype(AccImplPtr)>()(AccImplPtr);
[ 4243] #endif
[ 4244]   }
[ 4245] };
[ 4246] 
[ 4247] template <typename DataT, int Dimensions, sycl::access_mode AccessMode>
[ 4248] struct hash<
[ 4249]     sycl::host_unsampled_image_accessor<DataT, Dimensions, AccessMode>> {
[ 4250]   using AccType =
[ 4251]       sycl::host_unsampled_image_accessor<DataT, Dimensions, AccessMode>;
[ 4252] 
[ 4253]   size_t operator()(const AccType &A) const {
[ 4254]     auto AccImplPtr = sycl::detail::getSyclObjImpl(A);
[ 4255]     return hash<decltype(AccImplPtr)>()(AccImplPtr);
[ 4256]   }
[ 4257] };
[ 4258] 
[ 4259] template <typename DataT, int Dimensions, sycl::image_target AccessTarget>
[ 4260] struct hash<sycl::sampled_image_accessor<DataT, Dimensions, AccessTarget>> {
[ 4261]   using AccType = sycl::sampled_image_accessor<DataT, Dimensions, AccessTarget>;
[ 4262] 
[ 4263]   size_t operator()(const AccType &A) const {
[ 4264] #ifdef __SYCL_DEVICE_ONLY__
[ 4265]     // Hash is not supported on DEVICE. Just return 0 here.
[ 4266]     (void)A;
[ 4267]     return 0;
[ 4268] #else
[ 4269]     auto AccImplPtr = sycl::detail::getSyclObjImpl(A);
[ 4270]     return hash<decltype(AccImplPtr)>()(AccImplPtr);
[ 4271] #endif
[ 4272]   }
[ 4273] };
[ 4274] 
[ 4275] template <typename DataT, int Dimensions>
[ 4276] struct hash<sycl::host_sampled_image_accessor<DataT, Dimensions>> {
[ 4277]   using AccType = sycl::host_sampled_image_accessor<DataT, Dimensions>;
[ 4278] 
[ 4279]   size_t operator()(const AccType &A) const {
[ 4280]     auto AccImplPtr = sycl::detail::getSyclObjImpl(A);
[ 4281]     return hash<decltype(AccImplPtr)>()(AccImplPtr);
[ 4282]   }
[ 4283] };
[ 4284] 
[ 4285] } // namespace std
=== File: /storage/users/yuning/intel/oneapi/compiler/2024.1/bin/compiler/../../include/sycl/CL/__spirv/spirv_vars.hpp ===
[    1] //==----------- spirv_vars.hpp --- SPIRV variables -------------------------==//
[    2] //
[    3] // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
[    4] // See https://llvm.org/LICENSE.txt for license information.
[    5] // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
[    6] //
[    7] // ===-------------------------------------------------------------------=== //
[    8] 
[    9] #pragma once
[   10] 
[   11] #ifdef __SYCL_DEVICE_ONLY__
[   12] 
[   13] #include <sycl/detail/defines_elementary.hpp> // for __DPCPP_SYCL_EXTERNAL
[   14] 
[   15] #include <cstddef> // for size_t
[   16] #include <cstdint> // for uint8_t
[   17] 
[   18] #define __SPIRV_VAR_QUALIFIERS extern "C" const
[   19] 
[   20] #if defined(__NVPTX__) || defined(__AMDGCN__) || defined(__SYCL_NATIVE_CPU__)
[   21] 
[   22] __DPCPP_SYCL_EXTERNAL size_t __spirv_GlobalInvocationId_x();
[   23] __DPCPP_SYCL_EXTERNAL size_t __spirv_GlobalInvocationId_y();
[   24] __DPCPP_SYCL_EXTERNAL size_t __spirv_GlobalInvocationId_z();
[   25] 
[   26] __DPCPP_SYCL_EXTERNAL size_t __spirv_GlobalSize_x();
[   27] __DPCPP_SYCL_EXTERNAL size_t __spirv_GlobalSize_y();
[   28] __DPCPP_SYCL_EXTERNAL size_t __spirv_GlobalSize_z();
[   29] 
[   30] __DPCPP_SYCL_EXTERNAL size_t __spirv_GlobalOffset_x();
[   31] __DPCPP_SYCL_EXTERNAL size_t __spirv_GlobalOffset_y();
[   32] __DPCPP_SYCL_EXTERNAL size_t __spirv_GlobalOffset_z();
[   33] 
[   34] __DPCPP_SYCL_EXTERNAL size_t __spirv_NumWorkgroups_x();
[   35] __DPCPP_SYCL_EXTERNAL size_t __spirv_NumWorkgroups_y();
[   36] __DPCPP_SYCL_EXTERNAL size_t __spirv_NumWorkgroups_z();
[   37] 
[   38] __DPCPP_SYCL_EXTERNAL size_t __spirv_WorkgroupSize_x();
[   39] __DPCPP_SYCL_EXTERNAL size_t __spirv_WorkgroupSize_y();
[   40] __DPCPP_SYCL_EXTERNAL size_t __spirv_WorkgroupSize_z();
[   41] 
[   42] __DPCPP_SYCL_EXTERNAL size_t __spirv_WorkgroupId_x();
[   43] __DPCPP_SYCL_EXTERNAL size_t __spirv_WorkgroupId_y();
[   44] __DPCPP_SYCL_EXTERNAL size_t __spirv_WorkgroupId_z();
[   45] 
[   46] __DPCPP_SYCL_EXTERNAL size_t __spirv_LocalInvocationId_x();
[   47] __DPCPP_SYCL_EXTERNAL size_t __spirv_LocalInvocationId_y();
[   48] __DPCPP_SYCL_EXTERNAL size_t __spirv_LocalInvocationId_z();
[   49] 
[   50] __DPCPP_SYCL_EXTERNAL uint32_t __spirv_SubgroupSize();
[   51] __DPCPP_SYCL_EXTERNAL uint32_t __spirv_SubgroupMaxSize();
[   52] __DPCPP_SYCL_EXTERNAL uint32_t __spirv_NumSubgroups();
[   53] __DPCPP_SYCL_EXTERNAL uint32_t __spirv_SubgroupId();
[   54] __DPCPP_SYCL_EXTERNAL uint32_t __spirv_SubgroupLocalInvocationId();
[   55] 
[   56] #else // defined(__NVPTX__) || defined(__AMDGCN__)
[   57] 
[   58] typedef size_t size_t_vec __attribute__((ext_vector_type(3)));
[   59] __SPIRV_VAR_QUALIFIERS size_t_vec __spirv_BuiltInGlobalSize;
[   60] __SPIRV_VAR_QUALIFIERS size_t_vec __spirv_BuiltInGlobalInvocationId;
[   61] __SPIRV_VAR_QUALIFIERS size_t_vec __spirv_BuiltInWorkgroupSize;
[   62] __SPIRV_VAR_QUALIFIERS size_t_vec __spirv_BuiltInNumWorkgroups;
[   63] __SPIRV_VAR_QUALIFIERS size_t_vec __spirv_BuiltInLocalInvocationId;
[   64] __SPIRV_VAR_QUALIFIERS size_t_vec __spirv_BuiltInWorkgroupId;
[   65] __SPIRV_VAR_QUALIFIERS size_t_vec __spirv_BuiltInGlobalOffset;
[   66] 
[   67] __SPIRV_VAR_QUALIFIERS uint32_t __spirv_BuiltInSubgroupSize;
[   68] __SPIRV_VAR_QUALIFIERS uint32_t __spirv_BuiltInSubgroupMaxSize;
[   69] __SPIRV_VAR_QUALIFIERS uint32_t __spirv_BuiltInNumSubgroups;
[   70] __SPIRV_VAR_QUALIFIERS uint32_t __spirv_BuiltInSubgroupId;
[   71] __SPIRV_VAR_QUALIFIERS uint32_t __spirv_BuiltInSubgroupLocalInvocationId;
[   72] 
[   73] __SPIRV_VAR_QUALIFIERS __ocl_vec_t<uint32_t, 4> __spirv_BuiltInSubgroupEqMask;
[   74] __SPIRV_VAR_QUALIFIERS __ocl_vec_t<uint32_t, 4> __spirv_BuiltInSubgroupGeMask;
[   75] __SPIRV_VAR_QUALIFIERS __ocl_vec_t<uint32_t, 4> __spirv_BuiltInSubgroupGtMask;
[   76] __SPIRV_VAR_QUALIFIERS __ocl_vec_t<uint32_t, 4> __spirv_BuiltInSubgroupLeMask;
[   77] __SPIRV_VAR_QUALIFIERS __ocl_vec_t<uint32_t, 4> __spirv_BuiltInSubgroupLtMask;
[   78] 
[   79] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_GlobalInvocationId_x() {
[   80]   return __spirv_BuiltInGlobalInvocationId.x;
		[0x000F8] (W)     mul (1|M0)               acc0.0<1>:d   r5.8<0;1,0>:d     r0.2<0;1,0>:uw   {Compacted,A@1,$2.dst}
		[0x00100] (W)     macl (1|M0)              r7.0<1>:d     r5.8<0;1,0>:d     r0.1<0;1,0>:d    {Compacted}
		[0x00110]         add3 (32|M0)             r8.0<1>:d     r7.0<0;0>:d       r1.0<1;0>:uw      r4.0<0>:d        {I@2}
[   81] }
[   82] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_GlobalInvocationId_y() {
[   83]   return __spirv_BuiltInGlobalInvocationId.y;
[   84] }
[   85] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_GlobalInvocationId_z() {
[   86]   return __spirv_BuiltInGlobalInvocationId.z;
[   87] }
[   88] 
[   89] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_GlobalSize_x() {
[   90]   return __spirv_BuiltInGlobalSize.x;
[   91] }
[   92] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_GlobalSize_y() {
[   93]   return __spirv_BuiltInGlobalSize.y;
[   94] }
[   95] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_GlobalSize_z() {
[   96]   return __spirv_BuiltInGlobalSize.z;
[   97] }
[   98] 
[   99] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_GlobalOffset_x() {
[  100]   return __spirv_BuiltInGlobalOffset.x;
[  101] }
[  102] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_GlobalOffset_y() {
[  103]   return __spirv_BuiltInGlobalOffset.y;
[  104] }
[  105] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_GlobalOffset_z() {
[  106]   return __spirv_BuiltInGlobalOffset.z;
[  107] }
[  108] 
[  109] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_NumWorkgroups_x() {
[  110]   return __spirv_BuiltInNumWorkgroups.x;
[  111] }
[  112] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_NumWorkgroups_y() {
[  113]   return __spirv_BuiltInNumWorkgroups.y;
[  114] }
[  115] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_NumWorkgroups_z() {
[  116]   return __spirv_BuiltInNumWorkgroups.z;
[  117] }
[  118] 
[  119] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_WorkgroupSize_x() {
[  120]   return __spirv_BuiltInWorkgroupSize.x;
[  121] }
[  122] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_WorkgroupSize_y() {
[  123]   return __spirv_BuiltInWorkgroupSize.y;
[  124] }
[  125] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_WorkgroupSize_z() {
[  126]   return __spirv_BuiltInWorkgroupSize.z;
[  127] }
[  128] 
[  129] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_WorkgroupId_x() {
[  130]   return __spirv_BuiltInWorkgroupId.x;
[  131] }
[  132] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_WorkgroupId_y() {
[  133]   return __spirv_BuiltInWorkgroupId.y;
[  134] }
[  135] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_WorkgroupId_z() {
[  136]   return __spirv_BuiltInWorkgroupId.z;
[  137] }
[  138] 
[  139] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_LocalInvocationId_x() {
[  140]   return __spirv_BuiltInLocalInvocationId.x;
[  141] }
[  142] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_LocalInvocationId_y() {
[  143]   return __spirv_BuiltInLocalInvocationId.y;
[  144] }
[  145] __DPCPP_SYCL_EXTERNAL inline size_t __spirv_LocalInvocationId_z() {
[  146]   return __spirv_BuiltInLocalInvocationId.z;
[  147] }
[  148] 
[  149] __DPCPP_SYCL_EXTERNAL inline uint32_t __spirv_SubgroupSize() {
[  150]   return __spirv_BuiltInSubgroupSize;
[  151] }
[  152] __DPCPP_SYCL_EXTERNAL inline uint32_t __spirv_SubgroupMaxSize() {
[  153]   return __spirv_BuiltInSubgroupMaxSize;
[  154] }
[  155] __DPCPP_SYCL_EXTERNAL inline uint32_t __spirv_NumSubgroups() {
[  156]   return __spirv_BuiltInNumSubgroups;
[  157] }
[  158] __DPCPP_SYCL_EXTERNAL inline uint32_t __spirv_SubgroupId() {
[  159]   return __spirv_BuiltInSubgroupId;
[  160] }
[  161] __DPCPP_SYCL_EXTERNAL inline uint32_t __spirv_SubgroupLocalInvocationId() {
[  162]   return __spirv_BuiltInSubgroupLocalInvocationId;
[  163] }
[  164] 
[  165] #endif // defined(__NVPTX__) || defined(__AMDGCN__)
[  166] 
[  167] #undef __SPIRV_VAR_QUALIFIERS
[  168] 
[  169] namespace __spirv {
[  170] 
[  171] // Helper function templates to initialize and get vector component from SPIR-V
[  172] // built-in variables
[  173] #define __SPIRV_DEFINE_INIT_AND_GET_HELPERS(POSTFIX)                           \
[  174]   template <int ID> static size_t get##POSTFIX();                              \
[  175]   template <> size_t get##POSTFIX<0>() { return __spirv_##POSTFIX##_x(); }     \
[  176]   template <> size_t get##POSTFIX<1>() { return __spirv_##POSTFIX##_y(); }     \
[  177]   template <> size_t get##POSTFIX<2>() { return __spirv_##POSTFIX##_z(); }     \
[  178]                                                                                \
[  179]   template <int Dim, class DstT> struct InitSizesST##POSTFIX;                  \
[  180]                                                                                \
[  181]   template <class DstT> struct InitSizesST##POSTFIX<1, DstT> {                 \
[  182]     static DstT initSize() { return {get##POSTFIX<0>()}; }                     \
[  183]   };                                                                           \
[  184]                                                                                \
[  185]   template <class DstT> struct InitSizesST##POSTFIX<2, DstT> {                 \
[  186]     static DstT initSize() { return {get##POSTFIX<1>(), get##POSTFIX<0>()}; }  \
[  187]   };                                                                           \
[  188]                                                                                \
[  189]   template <class DstT> struct InitSizesST##POSTFIX<3, DstT> {                 \
[  190]     static DstT initSize() {                                                   \
[  191]       return {get##POSTFIX<2>(), get##POSTFIX<1>(), get##POSTFIX<0>()};        \
[  192]     }                                                                          \
[  193]   };                                                                           \
[  194]                                                                                \
[  195]   template <int Dims, class DstT> DstT init##POSTFIX() {                       \
[  196]     return InitSizesST##POSTFIX<Dims, DstT>::initSize();                       \
[  197]   }
[  198] 
[  199] __SPIRV_DEFINE_INIT_AND_GET_HELPERS(GlobalSize);
[  200] __SPIRV_DEFINE_INIT_AND_GET_HELPERS(GlobalInvocationId)
[  201] __SPIRV_DEFINE_INIT_AND_GET_HELPERS(WorkgroupSize)
[  202] __SPIRV_DEFINE_INIT_AND_GET_HELPERS(NumWorkgroups)
[  203] __SPIRV_DEFINE_INIT_AND_GET_HELPERS(LocalInvocationId)
[  204] __SPIRV_DEFINE_INIT_AND_GET_HELPERS(WorkgroupId)
[  205] __SPIRV_DEFINE_INIT_AND_GET_HELPERS(GlobalOffset)
[  206] 
[  207] #undef __SPIRV_DEFINE_INIT_AND_GET_HELPERS
[  208] 
[  209] } // namespace __spirv
[  210] 
[  211] #endif // __SYCL_DEVICE_ONLY__
=== File: /storage/users/yuning/intel/oneapi/compiler/2024.1/bin/compiler/../../include/sycl/detail/helpers.hpp ===
[    1] //
[    2] // Modifications, Copyright (C) 2023 Intel Corporation
[    3] //
[    4] // This software and the related documents are Intel copyrighted materials, and
[    5] // your use of them is governed by the express license under which they were
[    6] // provided to you ("License"). Unless the License provides otherwise, you may
[    7] // not use, modify, copy, publish, distribute, disclose or transmit this
[    8] // software or the related documents without Intel's prior written permission.
[    9] //
[   10] // This software and the related documents are provided as is, with no express
[   11] // or implied warranties, other than those that are expressly stated in the
[   12] // License.
[   13] //
[   14] //==---------------- helpers.hpp - SYCL helpers ----------------------------==//
[   15] //
[   16] // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
[   17] // See https://llvm.org/LICENSE.txt for license information.
[   18] // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
[   19] //
[   20] //===----------------------------------------------------------------------===//
[   21] 
[   22] #pragma once
[   23] 
[   24] #include <CL/__spirv/spirv_types.hpp> // for MemorySemanticsMask
[   25] #include <sycl/access/access.hpp>     // for fence_space
[   26] #include <sycl/detail/export.hpp>     // for __SYCL_EXPORT
[   27] #include <sycl/detail/pi.hpp>         // for PiEvent
[   28] #include <sycl/memory_enums.hpp>      // for memory_order
[   29] 
[   30] #ifdef __SYCL_DEVICE_ONLY__
[   31] #include <CL/__spirv/spirv_vars.hpp>
[   32] #endif
[   33] 
[   34] #include <cstddef>     // for size_t
[   35] #include <memory>      // for shared_ptr
[   36] #include <stdint.h>    // for uint32_t
[   37] #include <type_traits> // for enable_if_t, integral_constant
[   38] #include <utility>     // for forward, integer_sequence, mak...
[   39] #include <vector>      // for vector
[   40] 
[   41] namespace sycl {
[   42] inline namespace _V1 {
[   43] class context;
[   44] class event;
[   45] template <int Dims, bool WithOffset> class item;
[   46] template <int Dims> class group;
[   47] template <int Dims> class range;
[   48] template <int Dims> class id;
[   49] template <int Dims> class nd_item;
[   50] template <int Dims> class h_item;
[   51] template <typename Type, std::size_t NumElements> class marray;
[   52] enum class memory_order;
[   53] 
[   54] namespace detail {
[   55] 
[   56] class buffer_impl;
[   57] class context_impl;
[   58] // The function returns list of events that can be passed to OpenCL API as
[   59] // dependency list and waits for others.
[   60] __SYCL_EXPORT std::vector<sycl::detail::pi::PiEvent>
[   61] getOrWaitEvents(std::vector<sycl::event> DepEvents,
[   62]                 std::shared_ptr<sycl::detail::context_impl> Context);
[   63] 
[   64] __SYCL_EXPORT void waitEvents(std::vector<sycl::event> DepEvents);
[   65] 
[   66] __SYCL_EXPORT void
[   67] markBufferAsInternal(const std::shared_ptr<buffer_impl> &BufImpl);
[   68] 
[   69] template <typename T> T *declptr() { return static_cast<T *>(nullptr); }
[   70] 
[   71] // Function to get of store id, item, nd_item, group for the host implementation
[   72] // Pass nullptr to get stored object. Pass valid address to store object
[   73] template <typename T> T get_or_store(const T *obj) {
[   74]   static thread_local auto stored = *obj;
[   75]   if (obj != nullptr) {
[   76]     stored = *obj;
[   77]   }
[   78]   return stored;
[   79] }
[   80] 
[   81] class Builder {
[   82] public:
[   83]   Builder() = delete;
[   84] 
[   85]   template <int Dims>
[   86]   static group<Dims>
[   87]   createGroup(const range<Dims> &Global, const range<Dims> &Local,
[   88]               const range<Dims> &Group, const id<Dims> &Index) {
[   89]     return group<Dims>(Global, Local, Group, Index);
[   90]   }
[   91] 
[   92]   template <int Dims>
[   93]   static group<Dims> createGroup(const range<Dims> &Global,
[   94]                                  const range<Dims> &Local,
[   95]                                  const id<Dims> &Index) {
[   96]     return group<Dims>(Global, Local, Global / Local, Index);
[   97]   }
[   98] 
[   99]   template <class ResType, typename BitsType>
[  100]   static ResType createSubGroupMask(BitsType Bits, size_t BitsNum) {
[  101]     return ResType(Bits, BitsNum);
[  102]   }
[  103] 
[  104]   template <int Dims, bool WithOffset>
[  105]   static std::enable_if_t<WithOffset, item<Dims, WithOffset>>
[  106]   createItem(const range<Dims> &Extent, const id<Dims> &Index,
[  107]              const id<Dims> &Offset) {
[  108]     return item<Dims, WithOffset>(Extent, Index, Offset);
[  109]   }
[  110] 
[  111]   template <int Dims, bool WithOffset>
[  112]   static std::enable_if_t<!WithOffset, item<Dims, WithOffset>>
[  113]   createItem(const range<Dims> &Extent, const id<Dims> &Index) {
[  114]     return item<Dims, WithOffset>(Extent, Index);
[  115]   }
[  116] 
[  117]   template <int Dims>
[  118]   static nd_item<Dims> createNDItem(const item<Dims, true> &Global,
[  119]                                     const item<Dims, false> &Local,
[  120]                                     const group<Dims> &Group) {
[  121]     return nd_item<Dims>(Global, Local, Group);
[  122]   }
[  123] 
[  124]   template <int Dims>
[  125]   static h_item<Dims> createHItem(const item<Dims, false> &Global,
[  126]                                   const item<Dims, false> &Local) {
[  127]     return h_item<Dims>(Global, Local);
[  128]   }
[  129] 
[  130]   template <int Dims>
[  131]   static h_item<Dims> createHItem(const item<Dims, false> &Global,
[  132]                                   const item<Dims, false> &Local,
[  133]                                   const range<Dims> &Flex) {
[  134]     return h_item<Dims>(Global, Local, Flex);
[  135]   }
[  136] 
[  137]   template <int Dims, bool WithOffset>
[  138]   static void updateItemIndex(sycl::item<Dims, WithOffset> &Item,
[  139]                               const id<Dims> &NextIndex) {
[  140]     Item.MImpl.MIndex = NextIndex;
[  141]   }
[  142] 
[  143] #ifdef __SYCL_DEVICE_ONLY__
[  144] 
[  145]   template <int N>
[  146]   using is_valid_dimensions = std::integral_constant<bool, (N > 0) && (N < 4)>;
[  147] 
[  148]   template <int Dims> static const id<Dims> getElement(id<Dims> *) {
[  149]     static_assert(is_valid_dimensions<Dims>::value, "invalid dimensions");
[  150]     return __spirv::initGlobalInvocationId<Dims, id<Dims>>();
[  151]   }
[  152] 
[  153]   template <int Dims> static const group<Dims> getElement(group<Dims> *) {
[  154]     static_assert(is_valid_dimensions<Dims>::value, "invalid dimensions");
[  155]     range<Dims> GlobalSize{__spirv::initGlobalSize<Dims, range<Dims>>()};
[  156]     range<Dims> LocalSize{__spirv::initWorkgroupSize<Dims, range<Dims>>()};
[  157]     range<Dims> GroupRange{__spirv::initNumWorkgroups<Dims, range<Dims>>()};
[  158]     id<Dims> GroupId{__spirv::initWorkgroupId<Dims, id<Dims>>()};
[  159]     return createGroup<Dims>(GlobalSize, LocalSize, GroupRange, GroupId);
[  160]   }
[  161] 
[  162]   template <int Dims, bool WithOffset>
[  163]   static std::enable_if_t<WithOffset, const item<Dims, WithOffset>> getItem() {
[  164]     static_assert(is_valid_dimensions<Dims>::value, "invalid dimensions");
[  165]     id<Dims> GlobalId{__spirv::initGlobalInvocationId<Dims, id<Dims>>()};
[  166]     range<Dims> GlobalSize{__spirv::initGlobalSize<Dims, range<Dims>>()};
[  167]     id<Dims> GlobalOffset{__spirv::initGlobalOffset<Dims, id<Dims>>()};
[  168]     return createItem<Dims, true>(GlobalSize, GlobalId, GlobalOffset);
[  169]   }
[  170] 
[  171]   template <int Dims, bool WithOffset>
[  172]   static std::enable_if_t<!WithOffset, const item<Dims, WithOffset>> getItem() {
[  173]     static_assert(is_valid_dimensions<Dims>::value, "invalid dimensions");
[  174]     id<Dims> GlobalId{__spirv::initGlobalInvocationId<Dims, id<Dims>>()};
[  175]     range<Dims> GlobalSize{__spirv::initGlobalSize<Dims, range<Dims>>()};
[  176]     return createItem<Dims, false>(GlobalSize, GlobalId);
[  177]   }
[  178] 
[  179]   template <int Dims> static const nd_item<Dims> getElement(nd_item<Dims> *) {
[  180]     static_assert(is_valid_dimensions<Dims>::value, "invalid dimensions");
[  181]     range<Dims> GlobalSize{__spirv::initGlobalSize<Dims, range<Dims>>()};
[  182]     range<Dims> LocalSize{__spirv::initWorkgroupSize<Dims, range<Dims>>()};
[  183]     range<Dims> GroupRange{__spirv::initNumWorkgroups<Dims, range<Dims>>()};
[  184]     id<Dims> GroupId{__spirv::initWorkgroupId<Dims, id<Dims>>()};
[  185]     id<Dims> GlobalId{__spirv::initGlobalInvocationId<Dims, id<Dims>>()};
[  186]     id<Dims> LocalId{__spirv::initLocalInvocationId<Dims, id<Dims>>()};
[  187]     id<Dims> GlobalOffset{__spirv::initGlobalOffset<Dims, id<Dims>>()};
[  188]     group<Dims> Group =
[  189]         createGroup<Dims>(GlobalSize, LocalSize, GroupRange, GroupId);
[  190]     item<Dims, true> GlobalItem =
[  191]         createItem<Dims, true>(GlobalSize, GlobalId, GlobalOffset);
[  192]     item<Dims, false> LocalItem = createItem<Dims, false>(LocalSize, LocalId);
[  193]     return createNDItem<Dims>(GlobalItem, LocalItem, Group);
[  194]   }
[  195] 
[  196]   template <int Dims, bool WithOffset>
[  197]   static auto getElement(item<Dims, WithOffset> *)
[  198]       -> decltype(getItem<Dims, WithOffset>()) {
[  199]     return getItem<Dims, WithOffset>();
[  200]   }
[  201] 
[  202]   template <int Dims>
[  203]   static auto getNDItem() -> decltype(getElement(declptr<nd_item<Dims>>())) {
[  204]     return getElement(declptr<nd_item<Dims>>());
[  205]   }
[  206] 
[  207] #endif // __SYCL_DEVICE_ONLY__
[  208] };
[  209] 
[  210] inline constexpr __spv::MemorySemanticsMask::Flag
[  211] getSPIRVMemorySemanticsMask(memory_order) {
[  212]   return __spv::MemorySemanticsMask::None;
[  213] }
[  214] 
[  215] inline constexpr uint32_t
[  216] getSPIRVMemorySemanticsMask(const access::fence_space AccessSpace,
[  217]                             const __spv::MemorySemanticsMask LocalScopeMask =
[  218]                                 __spv::MemorySemanticsMask::WorkgroupMemory) {
[  219]   // Huge ternary operator below is a workaround for constexpr function
[  220]   // requirement that such function can only contain return statement and
[  221]   // nothing more
[  222]   //
[  223]   // It is equivalent to the following code:
[  224]   //
[  225]   // uint32_t Flags =
[  226]   //     static_cast<uint32_t>(__spv::MemorySemanticsMask::SequentiallyConsistent);
[  227]   // switch (AccessSpace) {
[  228]   // case access::fence_space::global_space:
[  229]   //   Flags |=
[  230]   //       static_cast<uint32_t>(__spv::MemorySemanticsMask::CrossWorkgroupMemory);
[  231]   //   break;
[  232]   // case access::fence_space::local_space:
[  233]   //   Flags |= static_cast<uint32_t>(LocalScopeMask);
[  234]   //   break;
[  235]   // case access::fence_space::global_and_local:
[  236]   // default:
[  237]   //   Flags |= static_cast<uint32_t>(
[  238]   //                __spv::MemorySemanticsMask::CrossWorkgroupMemory) |
[  239]   //            static_cast<uint32_t>(LocalScopeMask);
[  240]   //   break;
[  241]   // }
[  242]   // return Flags;
[  243] 
[  244]   return (AccessSpace == access::fence_space::global_space)
[  245]              ? static_cast<uint32_t>(
[  246]                    __spv::MemorySemanticsMask::SequentiallyConsistent |
[  247]                    __spv::MemorySemanticsMask::CrossWorkgroupMemory)
[  248]          : (AccessSpace == access::fence_space::local_space)
[  249]              ? static_cast<uint32_t>(
[  250]                    __spv::MemorySemanticsMask::SequentiallyConsistent |
[  251]                    LocalScopeMask)
[  252]              : /* default: (AccessSpace ==
[  253]                   access::fence_space::global_and_local) */
[  254]              static_cast<uint32_t>(
[  255]                  __spv::MemorySemanticsMask::SequentiallyConsistent |
[  256]                  __spv::MemorySemanticsMask::CrossWorkgroupMemory |
[  257]                  LocalScopeMask);
[  258] }
[  259] 
[  260] // To ensure loop unrolling is done when processing dimensions.
[  261] template <size_t... Inds, class F>
[  262] void loop_impl(std::integer_sequence<size_t, Inds...>, F &&f) {
[  263]   // Partial temporary revert because of the CMPLRLLVM-47016.
[  264]   (f(Inds), ...);
[  265] }
[  266] 
[  267] template <size_t count, class F> void loop(F &&f) {
[  268]   loop_impl(std::make_index_sequence<count>{}, std::forward<F>(f));
[  269] }
[  270] } // namespace detail
[  271] 
[  272] } // namespace _V1
[  273] } // namespace sycl
=== File: /home/users/yuning/pg/qahpct/minitest/intelgpu/single.sycloffload.ipcx/../../src/compute.h ===
[    1] //  This file is #include'd as the core of the computations on the GPU or CPU
[    2] 
[    3] #if 0
[    4]     // do nothing at all
[    5] #endif
[    6] 
[    7] #if 0
[    8]     // set the result to one in the kernel
[    9]     d_p1[i] = 1.;
[   10] #endif
[   11] 
[   12] #if 0
[   13]     // decrement the result by one in the kernel
[   14]     d_p1[i] = d_p1[i] -1.;
[   15] #endif
[   16] 
[   17] #if 0
[   18]       // use transcendental function in the kernel
[   19] #ifndef kkmax
[   20] #define kkmax 2000
[   21] #endif
[   22] #ifdef INFORTRAN
[   23]     do kk = 1, kkmax
[   24]        d_p1(i) = d_p1(i) + 1. + (sqrt( exp( log (d_l1(i)*d_l1(i)) ) + exp( log (d_r1(i)*d_r1(i)) ) ) ) / &
[   25]                                 (sqrt( exp( log (d_l1(i)*d_r1(i)) ) + exp( log (d_r1(i)*d_l1(i)) ) ) )
[   26]     end do
[   27] #else
[   28]     for (int kk = 0 ; kk < kkmax ; kk++ ) {
[   29]       d_p1[i] = d_p1[i] + 1.+ (sqrt( exp( log (d_l1[i]*d_l1[i]) ) + exp( log (d_r1[i]*d_r1[i]) ) ) ) /
[   30]         ( sqrt (exp( log(d_l1[i]*d_r1[i]) ) + exp( log( (d_r1[i]*d_l1[i]) )) ) );
[   31]     }
[   32] #endif /* INFORTRAN */
[   33] #endif
[   34] 
[   35] #if 1
[   36]     // do a vector add in the kernel
[   37] #ifndef kkmax
[   38] #define kkmax 2000
[   39] #endif
[   40] #ifdef INFORTRAN
[   41]     do kk = 1, kkmax
[   42]        d_p1(i) = d_p1(i) + d_l1(nelements + 1 - kk) / real(kkmax, KIND=real64) + d_r1(kk) / real(kkmax, KIND=real64)
[   43]     end do
[   44] #else
[   45]     for (int kk = 0 ; kk < kkmax ; kk++ ) {
		[0x00180] (W)     mov (1|M0)               r41.2<1>:df   0.0005:df                             
		[0x00190] (W)     mov (1|M0)               r41.6<1>:d    0:w                              
		[0x00220] (W)     not (1|M0)               r4.15<1>:d    r41.6<0;1,0>:d                  
		[0x00338] (W)     or (1|M0)                r5.6<1>:d     r41.6<0;1,0>:d    15:w              
		[0x00348] (W)     cmp (32|M0)   (lt)f0.0   null<1>:ud    r5.6<0;1,0>:ud    0x7CF:uw              {I@1}
		[0x00A88] (W&~f0.0) jmpi                               L2744                                
		[0x00A98] (W)     add (1|M0)               r41.6<1>:d    r41.6<0;1,0>:d    16:w              
		[0x00AA8] (W)     jmpi                                 L432                                
[   46]       d_p1[i] = d_p1[i] + d_l1[nelements - kk] / double(kkmax) + d_r1[kk] / double(kkmax);
		[0x001E8] (W)     mov (1|M0)               r10.0<1>:uq   r7.0<0;1,0>:uq                   {Compacted,I@2}
		[0x001F0]         sync.nop                             null                             {Compacted,I@2}
		[0x001F8] (W)     mov (1|M0)               r25.0<1>:uq   r9.0<0;1,0>:uq                   {Compacted,$11.src}
		[0x00200] (W)     send.ugm (1|M0)          r26      r10     null:0  0x0            0x02108780           {I@2,$12} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00210] (W)     send.ugm (1|M0)          r44      r25     null:0  0x0            0x02108780           {I@1,$13} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00358]         sync.nop                             null                             {Compacted,L@1}
		[0x00360]         sync.nop                             null                             {Compacted,$13.dst}
		[0x00368]         mad (16|M0)              acc0.0<1>:df  r119.0<1;0>:df    r44.0<0;0>:df     r41.2<0>:df      {$3.dst}
		[0x00378]         mad (16|M16)             acc2.0<1>:df  r121.0<1;0>:df    r44.0<0;0>:df     r41.2<0>:df     
		[0x00388]         sync.nop                             null                             {Compacted,$10.src}
		[0x00390]         mad (16|M0)              r79.0<1>:df   acc0.0<1;0>:df    r26.0<0;0>:df     r41.2<0>:df      {$12.dst}
		[0x003A0]         mad (16|M16)             r81.0<1>:df   acc2.0<1;0>:df    r26.0<0;0>:df     r41.2<0>:df     
		[0x003B0]         send.ugm (32|M0)         null     r115    r79:4   0x0            0x08000784           {A@1,$14} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x003C0] (W)     send.ugm (1|M0)          r84      r28     null:0  0x0            0x02108780           {$15} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x003D0] (W)     send.ugm (1|M0)          r86      r12     null:0  0x0            0x02108780           {$0} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x003E0]         mad (16|M0)              acc0.0<1>:df  r79.0<1;0>:df     r84.0<0;0>:df     r41.2<0>:df      {$15.dst}
		[0x003F0]         mad (16|M16)             acc2.0<1>:df  r81.0<1;0>:df     r84.0<0;0>:df     r41.2<0>:df     
		[0x00400]         sync.nop                             null                             {Compacted,$9.src}
		[0x00408]         mad (16|M0)              r93.0<1>:df   acc0.0<1;0>:df    r86.0<0;0>:df     r41.2<0>:df      {$0.dst}
		[0x00418]         mad (16|M16)             r95.0<1>:df   acc2.0<1;0>:df    r86.0<0;0>:df     r41.2<0>:df     
		[0x00428]         send.ugm (32|M0)         null     r115    r93:4   0x0            0x08000784           {A@1,$1} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x00438] (W)     send.ugm (1|M0)          r98      r30     null:0  0x0            0x02108780           {$2} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00448] (W)     send.ugm (1|M0)          r100     r14     null:0  0x0            0x02108780           {$3} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00458]         mad (16|M0)              acc0.0<1>:df  r93.0<1;0>:df     r98.0<0;0>:df     r41.2<0>:df      {$2.dst}
		[0x00468]         mad (16|M16)             acc2.0<1>:df  r95.0<1;0>:df     r98.0<0;0>:df     r41.2<0>:df     
		[0x00478]         sync.nop                             null                             {Compacted,$5.src}
		[0x00480]         mad (16|M0)              r107.0<1>:df  acc0.0<1;0>:df    r100.0<0;0>:df    r41.2<0>:df      {$3.dst}
		[0x00490]         mad (16|M16)             r109.0<1>:df  acc2.0<1;0>:df    r100.0<0;0>:df    r41.2<0>:df     
		[0x004A0]         send.ugm (32|M0)         null     r115    r107:4  0x0            0x08000784           {A@1,$12} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x004B0] (W)     send.ugm (1|M0)          r112     r32     null:0  0x0            0x02108780           {$13} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x004C0] (W)     send.ugm (1|M0)          r114     r16     null:0  0x0            0x02108780           {$15} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x004D0]         mad (16|M0)              acc0.0<1>:df  r107.0<1;0>:df    r112.0<0;0>:df    r41.2<0>:df      {$13.dst}
		[0x004E0]         mad (16|M16)             acc2.0<1>:df  r109.0<1;0>:df    r112.0<0;0>:df    r41.2<0>:df     
		[0x004F0]         mad (16|M0)              r11.0<1>:df   acc0.0<1;0>:df    r114.0<0;0>:df    r41.2<0>:df      {$15.dst}
		[0x00500]         mad (16|M16)             r13.0<1>:df   acc2.0<1;0>:df    r114.0<0;0>:df    r41.2<0>:df     
		[0x00510]         send.ugm (32|M0)         null     r115    r11:4   0x0            0x08000784           {A@1,$0} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x00520] (W)     send.ugm (1|M0)          r16      r34     null:0  0x0            0x02108780           {$2} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00530] (W)     send.ugm (1|M0)          r18      r18     null:0  0x0            0x02108780           {$3} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00540]         mad (16|M0)              acc0.0<1>:df  r11.0<1;0>:df     r16.0<0;0>:df     r41.2<0>:df      {$2.dst}
		[0x00550]         mad (16|M16)             acc2.0<1>:df  r13.0<1;0>:df     r16.0<0;0>:df     r41.2<0>:df     
		[0x00560]         mad (16|M0)              r29.0<1>:df   acc0.0<1;0>:df    r18.0<0;0>:df     r41.2<0>:df      {$3.dst}
		[0x00570]         mad (16|M16)             r31.0<1>:df   acc2.0<1;0>:df    r18.0<0;0>:df     r41.2<0>:df     
		[0x00580]         send.ugm (32|M0)         null     r115    r29:4   0x0            0x08000784           {A@1,$13} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x00590] (W)     send.ugm (1|M0)          r34      r36     null:0  0x0            0x02108780           {$15} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x005A0]         sync.nop                             null                             {Compacted,$15.src}
		[0x005A8] (W)     send.ugm (1|M0)          r36      r20     null:0  0x0            0x02108780           {$2} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x005B8]         mad (16|M0)              acc0.0<1>:df  r29.0<1;0>:df     r34.0<0;0>:df     r41.2<0>:df      {$15.dst}
		[0x005C8]         mad (16|M16)             acc2.0<1>:df  r31.0<1;0>:df     r34.0<0;0>:df     r41.2<0>:df     
		[0x005D8]         mad (16|M0)              r77.0<1>:df   acc0.0<1;0>:df    r36.0<0;0>:df     r41.2<0>:df      {$2.dst}
		[0x005E8]         mad (16|M16)             r79.0<1>:df   acc2.0<1;0>:df    r36.0<0;0>:df     r41.2<0>:df      {$14.src}
		[0x005F8]         send.ugm (32|M0)         null     r115    r77:4   0x0            0x08000784           {A@1,$3} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x00608] (W)     send.ugm (1|M0)          r82      r38     null:0  0x0            0x02108780           {$15} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00618] (W)     send.ugm (1|M0)          r84      r22     null:0  0x0            0x02108780           {$2} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00628]         mad (16|M0)              acc0.0<1>:df  r77.0<1;0>:df     r82.0<0;0>:df     r41.2<0>:df      {$15.dst}
		[0x00638]         mad (16|M16)             acc2.0<1>:df  r79.0<1;0>:df     r82.0<0;0>:df     r41.2<0>:df     
		[0x00648]         mad (16|M0)              r91.0<1>:df   acc0.0<1;0>:df    r84.0<0;0>:df     r41.2<0>:df      {$2.dst}
		[0x00658]         mad (16|M16)             r93.0<1>:df   acc2.0<1;0>:df    r84.0<0;0>:df     r41.2<0>:df      {$1.src}
		[0x00668]         send.ugm (32|M0)         null     r115    r91:4   0x0            0x08000784           {A@1,$4} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x00678] (W)     send.ugm (1|M0)          r96      r40     null:0  0x0            0x02108780           {$5} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00688] (W)     send.ugm (1|M0)          r98      r24     null:0  0x0            0x02108780           {$14} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00698]         mad (16|M0)              acc0.0<1>:df  r91.0<1;0>:df     r96.0<0;0>:df     r41.2<0>:df      {$5.dst}
		[0x006A8]         mad (16|M16)             acc2.0<1>:df  r93.0<1;0>:df     r96.0<0;0>:df     r41.2<0>:df     
		[0x006B8]         mad (16|M0)              r105.0<1>:df  acc0.0<1;0>:df    r98.0<0;0>:df     r41.2<0>:df      {$14.dst}
		[0x006C8]         mad (16|M16)             r107.0<1>:df  acc2.0<1;0>:df    r98.0<0;0>:df     r41.2<0>:df      {$12.src}
		[0x006D8]         send.ugm (32|M0)         null     r115    r105:4  0x0            0x08000784           {A@1,$15} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x006E8] (W)     send.ugm (1|M0)          r110     r42     null:0  0x0            0x02108780           {$2} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x006F8] (W)     send.ugm (1|M0)          r112     r46     null:0  0x0            0x02108780           {$1} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00708]         mad (16|M0)              acc0.0<1>:df  r105.0<1;0>:df    r110.0<0;0>:df    r41.2<0>:df      {$2.dst}
		[0x00718]         mad (16|M16)             acc2.0<1>:df  r107.0<1;0>:df    r110.0<0;0>:df    r41.2<0>:df     
		[0x00728]         mad (16|M0)              r9.0<1>:df    acc0.0<1;0>:df    r112.0<0;0>:df    r41.2<0>:df      {$1.dst}
		[0x00738]         mad (16|M16)             r11.0<1>:df   acc2.0<1;0>:df    r112.0<0;0>:df    r41.2<0>:df      {$0.src}
		[0x00748]         send.ugm (32|M0)         null     r115    r9:4    0x0            0x08000784           {A@1,$7} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x00758] (W)     send.ugm (1|M0)          r14      r48     null:0  0x0            0x02108780           {$14} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00768] (W)     send.ugm (1|M0)          r16      r50     null:0  0x0            0x02108780           {$12} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00778]         mad (16|M0)              acc0.0<1>:df  r9.0<1;0>:df      r14.0<0;0>:df     r41.2<0>:df      {$14.dst}
		[0x00788]         mad (16|M16)             acc2.0<1>:df  r11.0<1;0>:df     r14.0<0;0>:df     r41.2<0>:df     
		[0x00798]         mad (16|M0)              r23.0<1>:df   acc0.0<1;0>:df    r16.0<0;0>:df     r41.2<0>:df      {$12.dst}
		[0x007A8]         mad (16|M16)             r25.0<1>:df   acc2.0<1;0>:df    r16.0<0;0>:df     r41.2<0>:df     
		[0x007B8]         send.ugm (32|M0)         null     r115    r23:4   0x0            0x08000784           {A@1,$11} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x007C8] (W)     send.ugm (1|M0)          r28      r52     null:0  0x0            0x02108780           {$2} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x007D8]         sync.nop                             null                             {Compacted,$13.src}
		[0x007E0] (W)     send.ugm (1|M0)          r30      r54     null:0  0x0            0x02108780           {$1} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x007F0]         mad (16|M0)              acc0.0<1>:df  r23.0<1;0>:df     r28.0<0;0>:df     r41.2<0>:df      {$2.dst}
		[0x00800]         mad (16|M16)             acc2.0<1>:df  r25.0<1;0>:df     r28.0<0;0>:df     r41.2<0>:df     
		[0x00810]         mad (16|M0)              r37.0<1>:df   acc0.0<1;0>:df    r30.0<0;0>:df     r41.2<0>:df      {$1.dst}
		[0x00820]         mad (16|M16)             r39.0<1>:df   acc2.0<1;0>:df    r30.0<0;0>:df     r41.2<0>:df     
		[0x00830]         send.ugm (32|M0)         null     r115    r37:4   0x0            0x08000784           {A@1,$6} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x00840] (W)     send.ugm (1|M0)          r42      r56     null:0  0x0            0x02108780           {$0} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00850] (W)     send.ugm (1|M0)          r44      r58     null:0  0x0            0x02108780           {$12} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00860]         mad (16|M0)              acc0.0<1>:df  r37.0<1;0>:df     r42.0<0;0>:df     r41.2<0>:df      {$0.dst}
		[0x00870]         mad (16|M16)             acc2.0<1>:df  r39.0<1;0>:df     r42.0<0;0>:df     r41.2<0>:df     
		[0x00880]         mad (16|M0)              r51.0<1>:df   acc0.0<1;0>:df    r44.0<0;0>:df     r41.2<0>:df      {$12.dst}
		[0x00890]         mad (16|M16)             r53.0<1>:df   acc2.0<1;0>:df    r44.0<0;0>:df     r41.2<0>:df     
		[0x008A0]         send.ugm (32|M0)         null     r115    r51:4   0x0            0x08000784           {A@1,$8} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x008B0] (W)     send.ugm (1|M0)          r56      r60     null:0  0x0            0x02108780           {$14} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x008C0] (W)     send.ugm (1|M0)          r58      r62     null:0  0x0            0x02108780           {$0} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x008D0]         mad (16|M0)              acc0.0<1>:df  r51.0<1;0>:df     r56.0<0;0>:df     r41.2<0>:df      {$14.dst}
		[0x008E0]         mad (16|M16)             acc2.0<1>:df  r53.0<1;0>:df     r56.0<0;0>:df     r41.2<0>:df     
		[0x008F0]         sync.nop                             null                             {Compacted,$3.src}
		[0x008F8]         mad (16|M0)              r77.0<1>:df   acc0.0<1;0>:df    r58.0<0;0>:df     r41.2<0>:df      {$0.dst}
		[0x00908]         mad (16|M16)             r79.0<1>:df   acc2.0<1;0>:df    r58.0<0;0>:df     r41.2<0>:df     
		[0x00918]         send.ugm (32|M0)         null     r115    r77:4   0x0            0x08000784           {A@1,$10} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x00928] (W)     send.ugm (1|M0)          r82      r64     null:0  0x0            0x02108780           {$1} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00938] (W)     send.ugm (1|M0)          r84      r66     null:0  0x0            0x02108780           {$2} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00948]         mad (16|M0)              acc0.0<1>:df  r77.0<1;0>:df     r82.0<0;0>:df     r41.2<0>:df      {$1.dst}
		[0x00958]         mad (16|M16)             acc2.0<1>:df  r79.0<1;0>:df     r82.0<0;0>:df     r41.2<0>:df     
		[0x00968]         sync.nop                             null                             {Compacted,$4.src}
		[0x00970]         mad (16|M0)              r91.0<1>:df   acc0.0<1;0>:df    r84.0<0;0>:df     r41.2<0>:df      {$2.dst}
		[0x00980]         mad (16|M16)             r93.0<1>:df   acc2.0<1;0>:df    r84.0<0;0>:df     r41.2<0>:df     
		[0x00990]         send.ugm (32|M0)         null     r115    r91:4   0x0            0x08000784           {A@1,$9} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x009A0] (W)     send.ugm (1|M0)          r96      r68     null:0  0x0            0x02108780           {$3} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x009B0] (W)     send.ugm (1|M0)          r98      r70     null:0  0x0            0x02108780           {$12} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x009C0]         mad (16|M0)              acc0.0<1>:df  r91.0<1;0>:df     r96.0<0;0>:df     r41.2<0>:df      {$3.dst}
		[0x009D0]         mad (16|M16)             acc2.0<1>:df  r93.0<1;0>:df     r96.0<0;0>:df     r41.2<0>:df     
		[0x009E0]         sync.nop                             null                             {Compacted,$15.src}
		[0x009E8]         mad (16|M0)              r105.0<1>:df  acc0.0<1;0>:df    r98.0<0;0>:df     r41.2<0>:df      {$12.dst}
		[0x009F8]         mad (16|M16)             r107.0<1>:df  acc2.0<1;0>:df    r98.0<0;0>:df     r41.2<0>:df     
		[0x00A08]         send.ugm (32|M0)         null     r115    r105:4  0x0            0x08000784           {A@1,$5} // wr:4+4, rd:0; store.ugm.d64.a64
		[0x00A18] (W)     send.ugm (1|M0)          r110     r72     null:0  0x0            0x02108780           {$13} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00A28] (W)     send.ugm (1|M0)          r112     r74     null:0  0x0            0x02108780           {$14} // wr:1+0, rd:1; load.ugm.d64x1t.a64
		[0x00A38]         mad (16|M0)              acc0.0<1>:df  r105.0<1;0>:df    r110.0<0;0>:df    r41.2<0>:df      {$13.dst}
		[0x00A48]         mad (16|M16)             acc2.0<1>:df  r107.0<1;0>:df    r110.0<0;0>:df    r41.2<0>:df     
		[0x00A58]         mad (16|M0)              r119.0<1>:df  acc0.0<1;0>:df    r112.0<0;0>:df    r41.2<0>:df      {$14.dst}
		[0x00A68]         mad (16|M16)             r121.0<1>:df  acc2.0<1;0>:df    r112.0<0;0>:df    r41.2<0>:df     
		[0x00A78]         send.ugm (32|M0)         null     r115    r119:4  0x0            0x08000784           {A@1,$4} // wr:4+4, rd:0; store.ugm.d64.a64
[   47]     }
[   48] #endif /* INFORTRAN */
[   49] #endif
=== File: /storage/users/yuning/intel/oneapi/compiler/2024.1/bin/compiler/../../include/sycl/handler.hpp ===
[    1] //==-------- handler.hpp --- SYCL command group handler --------------------==//
[    2] //
[    3] // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
[    4] // See https://llvm.org/LICENSE.txt for license information.
[    5] // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
[    6] //
[    7] //===----------------------------------------------------------------------===//
[    8] 
[    9] #pragma once
[   10] 
[   11] #include <sycl/access/access.hpp>
[   12] #include <sycl/accessor.hpp>
[   13] #include <sycl/context.hpp>
[   14] #include <sycl/detail/array.hpp>
[   15] #include <sycl/detail/cg.hpp>
[   16] #include <sycl/detail/cg_types.hpp>
[   17] #include <sycl/detail/cl.h>
[   18] #include <sycl/detail/common.hpp>
[   19] #include <sycl/detail/defines_elementary.hpp>
[   20] #include <sycl/detail/export.hpp>
[   21] #include <sycl/detail/helpers.hpp>
[   22] #include <sycl/detail/impl_utils.hpp>
[   23] #include <sycl/detail/item_base.hpp>
[   24] #include <sycl/detail/kernel_desc.hpp>
[   25] #include <sycl/detail/pi.h>
[   26] #include <sycl/detail/pi.hpp>
[   27] #include <sycl/detail/reduction_forward.hpp>
[   28] #include <sycl/device.hpp>
[   29] #include <sycl/event.hpp>
[   30] #include <sycl/exception.hpp>
[   31] #include <sycl/exception_list.hpp>
[   32] #include <sycl/ext/intel/experimental/fp_control_kernel_properties.hpp>
[   33] #include <sycl/ext/intel/experimental/kernel_execution_properties.hpp>
[   34] #include <sycl/ext/oneapi/bindless_images_descriptor.hpp>
[   35] #include <sycl/ext/oneapi/bindless_images_interop.hpp>
[   36] #include <sycl/ext/oneapi/bindless_images_memory.hpp>
[   37] #include <sycl/ext/oneapi/device_global/device_global.hpp>
[   38] #include <sycl/ext/oneapi/device_global/properties.hpp>
[   39] #include <sycl/ext/oneapi/experimental/graph.hpp>
[   40] #include <sycl/ext/oneapi/kernel_properties/properties.hpp>
[   41] #include <sycl/ext/oneapi/properties/properties.hpp>
[   42] #include <sycl/group.hpp>
[   43] #include <sycl/id.hpp>
[   44] #include <sycl/interop_handle.hpp>
[   45] #include <sycl/item.hpp>
[   46] #include <sycl/kernel.hpp>
[   47] #include <sycl/kernel_bundle.hpp>
[   48] #include <sycl/kernel_bundle_enums.hpp>
[   49] #include <sycl/kernel_handler.hpp>
[   50] #include <sycl/nd_item.hpp>
[   51] #include <sycl/nd_range.hpp>
[   52] #include <sycl/property_list.hpp>
[   53] #include <sycl/range.hpp>
[   54] #include <sycl/sampler.hpp>
[   55] #include <sycl/types.hpp>
[   56] #include <sycl/usm/usm_enums.hpp>
[   57] #include <sycl/usm/usm_pointer_info.hpp>
[   58] 
[   59] #include <assert.h>
[   60] #include <functional>
[   61] #include <memory>
[   62] #include <stddef.h>
[   63] #include <stdint.h>
[   64] #include <string>
[   65] #include <tuple>
[   66] #include <type_traits>
[   67] #include <utility>
[   68] #include <vector>
[   69] 
[   70] // TODO: refactor this header
[   71] // 47(!!!) includes of SYCL headers + 10 includes of standard headers.
[   72] // 3300+ lines of code
[   73] 
[   74] // SYCL_LANGUAGE_VERSION is 4 digit year followed by 2 digit revision
[   75] #if !SYCL_LANGUAGE_VERSION || SYCL_LANGUAGE_VERSION < 202001
[   76] #define __SYCL_NONCONST_FUNCTOR__
[   77] #endif
[   78] 
[   79] // replace _KERNELFUNCPARAM(KernelFunc) with   KernelType KernelFunc
[   80] //                                     or     const KernelType &KernelFunc
[   81] #ifdef __SYCL_NONCONST_FUNCTOR__
[   82] #define _KERNELFUNCPARAMTYPE KernelType
[   83] #else
[   84] #define _KERNELFUNCPARAMTYPE const KernelType &
[   85] #endif
[   86] #define _KERNELFUNCPARAM(a) _KERNELFUNCPARAMTYPE a
[   87] 
[   88] #if defined(__SYCL_UNNAMED_LAMBDA__)
[   89] // We can't use nested types (e.g. struct S defined inside main() routine) to
[   90] // name kernels. At the same time, we have to provide a unique kernel name for
[   91] // sycl::fill and the only thing we can use to introduce that uniqueness (in
[   92] // general) is the template parameter T which might be exactly that nested type.
[   93] // That means we cannot support sycl::fill(void *, T&, size_t) for such types in
[   94] // general. However, we can do better than that when unnamed lambdas are
[   95] // enabled, so do it here! See also https://github.com/intel/llvm/issues/469.
[   96] template <typename DataT, int Dimensions, sycl::access::mode AccessMode,
[   97]           sycl::access::target AccessTarget,
[   98]           sycl::access::placeholder IsPlaceholder>
[   99] using __fill = sycl::detail::auto_name;
[  100] template <typename T> using __usmfill = sycl::detail::auto_name;
[  101] template <typename T> using __usmfill2d = sycl::detail::auto_name;
[  102] template <typename T> using __usmmemcpy2d = sycl::detail::auto_name;
[  103] 
[  104] template <typename T_Src, typename T_Dst, int Dims,
[  105]           sycl::access::mode AccessMode, sycl::access::target AccessTarget,
[  106]           sycl::access::placeholder IsPlaceholder>
[  107] using __copyAcc2Ptr = sycl::detail::auto_name;
[  108] 
[  109] template <typename T_Src, typename T_Dst, int Dims,
[  110]           sycl::access::mode AccessMode, sycl::access::target AccessTarget,
[  111]           sycl::access::placeholder IsPlaceholder>
[  112] using __copyPtr2Acc = sycl::detail::auto_name;
[  113] 
[  114] template <typename T_Src, int Dims_Src, sycl::access::mode AccessMode_Src,
[  115]           sycl::access::target AccessTarget_Src, typename T_Dst, int Dims_Dst,
[  116]           sycl::access::mode AccessMode_Dst,
[  117]           sycl::access::target AccessTarget_Dst,
[  118]           sycl::access::placeholder IsPlaceholder_Src,
[  119]           sycl::access::placeholder IsPlaceholder_Dst>
[  120] using __copyAcc2Acc = sycl::detail::auto_name;
[  121] #else
[  122] // Limited fallback path for when unnamed lambdas aren't available. Cannot
[  123] // handle nested types.
[  124] template <typename DataT, int Dimensions, sycl::access::mode AccessMode,
[  125]           sycl::access::target AccessTarget,
[  126]           sycl::access::placeholder IsPlaceholder>
[  127] class __fill;
[  128] template <typename T> class __usmfill;
[  129] template <typename T> class __usmfill2d;
[  130] template <typename T> class __usmmemcpy2d;
[  131] 
[  132] template <typename T_Src, typename T_Dst, int Dims,
[  133]           sycl::access::mode AccessMode, sycl::access::target AccessTarget,
[  134]           sycl::access::placeholder IsPlaceholder>
[  135] class __copyAcc2Ptr;
[  136] 
[  137] template <typename T_Src, typename T_Dst, int Dims,
[  138]           sycl::access::mode AccessMode, sycl::access::target AccessTarget,
[  139]           sycl::access::placeholder IsPlaceholder>
[  140] class __copyPtr2Acc;
[  141] 
[  142] template <typename T_Src, int Dims_Src, sycl::access::mode AccessMode_Src,
[  143]           sycl::access::target AccessTarget_Src, typename T_Dst, int Dims_Dst,
[  144]           sycl::access::mode AccessMode_Dst,
[  145]           sycl::access::target AccessTarget_Dst,
[  146]           sycl::access::placeholder IsPlaceholder_Src,
[  147]           sycl::access::placeholder IsPlaceholder_Dst>
[  148] class __copyAcc2Acc;
[  149] #endif
[  150] 
[  151] // For unit testing purposes
[  152] class MockHandler;
[  153] 
[  154] namespace sycl {
[  155] inline namespace _V1 {
[  156] 
[  157] // Forward declaration
[  158] 
[  159] class handler;
[  160] template <typename T, int Dimensions, typename AllocatorT, typename Enable>
[  161] class buffer;
[  162] 
[  163] namespace ext::intel::experimental {
[  164] template <class _name, class _dataT, int32_t _min_capacity, class _propertiesT,
[  165]           class>
[  166] class pipe;
[  167] }
[  168] 
[  169] namespace ext::oneapi::experimental::detail {
[  170] class graph_impl;
[  171] } // namespace ext::oneapi::experimental::detail
[  172] namespace detail {
[  173] 
[  174] class handler_impl;
[  175] class kernel_impl;
[  176] class queue_impl;
[  177] class stream_impl;
[  178] template <typename DataT, int Dimensions, access::mode AccessMode,
[  179]           access::target AccessTarget, access::placeholder IsPlaceholder>
[  180] class image_accessor;
[  181] template <typename RetType, typename Func, typename Arg>
[  182] static Arg member_ptr_helper(RetType (Func::*)(Arg) const);
[  183] 
[  184] // Non-const version of the above template to match functors whose 'operator()'
[  185] // is declared w/o the 'const' qualifier.
[  186] template <typename RetType, typename Func, typename Arg>
[  187] static Arg member_ptr_helper(RetType (Func::*)(Arg));
[  188] 
[  189] // Version with two arguments to handle the case when kernel_handler is passed
[  190] // to a lambda
[  191] template <typename RetType, typename Func, typename Arg1, typename Arg2>
[  192] static Arg1 member_ptr_helper(RetType (Func::*)(Arg1, Arg2) const);
[  193] 
[  194] // Non-const version of the above template to match functors whose 'operator()'
[  195] // is declared w/o the 'const' qualifier.
[  196] template <typename RetType, typename Func, typename Arg1, typename Arg2>
[  197] static Arg1 member_ptr_helper(RetType (Func::*)(Arg1, Arg2));
[  198] 
[  199] template <typename F, typename SuggestedArgType>
[  200] decltype(member_ptr_helper(&F::operator())) argument_helper(int);
[  201] 
[  202] template <typename F, typename SuggestedArgType>
[  203] SuggestedArgType argument_helper(...);
[  204] 
[  205] template <typename F, typename SuggestedArgType>
[  206] using lambda_arg_type = decltype(argument_helper<F, SuggestedArgType>(0));
[  207] 
[  208] // Used when parallel_for range is rounded-up.
[  209] template <typename Name> class __pf_kernel_wrapper;
[  210] 
[  211] template <typename Type> struct get_kernel_wrapper_name_t {
[  212]   using name = __pf_kernel_wrapper<Type>;
[  213] };
[  214] 
[  215] __SYCL_EXPORT device getDeviceFromHandler(handler &);
[  216] 
[  217] // Checks if a device_global has any registered kernel usage.
[  218] __SYCL_EXPORT bool isDeviceGlobalUsedInKernel(const void *DeviceGlobalPtr);
[  219] 
[  220] #if __SYCL_ID_QUERIES_FIT_IN_INT__
[  221] template <typename T> struct NotIntMsg;
[  222] 
[  223] template <int Dims> struct NotIntMsg<range<Dims>> {
[  224]   constexpr static const char *Msg =
[  225]       "Provided range is out of integer limits. Pass "
[  226]       "`-fno-sycl-id-queries-fit-in-int' to disable range check.";
[  227] };
[  228] 
[  229] template <int Dims> struct NotIntMsg<id<Dims>> {
[  230]   constexpr static const char *Msg =
[  231]       "Provided offset is out of integer limits. Pass "
[  232]       "`-fno-sycl-id-queries-fit-in-int' to disable offset check.";
[  233] };
[  234] #endif
[  235] 
[  236] // Helper for merging properties with ones defined in an optional kernel functor
[  237] // getter.
[  238] template <typename KernelType, typename PropertiesT, typename Cond = void>
[  239] struct GetMergedKernelProperties {
[  240]   using type = PropertiesT;
[  241] };
[  242] template <typename KernelType, typename PropertiesT>
[  243] struct GetMergedKernelProperties<
[  244]     KernelType, PropertiesT,
[  245]     std::enable_if_t<ext::oneapi::experimental::detail::
[  246]                          HasKernelPropertiesGetMethod<KernelType>::value>> {
[  247]   using get_method_properties =
[  248]       typename ext::oneapi::experimental::detail::HasKernelPropertiesGetMethod<
[  249]           KernelType>::properties_t;
[  250]   static_assert(
[  251]       ext::oneapi::experimental::is_property_list<get_method_properties>::value,
[  252]       "get(sycl::ext::oneapi::experimental::properties_tag) member in kernel "
[  253]       "functor class must return a valid property list.");
[  254]   using type = ext::oneapi::experimental::detail::merged_properties_t<
[  255]       PropertiesT, get_method_properties>;
[  256] };
[  257] 
[  258] #if __SYCL_ID_QUERIES_FIT_IN_INT__
[  259] template <typename T, typename ValT>
[  260] typename std::enable_if_t<std::is_same<ValT, size_t>::value ||
[  261]                           std::is_same<ValT, unsigned long long>::value>
[  262] checkValueRangeImpl(ValT V) {
[  263]   static constexpr size_t Limit =
[  264]       static_cast<size_t>((std::numeric_limits<int>::max)());
[  265]   if (V > Limit)
[  266]     throw sycl::exception(make_error_code(errc::nd_range), NotIntMsg<T>::Msg);
[  267] }
[  268] #endif
[  269] 
[  270] template <int Dims, typename T>
[  271] typename std::enable_if_t<std::is_same_v<T, range<Dims>> ||
[  272]                           std::is_same_v<T, id<Dims>>>
[  273] checkValueRange(const T &V) {
[  274] #if __SYCL_ID_QUERIES_FIT_IN_INT__
[  275]   for (size_t Dim = 0; Dim < Dims; ++Dim)
[  276]     checkValueRangeImpl<T>(V[Dim]);
[  277] 
[  278]   {
[  279]     unsigned long long Product = 1;
[  280]     for (size_t Dim = 0; Dim < Dims; ++Dim) {
[  281]       Product *= V[Dim];
[  282]       // check value now to prevent product overflow in the end
[  283]       checkValueRangeImpl<T>(Product);
[  284]     }
[  285]   }
[  286] #else
[  287]   (void)V;
[  288] #endif
[  289] }
[  290] 
[  291] template <int Dims>
[  292] void checkValueRange(const range<Dims> &R, const id<Dims> &O) {
[  293] #if __SYCL_ID_QUERIES_FIT_IN_INT__
[  294]   checkValueRange<Dims>(R);
[  295]   checkValueRange<Dims>(O);
[  296] 
[  297]   for (size_t Dim = 0; Dim < Dims; ++Dim) {
[  298]     unsigned long long Sum = R[Dim] + O[Dim];
[  299] 
[  300]     checkValueRangeImpl<range<Dims>>(Sum);
[  301]   }
[  302] #else
[  303]   (void)R;
[  304]   (void)O;
[  305] #endif
[  306] }
[  307] 
[  308] template <int Dims, typename T>
[  309] typename std::enable_if_t<std::is_same_v<T, nd_range<Dims>>>
[  310] checkValueRange(const T &V) {
[  311] #if __SYCL_ID_QUERIES_FIT_IN_INT__
[  312]   checkValueRange<Dims>(V.get_global_range());
[  313]   checkValueRange<Dims>(V.get_local_range());
[  314]   checkValueRange<Dims>(V.get_offset());
[  315] 
[  316]   checkValueRange<Dims>(V.get_global_range(), V.get_offset());
[  317] #else
[  318]   (void)V;
[  319] #endif
[  320] }
[  321] 
[  322] template <int Dims> class RoundedRangeIDGenerator {
[  323]   id<Dims> Id;
[  324]   id<Dims> InitId;
[  325]   range<Dims> UserRange;
[  326]   range<Dims> RoundedRange;
[  327]   bool Done = false;
[  328] 
[  329] public:
[  330]   RoundedRangeIDGenerator(const id<Dims> &Id, const range<Dims> &UserRange,
[  331]                           const range<Dims> &RoundedRange)
[  332]       : Id(Id), InitId(Id), UserRange(UserRange), RoundedRange(RoundedRange) {
[  333]     for (int i = 0; i < Dims; ++i)
[  334]       if (Id[i] >= UserRange[i])
[  335]         Done = true;
[  336]   }
[  337] 
[  338]   explicit operator bool() { return !Done; }
[  339] 
[  340]   void updateId() {
[  341]     for (int i = 0; i < Dims; ++i) {
[  342]       Id[i] += RoundedRange[i];
[  343]       if (Id[i] < UserRange[i])
[  344]         return;
[  345]       Id[i] = InitId[i];
[  346]     }
[  347]     Done = true;
[  348]   }
[  349] 
[  350]   id<Dims> getId() { return Id; }
[  351] 
[  352]   template <typename KernelType> auto getItem() {
[  353]     if constexpr (std::is_invocable_v<KernelType, item<Dims> &> ||
[  354]                   std::is_invocable_v<KernelType, item<Dims> &, kernel_handler>)
[  355]       return detail::Builder::createItem<Dims, true>(UserRange, getId(), {});
[  356]     else {
[  357]       static_assert(std::is_invocable_v<KernelType, item<Dims, false> &> ||
[  358]                         std::is_invocable_v<KernelType, item<Dims, false> &,
[  359]                                             kernel_handler>,
[  360]                     "Kernel must be invocable with an item!");
[  361]       return detail::Builder::createItem<Dims, false>(UserRange, getId());
[  362]     }
[  363]   }
[  364] };
[  365] 
[  366] // TODO: The wrappers can be optimized further so that the body
[  367] // essentially looks like this:
[  368] //   for (auto z = it[2]; z < UserRange[2]; z += it.get_range(2))
[  369] //     for (auto y = it[1]; y < UserRange[1]; y += it.get_range(1))
[  370] //       for (auto x = it[0]; x < UserRange[0]; x += it.get_range(0))
[  371] //         KernelFunc({x,y,z});
[  372] template <typename TransformedArgType, int Dims, typename KernelType>
[  373] class RoundedRangeKernel {
[  374] public:
[  375]   range<Dims> UserRange;
[  376]   KernelType KernelFunc;
[  377]   void operator()(item<Dims> It) const {
[  378]     auto RoundedRange = It.get_range();
[  379]     for (RoundedRangeIDGenerator Gen(It.get_id(), UserRange, RoundedRange); Gen;
[  380]          Gen.updateId()) {
[  381]       auto item = Gen.template getItem<KernelType>();
[  382]       KernelFunc(item);
[  383]     }
[  384]   }
[  385] };
[  386] 
[  387] template <typename TransformedArgType, int Dims, typename KernelType>
[  388] class RoundedRangeKernelWithKH {
[  389] public:
[  390]   range<Dims> UserRange;
[  391]   KernelType KernelFunc;
[  392]   void operator()(item<Dims> It, kernel_handler KH) const {
[  393]     auto RoundedRange = It.get_range();
[  394]     for (RoundedRangeIDGenerator Gen(It.get_id(), UserRange, RoundedRange); Gen;
[  395]          Gen.updateId()) {
[  396]       auto item = Gen.template getItem<KernelType>();
[  397]       KernelFunc(item, KH);
[  398]     }
[  399]   }
[  400] };
[  401] 
[  402] using std::enable_if_t;
[  403] using sycl::detail::queue_impl;
[  404] 
[  405] // Returns true if x*y will overflow in T;
[  406] // otherwise, returns false and stores x*y in dst.
[  407] template <typename T>
[  408] static std::enable_if_t<std::is_unsigned_v<T>, bool>
[  409] multiply_with_overflow_check(T &dst, T x, T y) {
[  410]   dst = x * y;
[  411]   return (y != 0) && (x > (std::numeric_limits<T>::max)() / y);
[  412] }
[  413] 
[  414] template <int Dims> bool range_size_fits_in_size_t(const range<Dims> &r) {
[  415]   size_t acc = 1;
[  416]   for (int i = 0; i < Dims; ++i) {
[  417]     bool did_overflow = multiply_with_overflow_check(acc, acc, r[i]);
[  418]     if (did_overflow)
[  419]       return false;
[  420]   }
[  421]   return true;
[  422] }
[  423] 
[  424] } // namespace detail
[  425] 
[  426] /// Command group handler class.
[  427] ///
[  428] /// Objects of the handler class collect information about command group, such
[  429] /// as kernel, requirements to the memory, arguments for the kernel.
[  430] ///
[  431] /// \code{.cpp}
[  432] /// sycl::queue::submit([](handler &CGH){
[  433] ///   CGH.require(Accessor1);   // Adds a requirement to the memory object.
[  434] ///   CGH.setArg(0, Accessor2); // Registers accessor given as an argument to
[  435] ///                             // the kernel + adds a requirement to the memory
[  436] ///                             // object.
[  437] ///   CGH.setArg(1, N);         // Registers value given as an argument to the
[  438] ///                             // kernel.
[  439] ///   // The following registers KernelFunctor to be a kernel that will be
[  440] ///   // executed in case of queue is bound to the host device, Kernel - for
[  441] ///   // an OpenCL device. This function clearly indicates that command group
[  442] ///   // represents kernel execution.
[  443] ///   CGH.parallel_for(KernelFunctor, Kernel);
[  444] ///  });
[  445] /// \endcode
[  446] ///
[  447] /// The command group can represent absolutely different operations. Depending
[  448] /// on the operation we need to store different data. But, in most cases, it's
[  449] /// impossible to say what kind of operation we need to perform until the very
[  450] /// end. So, handler class contains all fields simultaneously, then during
[  451] /// "finalization" it constructs CG object, that represents specific operation,
[  452] /// passing fields that are required only.
[  453] ///
[  454] /// \sa queue
[  455] /// \sa program
[  456] /// \sa kernel
[  457] ///
[  458] /// \ingroup sycl_api
[  459] class __SYCL_EXPORT handler {
[  460] private:
[  461]   /// Constructs SYCL handler from queue.
[  462]   ///
[  463]   /// \param Queue is a SYCL queue.
[  464]   /// \param IsHost indicates if this handler is created for SYCL host device.
[  465]   handler(std::shared_ptr<detail::queue_impl> Queue, bool IsHost);
[  466] 
[  467]   /// Constructs SYCL handler from the associated queue and the submission's
[  468]   /// primary and secondary queue.
[  469]   ///
[  470]   /// \param Queue is a SYCL queue. This is equal to either PrimaryQueue or
[  471]   ///        SecondaryQueue.
[  472]   /// \param PrimaryQueue is the primary SYCL queue of the submission.
[  473]   /// \param SecondaryQueue is the secondary SYCL queue of the submission. This
[  474]   ///        is null if no secondary queue is associated with the submission.
[  475]   /// \param IsHost indicates if this handler is created for SYCL host device.
[  476]   handler(std::shared_ptr<detail::queue_impl> Queue,
[  477]           std::shared_ptr<detail::queue_impl> PrimaryQueue,
[  478]           std::shared_ptr<detail::queue_impl> SecondaryQueue, bool IsHost);
[  479] 
[  480]   /// Constructs SYCL handler from Graph.
[  481]   ///
[  482]   /// The hander will add the command-group as a node to the graph rather than
[  483]   /// enqueueing it straight away.
[  484]   ///
[  485]   /// \param Graph is a SYCL command_graph
[  486]   handler(std::shared_ptr<ext::oneapi::experimental::detail::graph_impl> Graph);
[  487] 
[  488]   /// Stores copy of Arg passed to the CGData.MArgsStorage.
[  489]   template <typename T, typename F = typename std::remove_const_t<
[  490]                             typename std::remove_reference_t<T>>>
[  491]   F *storePlainArg(T &&Arg) {
[  492]     CGData.MArgsStorage.emplace_back(sizeof(T));
[  493]     auto Storage = reinterpret_cast<F *>(CGData.MArgsStorage.back().data());
[  494]     *Storage = Arg;
[  495]     return Storage;
[  496]   }
[  497] 
[  498]   void setType(detail::CG::CGTYPE Type) { MCGType = Type; }
[  499] 
[  500]   detail::CG::CGTYPE getType() { return MCGType; }
[  501] 
[  502]   void throwIfActionIsCreated() {
[  503]     if (detail::CG::None != getType())
[  504]       throw sycl::exception(make_error_code(errc::runtime),
[  505]                             "Attempt to set multiple actions for the "
[  506]                             "command group. Command group must consist of "
[  507]                             "a single kernel or explicit memory operation.");
[  508]   }
[  509] 
[  510]   constexpr static int AccessTargetMask = 0x7ff;
[  511]   /// According to section 4.7.6.11. of the SYCL specification, a local accessor
[  512]   /// must not be used in a SYCL kernel function that is invoked via single_task
[  513]   /// or via the simple form of parallel_for that takes a range parameter.
[  514]   template <typename KernelName, typename KernelType>
[  515]   void throwOnLocalAccessorMisuse() const {
[  516]     using NameT =
[  517]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[  518]     using KI = sycl::detail::KernelInfo<NameT>;
[  519] 
[  520]     auto *KernelArgs = &KI::getParamDesc(0);
[  521] 
[  522]     for (unsigned I = 0; I < KI::getNumParams(); ++I) {
[  523]       const detail::kernel_param_kind_t &Kind = KernelArgs[I].kind;
[  524]       const access::target AccTarget =
[  525]           static_cast<access::target>(KernelArgs[I].info & AccessTargetMask);
[  526]       if ((Kind == detail::kernel_param_kind_t::kind_accessor) &&
[  527]           (AccTarget == target::local))
[  528]         throw sycl::exception(
[  529]             make_error_code(errc::kernel_argument),
[  530]             "A local accessor must not be used in a SYCL kernel function "
[  531]             "that is invoked via single_task or via the simple form of "
[  532]             "parallel_for that takes a range parameter.");
[  533]     }
[  534]   }
[  535] 
[  536]   /// Extracts and prepares kernel arguments from the lambda using integration
[  537]   /// header.
[  538]   void
[  539]   extractArgsAndReqsFromLambda(char *LambdaPtr, size_t KernelArgsNum,
[  540]                                const detail::kernel_param_desc_t *KernelArgs,
[  541]                                bool IsESIMD);
[  542] 
[  543]   /// Extracts and prepares kernel arguments set via set_arg(s).
[  544]   void extractArgsAndReqs();
[  545] 
[  546]   void processArg(void *Ptr, const detail::kernel_param_kind_t &Kind,
[  547]                   const int Size, const size_t Index, size_t &IndexShift,
[  548]                   bool IsKernelCreatedFromSource, bool IsESIMD);
[  549] 
[  550]   /// \return a string containing name of SYCL kernel.
[  551]   std::string getKernelName();
[  552] 
[  553]   template <typename LambdaNameT> bool lambdaAndKernelHaveEqualName() {
[  554]     // TODO It is unclear a kernel and a lambda/functor must to be equal or not
[  555]     // for parallel_for with sycl::kernel and lambda/functor together
[  556]     // Now if they are equal we extract argumets from lambda/functor for the
[  557]     // kernel. Else it is necessary use set_atg(s) for resolve the order and
[  558]     // values of arguments for the kernel.
[  559]     assert(MKernel && "MKernel is not initialized");
[  560]     const std::string LambdaName = detail::KernelInfo<LambdaNameT>::getName();
[  561]     const std::string KernelName = getKernelName();
[  562]     return LambdaName == KernelName;
[  563]   }
[  564] 
[  565]   /// Saves the location of user's code passed in \p CodeLoc for future usage in
[  566]   /// finalize() method.
[  567]   void saveCodeLoc(detail::code_location CodeLoc) { MCodeLoc = CodeLoc; }
[  568] 
[  569]   /// Constructs CG object of specific type, passes it to Scheduler and
[  570]   /// returns sycl::event object representing the command group.
[  571]   /// It's expected that the method is the latest method executed before
[  572]   /// object destruction.
[  573]   ///
[  574]   /// \return a SYCL event object representing the command group
[  575]   event finalize();
[  576] 
[  577]   /// Saves streams associated with this handler.
[  578]   ///
[  579]   /// Streams are then forwarded to command group and flushed in the scheduler.
[  580]   ///
[  581]   /// \param Stream is a pointer to SYCL stream.
[  582]   void addStream(const std::shared_ptr<detail::stream_impl> &Stream) {
[  583]     MStreamStorage.push_back(Stream);
[  584]   }
[  585] 
[  586]   /// Saves resources created by handling reduction feature in handler.
[  587]   /// They are then forwarded to command group and destroyed only after
[  588]   /// the command group finishes the work on device/host.
[  589]   ///
[  590]   /// @param ReduObj is a pointer to object that must be stored.
[  591]   void addReduction(const std::shared_ptr<const void> &ReduObj);
[  592] 
[  593]   /// Saves buffers created by handling reduction feature in handler and marks
[  594]   /// them as internal. They are then forwarded to command group and destroyed
[  595]   /// only after the command group finishes the work on device/host.
[  596]   ///
[  597]   /// @param ReduBuf is a pointer to buffer that must be stored.
[  598]   template <typename T, int Dimensions, typename AllocatorT, typename Enable>
[  599]   void
[  600]   addReduction(const std::shared_ptr<buffer<T, Dimensions, AllocatorT, Enable>>
[  601]                    &ReduBuf) {
[  602]     detail::markBufferAsInternal(getSyclObjImpl(*ReduBuf));
[  603]     addReduction(std::shared_ptr<const void>(ReduBuf));
[  604]   }
[  605] 
[  606]   ~handler() = default;
[  607] 
[  608]   // TODO: Private and unusued. Remove when ABI break is allowed.
[  609]   bool is_host() { return MIsHost; }
[  610] 
[  611] #ifdef __SYCL_DEVICE_ONLY__
[  612]   // In device compilation accessor isn't inherited from host base classes, so
[  613]   // can't detect by it. Since we don't expect it to be ever called in device
[  614]   // execution, just use blind void *.
[  615]   void associateWithHandler(void *AccBase, access::target AccTarget);
[  616]   void associateWithHandler(void *AccBase, image_target AccTarget);
[  617] #else
[  618]   void associateWithHandlerCommon(detail::AccessorImplPtr AccImpl,
[  619]                                   int AccTarget);
[  620]   void associateWithHandler(detail::AccessorBaseHost *AccBase,
[  621]                             access::target AccTarget);
[  622]   void associateWithHandler(detail::UnsampledImageAccessorBaseHost *AccBase,
[  623]                             image_target AccTarget);
[  624]   void associateWithHandler(detail::SampledImageAccessorBaseHost *AccBase,
[  625]                             image_target AccTarget);
[  626] #endif
[  627] 
[  628]   // Recursively calls itself until arguments pack is fully processed.
[  629]   // The version for regular(standard layout) argument.
[  630]   template <typename T, typename... Ts>
[  631]   void setArgsHelper(int ArgIndex, T &&Arg, Ts &&...Args) {
[  632]     set_arg(ArgIndex, std::move(Arg));
[  633]     setArgsHelper(++ArgIndex, std::move(Args)...);
[  634]   }
[  635] 
[  636]   void setArgsHelper(int) {}
[  637] 
[  638]   void setLocalAccessorArgHelper(int ArgIndex,
[  639]                                  detail::LocalAccessorBaseHost &LocalAccBase) {
[  640]     detail::LocalAccessorImplPtr LocalAccImpl =
[  641]         detail::getSyclObjImpl(LocalAccBase);
[  642]     detail::LocalAccessorImplHost *Req = LocalAccImpl.get();
[  643]     MLocalAccStorage.push_back(std::move(LocalAccImpl));
[  644]     MArgs.emplace_back(detail::kernel_param_kind_t::kind_accessor, Req,
[  645]                        static_cast<int>(access::target::local), ArgIndex);
[  646]   }
[  647] 
[  648]   // setArgHelper for local accessor argument (legacy accessor interface)
[  649]   template <typename DataT, int Dims, access::mode AccessMode,
[  650]             access::placeholder IsPlaceholder>
[  651]   void setArgHelper(int ArgIndex,
[  652]                     accessor<DataT, Dims, AccessMode, access::target::local,
[  653]                              IsPlaceholder> &&Arg) {
[  654]     (void)ArgIndex;
[  655]     (void)Arg;
[  656] #ifndef __SYCL_DEVICE_ONLY__
[  657]     setLocalAccessorArgHelper(ArgIndex, Arg);
[  658] #endif
[  659]   }
[  660] 
[  661]   // setArgHelper for local accessor argument (up to date accessor interface)
[  662]   template <typename DataT, int Dims>
[  663]   void setArgHelper(int ArgIndex, local_accessor<DataT, Dims> &&Arg) {
[  664]     (void)ArgIndex;
[  665]     (void)Arg;
[  666] #ifndef __SYCL_DEVICE_ONLY__
[  667]     setLocalAccessorArgHelper(ArgIndex, Arg);
[  668] #endif
[  669]   }
[  670] 
[  671]   // setArgHelper for non local accessor argument.
[  672]   template <typename DataT, int Dims, access::mode AccessMode,
[  673]             access::target AccessTarget, access::placeholder IsPlaceholder>
[  674]   typename std::enable_if_t<AccessTarget != access::target::local, void>
[  675]   setArgHelper(
[  676]       int ArgIndex,
[  677]       accessor<DataT, Dims, AccessMode, AccessTarget, IsPlaceholder> &&Arg) {
[  678]     detail::AccessorBaseHost *AccBase = (detail::AccessorBaseHost *)&Arg;
[  679]     detail::AccessorImplPtr AccImpl = detail::getSyclObjImpl(*AccBase);
[  680]     detail::AccessorImplHost *Req = AccImpl.get();
[  681]     // Add accessor to the list of requirements.
[  682]     CGData.MRequirements.push_back(Req);
[  683]     // Store copy of the accessor.
[  684]     CGData.MAccStorage.push_back(std::move(AccImpl));
[  685]     // Add accessor to the list of arguments.
[  686]     MArgs.emplace_back(detail::kernel_param_kind_t::kind_accessor, Req,
[  687]                        static_cast<int>(AccessTarget), ArgIndex);
[  688]   }
[  689] 
[  690]   template <typename T> void setArgHelper(int ArgIndex, T &&Arg) {
[  691]     auto StoredArg = static_cast<void *>(storePlainArg(Arg));
[  692] 
[  693]     if (!std::is_same<cl_mem, T>::value && std::is_pointer<T>::value) {
[  694]       MArgs.emplace_back(detail::kernel_param_kind_t::kind_pointer, StoredArg,
[  695]                          sizeof(T), ArgIndex);
[  696]     } else {
[  697]       MArgs.emplace_back(detail::kernel_param_kind_t::kind_std_layout,
[  698]                          StoredArg, sizeof(T), ArgIndex);
[  699]     }
[  700]   }
[  701] 
[  702]   void setArgHelper(int ArgIndex, sampler &&Arg) {
[  703]     auto StoredArg = static_cast<void *>(storePlainArg(Arg));
[  704]     MArgs.emplace_back(detail::kernel_param_kind_t::kind_sampler, StoredArg,
[  705]                        sizeof(sampler), ArgIndex);
[  706]   }
[  707] 
[  708]   // TODO: Unusued. Remove when ABI break is allowed.
[  709]   void verifyKernelInvoc(const kernel &Kernel) {
[  710]     std::ignore = Kernel;
[  711]     return;
[  712]   }
[  713] 
[  714]   /* The kernel passed to StoreLambda can take an id, an item or an nd_item as
[  715]    * its argument. Since esimd plugin directly invokes the kernel (doesn’t use
[  716]    * piKernelSetArg), the kernel argument type must be known to the plugin.
[  717]    * However, passing kernel argument type to the plugin requires changing ABI
[  718]    * in HostKernel class. To overcome this problem, helpers below wrap the
[  719]    * “original” kernel with a functor that always takes an nd_item as argument.
[  720]    * A functor is used instead of a lambda because extractArgsAndReqsFromLambda
[  721]    * needs access to the “original” kernel and keeps references to its internal
[  722]    * data, i.e. the kernel passed as argument cannot be local in scope. The
[  723]    * functor itself is again encapsulated in a std::function since functor’s
[  724]    * type is unknown to the plugin.
[  725]    */
[  726] 
[  727]   // For 'id, item w/wo offset, nd_item' kernel arguments
[  728]   template <class KernelType, class NormalizedKernelType, int Dims>
[  729]   KernelType *ResetHostKernelHelper(const KernelType &KernelFunc) {
[  730]     NormalizedKernelType NormalizedKernel(KernelFunc);
[  731]     auto NormalizedKernelFunc =
[  732]         std::function<void(const sycl::nd_item<Dims> &)>(NormalizedKernel);
[  733]     auto HostKernelPtr = new detail::HostKernel<decltype(NormalizedKernelFunc),
[  734]                                                 sycl::nd_item<Dims>, Dims>(
[  735]         std::move(NormalizedKernelFunc));
[  736]     MHostKernel.reset(HostKernelPtr);
[  737]     return &HostKernelPtr->MKernel.template target<NormalizedKernelType>()
[  738]                 ->MKernelFunc;
[  739]   }
[  740] 
[  741]   // For 'sycl::id<Dims>' kernel argument
[  742]   template <class KernelType, typename ArgT, int Dims>
[  743]   std::enable_if_t<std::is_same_v<ArgT, sycl::id<Dims>>, KernelType *>
[  744]   ResetHostKernel(const KernelType &KernelFunc) {
[  745]     struct NormalizedKernelType {
[  746]       KernelType MKernelFunc;
[  747]       NormalizedKernelType(const KernelType &KernelFunc)
[  748]           : MKernelFunc(KernelFunc) {}
[  749]       void operator()(const nd_item<Dims> &Arg) {
[  750]         detail::runKernelWithArg(MKernelFunc, Arg.get_global_id());
[  751]       }
[  752]     };
[  753]     return ResetHostKernelHelper<KernelType, struct NormalizedKernelType, Dims>(
[  754]         KernelFunc);
[  755]   }
[  756] 
[  757]   // For 'sycl::nd_item<Dims>' kernel argument
[  758]   template <class KernelType, typename ArgT, int Dims>
[  759]   std::enable_if_t<std::is_same_v<ArgT, sycl::nd_item<Dims>>, KernelType *>
[  760]   ResetHostKernel(const KernelType &KernelFunc) {
[  761]     struct NormalizedKernelType {
[  762]       KernelType MKernelFunc;
[  763]       NormalizedKernelType(const KernelType &KernelFunc)
[  764]           : MKernelFunc(KernelFunc) {}
[  765]       void operator()(const nd_item<Dims> &Arg) {
[  766]         detail::runKernelWithArg(MKernelFunc, Arg);
[  767]       }
[  768]     };
[  769]     return ResetHostKernelHelper<KernelType, struct NormalizedKernelType, Dims>(
[  770]         KernelFunc);
[  771]   }
[  772] 
[  773]   // For 'sycl::item<Dims, without_offset>' kernel argument
[  774]   template <class KernelType, typename ArgT, int Dims>
[  775]   std::enable_if_t<std::is_same_v<ArgT, sycl::item<Dims, false>>, KernelType *>
[  776]   ResetHostKernel(const KernelType &KernelFunc) {
[  777]     struct NormalizedKernelType {
[  778]       KernelType MKernelFunc;
[  779]       NormalizedKernelType(const KernelType &KernelFunc)
[  780]           : MKernelFunc(KernelFunc) {}
[  781]       void operator()(const nd_item<Dims> &Arg) {
[  782]         sycl::item<Dims, false> Item = detail::Builder::createItem<Dims, false>(
[  783]             Arg.get_global_range(), Arg.get_global_id());
[  784]         detail::runKernelWithArg(MKernelFunc, Item);
[  785]       }
[  786]     };
[  787]     return ResetHostKernelHelper<KernelType, struct NormalizedKernelType, Dims>(
[  788]         KernelFunc);
[  789]   }
[  790] 
[  791]   // For 'sycl::item<Dims, with_offset>' kernel argument
[  792]   template <class KernelType, typename ArgT, int Dims>
[  793]   std::enable_if_t<std::is_same_v<ArgT, sycl::item<Dims, true>>, KernelType *>
[  794]   ResetHostKernel(const KernelType &KernelFunc) {
[  795]     struct NormalizedKernelType {
[  796]       KernelType MKernelFunc;
[  797]       NormalizedKernelType(const KernelType &KernelFunc)
[  798]           : MKernelFunc(KernelFunc) {}
[  799]       void operator()(const nd_item<Dims> &Arg) {
[  800]         sycl::item<Dims, true> Item = detail::Builder::createItem<Dims, true>(
[  801]             Arg.get_global_range(), Arg.get_global_id(), Arg.get_offset());
[  802]         detail::runKernelWithArg(MKernelFunc, Item);
[  803]       }
[  804]     };
[  805]     return ResetHostKernelHelper<KernelType, struct NormalizedKernelType, Dims>(
[  806]         KernelFunc);
[  807]   }
[  808] 
[  809]   // For 'void' kernel argument (single_task)
[  810]   template <class KernelType, typename ArgT, int Dims>
[  811]   typename std::enable_if_t<std::is_same_v<ArgT, void>, KernelType *>
[  812]   ResetHostKernel(const KernelType &KernelFunc) {
[  813]     struct NormalizedKernelType {
[  814]       KernelType MKernelFunc;
[  815]       NormalizedKernelType(const KernelType &KernelFunc)
[  816]           : MKernelFunc(KernelFunc) {}
[  817]       void operator()(const nd_item<Dims> &Arg) {
[  818]         (void)Arg;
[  819]         detail::runKernelWithoutArg(MKernelFunc);
[  820]       }
[  821]     };
[  822]     return ResetHostKernelHelper<KernelType, struct NormalizedKernelType, Dims>(
[  823]         KernelFunc);
[  824]   }
[  825] 
[  826]   // For 'sycl::group<Dims>' kernel argument
[  827]   // 'wrapper'-based approach using 'NormalizedKernelType' struct is not used
[  828]   // for 'void(sycl::group<Dims>)' since 'void(sycl::group<Dims>)' is not
[  829]   // supported in ESIMD.
[  830]   template <class KernelType, typename ArgT, int Dims>
[  831]   std::enable_if_t<std::is_same_v<ArgT, sycl::group<Dims>>, KernelType *>
[  832]   ResetHostKernel(const KernelType &KernelFunc) {
[  833]     MHostKernel.reset(
[  834]         new detail::HostKernel<KernelType, ArgT, Dims>(KernelFunc));
[  835]     return (KernelType *)(MHostKernel->getPtr());
[  836]   }
[  837] 
[  838]   /// Verifies the kernel bundle to be used if any is set. This throws a
[  839]   /// sycl::exception with error code errc::kernel_not_supported if the used
[  840]   /// kernel bundle does not contain a suitable device image with the requested
[  841]   /// kernel.
[  842]   ///
[  843]   /// \param KernelName is the name of the SYCL kernel to check that the used
[  844]   ///                   kernel bundle contains.
[  845]   void verifyUsedKernelBundle(const std::string &KernelName);
[  846] 
[  847]   /// Stores lambda to the template-free object
[  848]   ///
[  849]   /// Also initializes kernel name, list of arguments and requirements using
[  850]   /// information from the integration header.
[  851]   ///
[  852]   /// \param KernelFunc is a SYCL kernel function.
[  853]   template <typename KernelName, typename KernelType, int Dims,
[  854]             typename LambdaArgType>
[  855]   void StoreLambda(KernelType KernelFunc) {
[  856]     using KI = detail::KernelInfo<KernelName>;
[  857]     constexpr bool IsCallableWithKernelHandler =
[  858]         detail::KernelLambdaHasKernelHandlerArgT<KernelType,
[  859]                                                  LambdaArgType>::value;
[  860] 
[  861]     if (IsCallableWithKernelHandler && MIsHost) {
[  862]       throw sycl::feature_not_supported(
[  863]           "kernel_handler is not yet supported by host device.",
[  864]           PI_ERROR_INVALID_OPERATION);
[  865]     }
[  866] 
[  867]     KernelType *KernelPtr =
[  868]         ResetHostKernel<KernelType, LambdaArgType, Dims>(KernelFunc);
[  869] 
[  870]     constexpr bool KernelHasName =
[  871]         KI::getName() != nullptr && KI::getName()[0] != '\0';
[  872] 
[  873]     // Some host compilers may have different captures from Clang. Currently
[  874]     // there is no stable way of handling this when extracting the captures, so
[  875]     // a static assert is made to fail for incompatible kernel lambdas.
[  876]     static_assert(
[  877]         !KernelHasName || sizeof(KernelFunc) == KI::getKernelSize(),
[  878]         "Unexpected kernel lambda size. This can be caused by an "
[  879]         "external host compiler producing a lambda with an "
[  880]         "unexpected layout. This is a limitation of the compiler."
[  881]         "In many cases the difference is related to capturing constexpr "
[  882]         "variables. In such cases removing constexpr specifier aligns the "
[  883]         "captures between the host compiler and the device compiler."
[  884]         "\n"
[  885]         "In case of MSVC, passing "
[  886]         "-fsycl-host-compiler-options='/std:c++latest' "
[  887]         "might also help.");
[  888] 
[  889]     // Empty name indicates that the compilation happens without integration
[  890]     // header, so don't perform things that require it.
[  891]     if (KernelHasName) {
[  892]       // TODO support ESIMD in no-integration-header case too.
[  893]       MArgs.clear();
[  894]       extractArgsAndReqsFromLambda(reinterpret_cast<char *>(KernelPtr),
[  895]                                    KI::getNumParams(), &KI::getParamDesc(0),
[  896]                                    KI::isESIMD());
[  897]       MKernelName = KI::getName();
[  898]     } else {
[  899]       // In case w/o the integration header it is necessary to process
[  900]       // accessors from the list(which are associated with this handler) as
[  901]       // arguments.
[  902]       MArgs = std::move(MAssociatedAccesors);
[  903]     }
[  904] 
[  905]     // If the kernel lambda is callable with a kernel_handler argument, manifest
[  906]     // the associated kernel handler.
[  907]     if (IsCallableWithKernelHandler) {
[  908]       getOrInsertHandlerKernelBundle(/*Insert=*/true);
[  909]     }
[  910]   }
[  911] 
[  912]   /// Process kernel properties.
[  913]   ///
[  914]   /// Stores information about kernel properties into the handler.
[  915]   template <
[  916]       typename KernelName,
[  917]       typename PropertiesT = ext::oneapi::experimental::empty_properties_t>
[  918]   void processProperties(PropertiesT Props) {
[  919]     using KI = detail::KernelInfo<KernelName>;
[  920]     static_assert(
[  921]         ext::oneapi::experimental::is_property_list<PropertiesT>::value,
[  922]         "Template type is not a property list.");
[  923]     static_assert(
[  924]         !PropertiesT::template has_property<
[  925]             sycl::ext::intel::experimental::fp_control_key>() ||
[  926]             (PropertiesT::template has_property<
[  927]                  sycl::ext::intel::experimental::fp_control_key>() &&
[  928]              KI::isESIMD()),
[  929]         "Floating point control property is supported for ESIMD kernels only.");
[  930]     if constexpr (PropertiesT::template has_property<
[  931]                       sycl::ext::intel::experimental::cache_config_key>()) {
[  932]       auto Config = Props.template get_property<
[  933]           sycl::ext::intel::experimental::cache_config_key>();
[  934]       if (Config == sycl::ext::intel::experimental::large_slm) {
[  935]         setKernelCacheConfig(PI_EXT_KERNEL_EXEC_INFO_CACHE_LARGE_SLM);
[  936]       } else if (Config == sycl::ext::intel::experimental::large_data) {
[  937]         setKernelCacheConfig(PI_EXT_KERNEL_EXEC_INFO_CACHE_LARGE_DATA);
[  938]       }
[  939]     } else {
[  940]       std::ignore = Props;
[  941]     }
[  942]   }
[  943] 
[  944]   /// Checks whether it is possible to copy the source shape to the destination
[  945]   /// shape(the shapes are described by the accessor ranges) by using
[  946]   /// copying by regions of memory and not copying element by element
[  947]   /// Shapes can be 1, 2 or 3 dimensional rectangles.
[  948]   template <int Dims_Src, int Dims_Dst>
[  949]   static bool IsCopyingRectRegionAvailable(const range<Dims_Src> Src,
[  950]                                            const range<Dims_Dst> Dst) {
[  951]     if (Dims_Src > Dims_Dst)
[  952]       return false;
[  953]     for (size_t I = 0; I < Dims_Src; ++I)
[  954]       if (Src[I] > Dst[I])
[  955]         return false;
[  956]     return true;
[  957]   }
[  958] 
[  959]   /// Handles some special cases of the copy operation from one accessor
[  960]   /// to another accessor. Returns true if the copy is handled here.
[  961]   ///
[  962]   /// \param Src is a source SYCL accessor.
[  963]   /// \param Dst is a destination SYCL accessor.
[  964]   template <typename TSrc, int DimSrc, access::mode ModeSrc,
[  965]             access::target TargetSrc, typename TDst, int DimDst,
[  966]             access::mode ModeDst, access::target TargetDst,
[  967]             access::placeholder IsPHSrc, access::placeholder IsPHDst>
[  968]   std::enable_if_t<(DimSrc > 0) && (DimDst > 0), bool>
[  969]   copyAccToAccHelper(accessor<TSrc, DimSrc, ModeSrc, TargetSrc, IsPHSrc> Src,
[  970]                      accessor<TDst, DimDst, ModeDst, TargetDst, IsPHDst> Dst) {
[  971]     if (!MIsHost &&
[  972]         IsCopyingRectRegionAvailable(Src.get_range(), Dst.get_range()))
[  973]       return false;
[  974] 
[  975]     range<1> LinearizedRange(Src.size());
[  976]     parallel_for<__copyAcc2Acc<TSrc, DimSrc, ModeSrc, TargetSrc, TDst, DimDst,
[  977]                                ModeDst, TargetDst, IsPHSrc, IsPHDst>>(
[  978]         LinearizedRange, [=](id<1> Id) {
[  979]           size_t Index = Id[0];
[  980]           id<DimSrc> SrcId = detail::getDelinearizedId(Src.get_range(), Index);
[  981]           id<DimDst> DstId = detail::getDelinearizedId(Dst.get_range(), Index);
[  982]           Dst[DstId] = Src[SrcId];
[  983]         });
[  984]     return true;
[  985]   }
[  986] 
[  987]   /// Handles some special cases of the copy operation from one accessor
[  988]   /// to another accessor. Returns true if the copy is handled here.
[  989]   ///
[  990]   /// Source must have at least as many bytes as the range accessed by Dst.
[  991]   ///
[  992]   /// \param Src is a source SYCL accessor.
[  993]   /// \param Dst is a destination SYCL accessor.
[  994]   template <typename TSrc, int DimSrc, access::mode ModeSrc,
[  995]             access::target TargetSrc, typename TDst, int DimDst,
[  996]             access::mode ModeDst, access::target TargetDst,
[  997]             access::placeholder IsPHSrc, access::placeholder IsPHDst>
[  998]   std::enable_if_t<DimSrc == 0 || DimDst == 0, bool>
[  999]   copyAccToAccHelper(accessor<TSrc, DimSrc, ModeSrc, TargetSrc, IsPHSrc> Src,
[ 1000]                      accessor<TDst, DimDst, ModeDst, TargetDst, IsPHDst> Dst) {
[ 1001]     if (!MIsHost)
[ 1002]       return false;
[ 1003] 
[ 1004]     single_task<__copyAcc2Acc<TSrc, DimSrc, ModeSrc, TargetSrc, TDst, DimDst,
[ 1005]                               ModeDst, TargetDst, IsPHSrc, IsPHDst>>(
[ 1006]         [=]() { *(Dst.get_pointer()) = *(Src.get_pointer()); });
[ 1007]     return true;
[ 1008]   }
[ 1009] 
[ 1010] #ifndef __SYCL_DEVICE_ONLY__
[ 1011]   /// Copies the content of memory object accessed by Src into the memory
[ 1012]   /// pointed by Dst.
[ 1013]   ///
[ 1014]   /// \param Src is a source SYCL accessor.
[ 1015]   /// \param Dst is a pointer to destination memory.
[ 1016]   template <typename TSrc, typename TDst, int Dim, access::mode AccMode,
[ 1017]             access::target AccTarget, access::placeholder IsPH>
[ 1018]   std::enable_if_t<(Dim > 0)>
[ 1019]   copyAccToPtrHost(accessor<TSrc, Dim, AccMode, AccTarget, IsPH> Src,
[ 1020]                    TDst *Dst) {
[ 1021]     range<Dim> Range = Src.get_range();
[ 1022]     parallel_for<__copyAcc2Ptr<TSrc, TDst, Dim, AccMode, AccTarget, IsPH>>(
[ 1023]         Range, [=](id<Dim> Index) {
[ 1024]           const size_t LinearIndex = detail::getLinearIndex(Index, Range);
[ 1025]           using TSrcNonConst = typename std::remove_const_t<TSrc>;
[ 1026]           (reinterpret_cast<TSrcNonConst *>(Dst))[LinearIndex] = Src[Index];
[ 1027]         });
[ 1028]   }
[ 1029] 
[ 1030]   /// Copies 1 element accessed by 0-dimensional accessor Src into the memory
[ 1031]   /// pointed by Dst.
[ 1032]   ///
[ 1033]   /// \param Src is a source SYCL accessor.
[ 1034]   /// \param Dst is a pointer to destination memory.
[ 1035]   template <typename TSrc, typename TDst, int Dim, access::mode AccMode,
[ 1036]             access::target AccTarget, access::placeholder IsPH>
[ 1037]   std::enable_if_t<Dim == 0>
[ 1038]   copyAccToPtrHost(accessor<TSrc, Dim, AccMode, AccTarget, IsPH> Src,
[ 1039]                    TDst *Dst) {
[ 1040]     single_task<__copyAcc2Ptr<TSrc, TDst, Dim, AccMode, AccTarget, IsPH>>(
[ 1041]         [=]() {
[ 1042]           using TSrcNonConst = typename std::remove_const_t<TSrc>;
[ 1043]           *(reinterpret_cast<TSrcNonConst *>(Dst)) = *(Src.get_pointer());
[ 1044]         });
[ 1045]   }
[ 1046] 
[ 1047]   /// Copies the memory pointed by Src into the memory accessed by Dst.
[ 1048]   ///
[ 1049]   /// \param Src is a pointer to source memory.
[ 1050]   /// \param Dst is a destination SYCL accessor.
[ 1051]   template <typename TSrc, typename TDst, int Dim, access::mode AccMode,
[ 1052]             access::target AccTarget, access::placeholder IsPH>
[ 1053]   std::enable_if_t<(Dim > 0)>
[ 1054]   copyPtrToAccHost(TSrc *Src,
[ 1055]                    accessor<TDst, Dim, AccMode, AccTarget, IsPH> Dst) {
[ 1056]     range<Dim> Range = Dst.get_range();
[ 1057]     parallel_for<__copyPtr2Acc<TSrc, TDst, Dim, AccMode, AccTarget, IsPH>>(
[ 1058]         Range, [=](id<Dim> Index) {
[ 1059]           const size_t LinearIndex = detail::getLinearIndex(Index, Range);
[ 1060]           Dst[Index] = (reinterpret_cast<const TDst *>(Src))[LinearIndex];
[ 1061]         });
[ 1062]   }
[ 1063] 
[ 1064]   /// Copies 1 element pointed by Src to memory accessed by 0-dimensional
[ 1065]   /// accessor Dst.
[ 1066]   ///
[ 1067]   /// \param Src is a pointer to source memory.
[ 1068]   /// \param Dst is a destination SYCL accessor.
[ 1069]   template <typename TSrc, typename TDst, int Dim, access::mode AccMode,
[ 1070]             access::target AccTarget, access::placeholder IsPH>
[ 1071]   std::enable_if_t<Dim == 0>
[ 1072]   copyPtrToAccHost(TSrc *Src,
[ 1073]                    accessor<TDst, Dim, AccMode, AccTarget, IsPH> Dst) {
[ 1074]     single_task<__copyPtr2Acc<TSrc, TDst, Dim, AccMode, AccTarget, IsPH>>(
[ 1075]         [=]() {
[ 1076]           *(Dst.get_pointer()) = *(reinterpret_cast<const TDst *>(Src));
[ 1077]         });
[ 1078]   }
[ 1079] #endif // __SYCL_DEVICE_ONLY__
[ 1080] 
[ 1081]   constexpr static bool isConstOrGlobal(access::target AccessTarget) {
[ 1082]     return AccessTarget == access::target::device ||
[ 1083]            AccessTarget == access::target::constant_buffer;
[ 1084]   }
[ 1085] 
[ 1086]   constexpr static bool isImageOrImageArray(access::target AccessTarget) {
[ 1087]     return AccessTarget == access::target::image ||
[ 1088]            AccessTarget == access::target::image_array;
[ 1089]   }
[ 1090] 
[ 1091]   constexpr static bool
[ 1092]   isValidTargetForExplicitOp(access::target AccessTarget) {
[ 1093]     return isConstOrGlobal(AccessTarget) || isImageOrImageArray(AccessTarget);
[ 1094]   }
[ 1095] 
[ 1096]   constexpr static bool isValidModeForSourceAccessor(access::mode AccessMode) {
[ 1097]     return AccessMode == access::mode::read ||
[ 1098]            AccessMode == access::mode::read_write;
[ 1099]   }
[ 1100] 
[ 1101]   constexpr static bool
[ 1102]   isValidModeForDestinationAccessor(access::mode AccessMode) {
[ 1103]     return AccessMode == access::mode::write ||
[ 1104]            AccessMode == access::mode::read_write ||
[ 1105]            AccessMode == access::mode::discard_write ||
[ 1106]            AccessMode == access::mode::discard_read_write;
[ 1107]   }
[ 1108] 
[ 1109]   // PI APIs only support select fill sizes: 1, 2, 4, 8, 16, 32, 64, 128
[ 1110]   constexpr static bool isBackendSupportedFillSize(size_t Size) {
[ 1111]     return Size == 1 || Size == 2 || Size == 4 || Size == 8 || Size == 16 ||
[ 1112]            Size == 32 || Size == 64 || Size == 128;
[ 1113]   }
[ 1114] 
[ 1115]   template <int Dims, typename LambdaArgType> struct TransformUserItemType {
[ 1116]     using type = std::conditional_t<
[ 1117]         std::is_convertible_v<nd_item<Dims>, LambdaArgType>, nd_item<Dims>,
[ 1118]         std::conditional_t<std::is_convertible_v<item<Dims>, LambdaArgType>,
[ 1119]                            item<Dims>, LambdaArgType>>;
[ 1120]   };
[ 1121] 
[ 1122]   std::optional<std::array<size_t, 3>> getMaxWorkGroups();
[ 1123]   // We need to use this version to support gcc 7.5.0. Remove when minimal
[ 1124]   // supported gcc version is bumped.
[ 1125]   std::tuple<std::array<size_t, 3>, bool> getMaxWorkGroups_v2();
[ 1126] 
[ 1127]   template <int Dims>
[ 1128]   std::tuple<range<Dims>, bool> getRoundedRange(range<Dims> UserRange) {
[ 1129]     range<Dims> RoundedRange = UserRange;
[ 1130]     // Disable the rounding-up optimizations under these conditions:
[ 1131]     // 1. The env var SYCL_DISABLE_PARALLEL_FOR_RANGE_ROUNDING is set.
[ 1132]     // 2. The kernel is provided via an interoperability method (this uses a
[ 1133]     // different code path).
[ 1134]     // 3. The range is already a multiple of the rounding factor.
[ 1135]     //
[ 1136]     // Cases 2 and 3 could be supported with extra effort.
[ 1137]     // As an optimization for the common case it is an
[ 1138]     // implementation choice to not support those scenarios.
[ 1139]     // Note that "this_item" is a free function, i.e. not tied to any
[ 1140]     // specific id or item. When concurrent parallel_fors are executing
[ 1141]     // on a device it is difficult to tell which parallel_for the call is
[ 1142]     // being made from. One could replicate portions of the
[ 1143]     // call-graph to make this_item calls kernel-specific but this is
[ 1144]     // not considered worthwhile.
[ 1145] 
[ 1146]     // Perform range rounding if rounding-up is enabled.
[ 1147]     if (this->DisableRangeRounding())
[ 1148]       return {range<Dims>{}, false};
[ 1149] 
[ 1150]     // Range should be a multiple of this for reasonable performance.
[ 1151]     size_t MinFactorX = 16;
[ 1152]     // Range should be a multiple of this for improved performance.
[ 1153]     size_t GoodFactor = 32;
[ 1154]     // Range should be at least this to make rounding worthwhile.
[ 1155]     size_t MinRangeX = 1024;
[ 1156] 
[ 1157]     // Check if rounding parameters have been set through environment:
[ 1158]     // SYCL_PARALLEL_FOR_RANGE_ROUNDING_PARAMS=MinRound:PreferredRound:MinRange
[ 1159]     this->GetRangeRoundingSettings(MinFactorX, GoodFactor, MinRangeX);
[ 1160] 
[ 1161]     // In SYCL, each dimension of a global range size is specified by
[ 1162]     // a size_t, which can be up to 64 bits.  All backends should be
[ 1163]     // able to accept a kernel launch with a 32-bit global range size
[ 1164]     // (i.e. do not throw an error).  The OpenCL CPU backend will
[ 1165]     // accept every 64-bit global range, but the GPU backends will not
[ 1166]     // generally accept every 64-bit global range.  So, when we get a
[ 1167]     // non-32-bit global range, we wrap the old kernel in a new kernel
[ 1168]     // that has each work item peform multiple invocations the old
[ 1169]     // kernel in a 32-bit global range.
[ 1170]     auto Dev = detail::getSyclObjImpl(detail::getDeviceFromHandler(*this));
[ 1171]     id<Dims> MaxNWGs = [&] {
[ 1172]       auto [MaxWGs, HasMaxWGs] = getMaxWorkGroups_v2();
[ 1173]       if (!HasMaxWGs) {
[ 1174]         id<Dims> Default;
[ 1175]         for (int i = 0; i < Dims; ++i)
[ 1176]           Default[i] = (std::numeric_limits<int32_t>::max)();
[ 1177]         return Default;
[ 1178]       }
[ 1179] 
[ 1180]       id<Dims> IdResult;
[ 1181]       size_t Limit = (std::numeric_limits<int>::max)();
[ 1182]       for (int i = 0; i < Dims; ++i)
[ 1183]         IdResult[i] = (std::min)(Limit, MaxWGs[Dims - i - 1]);
[ 1184]       return IdResult;
[ 1185]     }();
[ 1186]     auto M = (std::numeric_limits<uint32_t>::max)();
[ 1187]     range<Dims> MaxRange;
[ 1188]     for (int i = 0; i < Dims; ++i) {
[ 1189]       auto DesiredSize = MaxNWGs[i] * GoodFactor;
[ 1190]       MaxRange[i] =
[ 1191]           DesiredSize <= M ? DesiredSize : (M / GoodFactor) * GoodFactor;
[ 1192]     }
[ 1193] 
[ 1194]     bool DidAdjust = false;
[ 1195]     auto Adjust = [&](int Dim, size_t Value) {
[ 1196]       if (this->RangeRoundingTrace())
[ 1197]         std::cout << "parallel_for range adjusted at dim " << Dim << " from "
[ 1198]                   << RoundedRange[Dim] << " to " << Value << std::endl;
[ 1199]       RoundedRange[Dim] = Value;
[ 1200]       DidAdjust = true;
[ 1201]     };
[ 1202] 
[ 1203]     // Perform range rounding if there are sufficient work-items to
[ 1204]     // need rounding and the user-specified range is not a multiple of
[ 1205]     // a "good" value.
[ 1206]     if (RoundedRange[0] % MinFactorX != 0 && RoundedRange[0] >= MinRangeX) {
[ 1207]       // It is sufficient to round up just the first dimension.
[ 1208]       // Multiplying the rounded-up value of the first dimension
[ 1209]       // by the values of the remaining dimensions (if any)
[ 1210]       // will yield a rounded-up value for the total range.
[ 1211]       Adjust(0, ((RoundedRange[0] + GoodFactor - 1) / GoodFactor) * GoodFactor);
[ 1212]     }
[ 1213] 
[ 1214]     for (int i = 0; i < Dims; ++i)
[ 1215]       if (RoundedRange[i] > MaxRange[i])
[ 1216]         Adjust(i, MaxRange[i]);
[ 1217] 
[ 1218]     if (!DidAdjust)
[ 1219]       return {range<Dims>{}, false};
[ 1220]     return {RoundedRange, true};
[ 1221]   }
[ 1222] 
[ 1223]   /// Defines and invokes a SYCL kernel function for the specified range.
[ 1224]   ///
[ 1225]   /// The SYCL kernel function is defined as a lambda function or a named
[ 1226]   /// function object type and given an id or item for indexing in the indexing
[ 1227]   /// space defined by range.
[ 1228]   /// If it is a named function object and the function object type is
[ 1229]   /// globally visible, there is no need for the developer to provide
[ 1230]   /// a kernel name for it.
[ 1231]   ///
[ 1232]   /// \param NumWorkItems is a range defining indexing space.
[ 1233]   /// \param KernelFunc is a SYCL kernel function.
[ 1234]   template <
[ 1235]       typename KernelName, typename KernelType, int Dims,
[ 1236]       typename PropertiesT = ext::oneapi::experimental::empty_properties_t>
[ 1237]   void parallel_for_lambda_impl(range<Dims> UserRange, PropertiesT Props,
[ 1238]                                 KernelType KernelFunc) {
[ 1239]     throwIfActionIsCreated();
[ 1240]     throwOnLocalAccessorMisuse<KernelName, KernelType>();
[ 1241]     if (!range_size_fits_in_size_t(UserRange))
[ 1242]       throw sycl::exception(make_error_code(errc::runtime),
[ 1243]                             "The total number of work-items in "
[ 1244]                             "a range must fit within size_t");
[ 1245] 
[ 1246]     using LambdaArgType = sycl::detail::lambda_arg_type<KernelType, item<Dims>>;
[ 1247] 
[ 1248]     // If 1D kernel argument is an integral type, convert it to sycl::item<1>
[ 1249]     // If user type is convertible from sycl::item/sycl::nd_item, use
[ 1250]     // sycl::item/sycl::nd_item to transport item information
[ 1251]     using TransformedArgType = std::conditional_t<
[ 1252]         std::is_integral<LambdaArgType>::value && Dims == 1, item<Dims>,
[ 1253]         typename TransformUserItemType<Dims, LambdaArgType>::type>;
[ 1254] 
[ 1255]     static_assert(!std::is_same_v<TransformedArgType, sycl::nd_item<Dims>>,
[ 1256]                   "Kernel argument cannot have a sycl::nd_item type in "
[ 1257]                   "sycl::parallel_for with sycl::range");
[ 1258] 
[ 1259] #if defined(SYCL2020_CONFORMANT_APIS) ||                                       \
[ 1260]     defined(__INTEL_PREVIEW_BREAKING_CHANGES)
[ 1261]     static_assert(std::is_convertible_v<item<Dims>, LambdaArgType> ||
[ 1262]                       std::is_convertible_v<item<Dims, false>, LambdaArgType>,
[ 1263]                   "sycl::parallel_for(sycl::range) kernel must have the "
[ 1264]                   "first argument of sycl::item type, or of a type which is "
[ 1265]                   "implicitly convertible from sycl::item");
[ 1266] 
[ 1267]     using RefLambdaArgType = std::add_lvalue_reference_t<LambdaArgType>;
[ 1268]     static_assert(
[ 1269]         (std::is_invocable_v<KernelType, RefLambdaArgType> ||
[ 1270]          std::is_invocable_v<KernelType, RefLambdaArgType, kernel_handler>),
[ 1271]         "SYCL kernel lambda/functor has an unexpected signature, it should be "
[ 1272]         "invocable with sycl::item and optionally sycl::kernel_handler");
[ 1273] #endif
[ 1274] 
[ 1275]     // TODO: Properties may change the kernel function, so in order to avoid
[ 1276]     //       conflicts they should be included in the name.
[ 1277]     using NameT =
[ 1278]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 1279] 
[ 1280]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 1281] 
[ 1282]     // Range rounding can be disabled by the user.
[ 1283]     // Range rounding is not done on the host device.
[ 1284]     // Range rounding is supported only for newer SYCL standards.
[ 1285] #if !defined(__SYCL_DISABLE_PARALLEL_FOR_RANGE_ROUNDING__) &&                  \
[ 1286]     !defined(DPCPP_HOST_DEVICE_OPENMP) &&                                      \
[ 1287]     !defined(DPCPP_HOST_DEVICE_PERF_NATIVE) && SYCL_LANGUAGE_VERSION >= 202001
[ 1288]     auto [RoundedRange, HasRoundedRange] = getRoundedRange(UserRange);
[ 1289]     if (HasRoundedRange) {
[ 1290]       using NameWT = typename detail::get_kernel_wrapper_name_t<NameT>::name;
[ 1291]       auto Wrapper =
[ 1292]           getRangeRoundedKernelLambda<NameWT, TransformedArgType, Dims>(
[ 1293]               KernelFunc, UserRange);
[ 1294] 
[ 1295]       using KName = std::conditional_t<std::is_same<KernelType, NameT>::value,
[ 1296]                                        decltype(Wrapper), NameWT>;
[ 1297] 
[ 1298]       kernel_parallel_for_wrapper<KName, TransformedArgType, decltype(Wrapper),
[ 1299]                                   PropertiesT>(Wrapper);
[ 1300] #ifndef __SYCL_DEVICE_ONLY__
[ 1301]       // We are executing over the rounded range, but there are still
[ 1302]       // items/ids that are are constructed in ther range rounded
[ 1303]       // kernel use items/ids in the user range, which means that
[ 1304]       // __SYCL_ASSUME_INT can still be violated. So check the bounds
[ 1305]       // of the user range, instead of the rounded range.
[ 1306]       detail::checkValueRange<Dims>(UserRange);
[ 1307]       MNDRDesc.set(RoundedRange);
[ 1308]       StoreLambda<KName, decltype(Wrapper), Dims, TransformedArgType>(
[ 1309]           std::move(Wrapper));
[ 1310]       setType(detail::CG::Kernel);
[ 1311] #endif
[ 1312]     } else
[ 1313] #endif // !__SYCL_DISABLE_PARALLEL_FOR_RANGE_ROUNDING__ &&
[ 1314]        // !DPCPP_HOST_DEVICE_OPENMP && !DPCPP_HOST_DEVICE_PERF_NATIVE &&
[ 1315]        // SYCL_LANGUAGE_VERSION >= 202001
[ 1316]     {
[ 1317]       (void)UserRange;
[ 1318]       (void)Props;
[ 1319]       kernel_parallel_for_wrapper<NameT, TransformedArgType, KernelType,
[ 1320]                                   PropertiesT>(KernelFunc);
[ 1321] #ifndef __SYCL_DEVICE_ONLY__
[ 1322]       processProperties<NameT, PropertiesT>(Props);
[ 1323]       detail::checkValueRange<Dims>(UserRange);
[ 1324]       MNDRDesc.set(std::move(UserRange));
[ 1325]       StoreLambda<NameT, KernelType, Dims, TransformedArgType>(
[ 1326]           std::move(KernelFunc));
[ 1327]       setType(detail::CG::Kernel);
[ 1328] #endif
[ 1329]     }
[ 1330]   }
[ 1331] 
[ 1332]   /// Defines and invokes a SYCL kernel function for the specified nd_range.
[ 1333]   ///
[ 1334]   /// The SYCL kernel function is defined as a lambda function or a named
[ 1335]   /// function object type and given an id or item for indexing in the indexing
[ 1336]   /// space defined by range.
[ 1337]   /// If it is a named function object and the function object type is
[ 1338]   /// globally visible, there is no need for the developer to provide
[ 1339]   /// a kernel name for it.
[ 1340]   ///
[ 1341]   /// \param ExecutionRange is a ND-range defining global and local sizes as
[ 1342]   /// well as offset.
[ 1343]   /// \param Properties is the properties.
[ 1344]   /// \param KernelFunc is a SYCL kernel function.
[ 1345]   template <typename KernelName, typename KernelType, int Dims,
[ 1346]             typename PropertiesT>
[ 1347]   void parallel_for_impl(nd_range<Dims> ExecutionRange, PropertiesT Props,
[ 1348]                          _KERNELFUNCPARAM(KernelFunc)) {
[ 1349]     throwIfActionIsCreated();
[ 1350]     // TODO: Properties may change the kernel function, so in order to avoid
[ 1351]     //       conflicts they should be included in the name.
[ 1352]     using NameT =
[ 1353]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 1354]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 1355]     using LambdaArgType =
[ 1356]         sycl::detail::lambda_arg_type<KernelType, nd_item<Dims>>;
[ 1357] #if defined(SYCL2020_CONFORMANT_APIS) ||                                       \
[ 1358]     defined(__INTEL_PREVIEW_BREAKING_CHANGES)
[ 1359]     static_assert(
[ 1360]         std::is_convertible_v<sycl::nd_item<Dims>, LambdaArgType>,
[ 1361]         "Kernel argument of a sycl::parallel_for with sycl::nd_range "
[ 1362]         "must be either sycl::nd_item or be convertible from sycl::nd_item");
[ 1363]     using TransformedArgType = sycl::nd_item<Dims>;
[ 1364] #else
[ 1365]     // If user type is convertible from sycl::item/sycl::nd_item, use
[ 1366]     // sycl::item/sycl::nd_item to transport item information
[ 1367]     using TransformedArgType =
[ 1368]         typename TransformUserItemType<Dims, LambdaArgType>::type;
[ 1369] #endif
[ 1370] 
[ 1371]     (void)ExecutionRange;
[ 1372]     (void)Props;
[ 1373]     kernel_parallel_for_wrapper<NameT, TransformedArgType, KernelType,
[ 1374]                                 PropertiesT>(KernelFunc);
[ 1375] #ifndef __SYCL_DEVICE_ONLY__
[ 1376]     processProperties<NameT, PropertiesT>(Props);
[ 1377]     detail::checkValueRange<Dims>(ExecutionRange);
[ 1378]     MNDRDesc.set(std::move(ExecutionRange));
[ 1379]     StoreLambda<NameT, KernelType, Dims, TransformedArgType>(
[ 1380]         std::move(KernelFunc));
[ 1381]     setType(detail::CG::Kernel);
[ 1382] #endif
[ 1383]   }
[ 1384] 
[ 1385]   /// Defines and invokes a SYCL kernel function for the specified range.
[ 1386]   ///
[ 1387]   /// The SYCL kernel function is defined as SYCL kernel object. The kernel
[ 1388]   /// invocation method has no functors and cannot be called on host.
[ 1389]   ///
[ 1390]   /// \param NumWorkItems is a range defining indexing space.
[ 1391]   /// \param Kernel is a SYCL kernel function.
[ 1392]   template <int Dims>
[ 1393]   void parallel_for_impl(range<Dims> NumWorkItems, kernel Kernel) {
[ 1394]     throwIfActionIsCreated();
[ 1395]     MKernel = detail::getSyclObjImpl(std::move(Kernel));
[ 1396]     detail::checkValueRange<Dims>(NumWorkItems);
[ 1397]     MNDRDesc.set(std::move(NumWorkItems));
[ 1398]     setType(detail::CG::Kernel);
[ 1399]     extractArgsAndReqs();
[ 1400]     MKernelName = getKernelName();
[ 1401]   }
[ 1402] 
[ 1403]   /// Hierarchical kernel invocation method of a kernel defined as a lambda
[ 1404]   /// encoding the body of each work-group to launch.
[ 1405]   ///
[ 1406]   /// Lambda may contain multiple calls to parallel_for_work_item(...) methods
[ 1407]   /// representing the execution on each work-item. Launches NumWorkGroups
[ 1408]   /// work-groups of runtime-defined size.
[ 1409]   ///
[ 1410]   /// \param NumWorkGroups is a range describing the number of work-groups in
[ 1411]   /// each dimension.
[ 1412]   /// \param KernelFunc is a lambda representing kernel.
[ 1413]   template <
[ 1414]       typename KernelName, typename KernelType, int Dims,
[ 1415]       typename PropertiesT = ext::oneapi::experimental::empty_properties_t>
[ 1416]   void parallel_for_work_group_lambda_impl(range<Dims> NumWorkGroups,
[ 1417]                                            PropertiesT Props,
[ 1418]                                            _KERNELFUNCPARAM(KernelFunc)) {
[ 1419]     throwIfActionIsCreated();
[ 1420]     // TODO: Properties may change the kernel function, so in order to avoid
[ 1421]     //       conflicts they should be included in the name.
[ 1422]     using NameT =
[ 1423]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 1424]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 1425]     using LambdaArgType =
[ 1426]         sycl::detail::lambda_arg_type<KernelType, group<Dims>>;
[ 1427]     (void)NumWorkGroups;
[ 1428]     (void)Props;
[ 1429]     kernel_parallel_for_work_group_wrapper<NameT, LambdaArgType, KernelType,
[ 1430]                                            PropertiesT>(KernelFunc);
[ 1431] #ifndef __SYCL_DEVICE_ONLY__
[ 1432]     processProperties<NameT, PropertiesT>(Props);
[ 1433]     detail::checkValueRange<Dims>(NumWorkGroups);
[ 1434]     MNDRDesc.setNumWorkGroups(NumWorkGroups);
[ 1435]     StoreLambda<NameT, KernelType, Dims, LambdaArgType>(std::move(KernelFunc));
[ 1436]     setType(detail::CG::Kernel);
[ 1437] #endif // __SYCL_DEVICE_ONLY__
[ 1438]   }
[ 1439] 
[ 1440]   /// Hierarchical kernel invocation method of a kernel defined as a lambda
[ 1441]   /// encoding the body of each work-group to launch.
[ 1442]   ///
[ 1443]   /// Lambda may contain multiple calls to parallel_for_work_item(...) methods
[ 1444]   /// representing the execution on each work-item. Launches NumWorkGroups
[ 1445]   /// work-groups of WorkGroupSize size.
[ 1446]   ///
[ 1447]   /// \param NumWorkGroups is a range describing the number of work-groups in
[ 1448]   /// each dimension.
[ 1449]   /// \param WorkGroupSize is a range describing the size of work-groups in
[ 1450]   /// each dimension.
[ 1451]   /// \param KernelFunc is a lambda representing kernel.
[ 1452]   template <
[ 1453]       typename KernelName, typename KernelType, int Dims,
[ 1454]       typename PropertiesT = ext::oneapi::experimental::empty_properties_t>
[ 1455]   void parallel_for_work_group_lambda_impl(range<Dims> NumWorkGroups,
[ 1456]                                            range<Dims> WorkGroupSize,
[ 1457]                                            PropertiesT Props,
[ 1458]                                            _KERNELFUNCPARAM(KernelFunc)) {
[ 1459]     throwIfActionIsCreated();
[ 1460]     // TODO: Properties may change the kernel function, so in order to avoid
[ 1461]     //       conflicts they should be included in the name.
[ 1462]     using NameT =
[ 1463]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 1464]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 1465]     using LambdaArgType =
[ 1466]         sycl::detail::lambda_arg_type<KernelType, group<Dims>>;
[ 1467]     (void)NumWorkGroups;
[ 1468]     (void)WorkGroupSize;
[ 1469]     (void)Props;
[ 1470]     kernel_parallel_for_work_group_wrapper<NameT, LambdaArgType, KernelType,
[ 1471]                                            PropertiesT>(KernelFunc);
[ 1472] #ifndef __SYCL_DEVICE_ONLY__
[ 1473]     processProperties<NameT, PropertiesT>(Props);
[ 1474]     nd_range<Dims> ExecRange =
[ 1475]         nd_range<Dims>(NumWorkGroups * WorkGroupSize, WorkGroupSize);
[ 1476]     detail::checkValueRange<Dims>(ExecRange);
[ 1477]     MNDRDesc.set(std::move(ExecRange));
[ 1478]     StoreLambda<NameT, KernelType, Dims, LambdaArgType>(std::move(KernelFunc));
[ 1479]     setType(detail::CG::Kernel);
[ 1480] #endif // __SYCL_DEVICE_ONLY__
[ 1481]   }
[ 1482] 
[ 1483] #ifdef SYCL_LANGUAGE_VERSION
[ 1484] #define __SYCL_KERNEL_ATTR__ [[clang::sycl_kernel]]
[ 1485] #else
[ 1486] #define __SYCL_KERNEL_ATTR__
[ 1487] #endif
[ 1488] 
[ 1489]   // NOTE: the name of this function - "kernel_single_task" - is used by the
[ 1490]   // Front End to determine kernel invocation kind.
[ 1491]   template <typename KernelName, typename KernelType, typename... Props>
[ 1492] #ifdef __SYCL_DEVICE_ONLY__
[ 1493]   [[__sycl_detail__::add_ir_attributes_function(
[ 1494]       "sycl-single-task",
[ 1495]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::name...,
[ 1496]       nullptr,
[ 1497]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::value...)]]
[ 1498] #endif
[ 1499]   __SYCL_KERNEL_ATTR__ void
[ 1500]   kernel_single_task(_KERNELFUNCPARAM(KernelFunc)) {
[ 1501] #ifdef __SYCL_DEVICE_ONLY__
[ 1502]     KernelFunc();
[ 1503] #else
[ 1504]     (void)KernelFunc;
[ 1505] #endif
[ 1506]   }
[ 1507] 
[ 1508]   // NOTE: the name of this function - "kernel_single_task" - is used by the
[ 1509]   // Front End to determine kernel invocation kind.
[ 1510]   template <typename KernelName, typename KernelType, typename... Props>
[ 1511] #ifdef __SYCL_DEVICE_ONLY__
[ 1512]   [[__sycl_detail__::add_ir_attributes_function(
[ 1513]       "sycl-single-task",
[ 1514]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::name...,
[ 1515]       nullptr,
[ 1516]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::value...)]]
[ 1517] #endif
[ 1518]   __SYCL_KERNEL_ATTR__ void
[ 1519]   kernel_single_task(_KERNELFUNCPARAM(KernelFunc), kernel_handler KH) {
[ 1520] #ifdef __SYCL_DEVICE_ONLY__
[ 1521]     KernelFunc(KH);
[ 1522] #else
[ 1523]     (void)KernelFunc;
[ 1524]     (void)KH;
[ 1525] #endif
[ 1526]   }
[ 1527] 
[ 1528]   // NOTE: the name of these functions - "kernel_parallel_for" - are used by the
[ 1529]   // Front End to determine kernel invocation kind.
[ 1530]   template <typename KernelName, typename ElementType, typename KernelType,
[ 1531]             typename... Props>
[ 1532] #ifdef __SYCL_DEVICE_ONLY__
[ 1533]   [[__sycl_detail__::add_ir_attributes_function(
[ 1534]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::name...,
[ 1535]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::value...)]]
[ 1536] #endif
[ 1537]   __SYCL_KERNEL_ATTR__ void
[ 1538]   kernel_parallel_for(_KERNELFUNCPARAM(KernelFunc)) {
[ 1539] #ifdef __SYCL_DEVICE_ONLY__
[ 1540]     KernelFunc(detail::Builder::getElement(detail::declptr<ElementType>()));
[ 1541] #else
[ 1542]     (void)KernelFunc;
[ 1543] #endif
[ 1544]   }
		[0x00AB8] (W)     mov (16|M0)              r127.0<1>:f   r0.0<1;1,0>:f                    {Compacted}
		[0x00AC0] (W)     send.gtwy (8|M0)         null     r127    null:0  0x0            0x02000010           {EOT,F@1} // wr:1+0, rd:0; end of thread
		[0x00AD0]         illegal                
		[0x00AE0]         illegal                
		[0x00AF0]         illegal                
		[0x00B00]         illegal                
		[0x00B10]         illegal                
		[0x00B20]         illegal                
		[0x00B30]         illegal                
		[0x00B40]         illegal                
		[0x00B50]         illegal                
		[0x00B60]         illegal                
[ 1545] 
[ 1546]   // NOTE: the name of these functions - "kernel_parallel_for" - are used by the
[ 1547]   // Front End to determine kernel invocation kind.
[ 1548]   template <typename KernelName, typename ElementType, typename KernelType,
[ 1549]             typename... Props>
[ 1550] #ifdef __SYCL_DEVICE_ONLY__
[ 1551]   [[__sycl_detail__::add_ir_attributes_function(
[ 1552]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::name...,
[ 1553]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::value...)]]
[ 1554] #endif
[ 1555]   __SYCL_KERNEL_ATTR__ void
[ 1556]   kernel_parallel_for(_KERNELFUNCPARAM(KernelFunc), kernel_handler KH) {
[ 1557] #ifdef __SYCL_DEVICE_ONLY__
[ 1558]     KernelFunc(detail::Builder::getElement(detail::declptr<ElementType>()), KH);
[ 1559] #else
[ 1560]     (void)KernelFunc;
[ 1561]     (void)KH;
[ 1562] #endif
[ 1563]   }
[ 1564] 
[ 1565]   // NOTE: the name of this function - "kernel_parallel_for_work_group" - is
[ 1566]   // used by the Front End to determine kernel invocation kind.
[ 1567]   template <typename KernelName, typename ElementType, typename KernelType,
[ 1568]             typename... Props>
[ 1569] #ifdef __SYCL_DEVICE_ONLY__
[ 1570]   [[__sycl_detail__::add_ir_attributes_function(
[ 1571]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::name...,
[ 1572]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::value...)]]
[ 1573] #endif
[ 1574]   __SYCL_KERNEL_ATTR__ void
[ 1575]   kernel_parallel_for_work_group(_KERNELFUNCPARAM(KernelFunc)) {
[ 1576] #ifdef __SYCL_DEVICE_ONLY__
[ 1577]     KernelFunc(detail::Builder::getElement(detail::declptr<ElementType>()));
[ 1578] #else
[ 1579]     (void)KernelFunc;
[ 1580] #endif
[ 1581]   }
[ 1582] 
[ 1583]   // NOTE: the name of this function - "kernel_parallel_for_work_group" - is
[ 1584]   // used by the Front End to determine kernel invocation kind.
[ 1585]   template <typename KernelName, typename ElementType, typename KernelType,
[ 1586]             typename... Props>
[ 1587] #ifdef __SYCL_DEVICE_ONLY__
[ 1588]   [[__sycl_detail__::add_ir_attributes_function(
[ 1589]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::name...,
[ 1590]       ext::oneapi::experimental::detail::PropertyMetaInfo<Props>::value...)]]
[ 1591] #endif
[ 1592]   __SYCL_KERNEL_ATTR__ void
[ 1593]   kernel_parallel_for_work_group(_KERNELFUNCPARAM(KernelFunc),
[ 1594]                                  kernel_handler KH) {
[ 1595] #ifdef __SYCL_DEVICE_ONLY__
[ 1596]     KernelFunc(detail::Builder::getElement(detail::declptr<ElementType>()), KH);
[ 1597] #else
[ 1598]     (void)KernelFunc;
[ 1599]     (void)KH;
[ 1600] #endif
[ 1601]   }
[ 1602] 
[ 1603]   template <typename... Props> struct KernelPropertiesUnpackerImpl {
[ 1604]     // Just pass extra Props... as template parameters to the underlying
[ 1605]     // Caller->* member functions. Don't have reflection so try to use
[ 1606]     // templates as much as possible to reduce the amount of boilerplate code
[ 1607]     // needed. All the type checks are expected to be done at the Caller's
[ 1608]     // methods side.
[ 1609] 
[ 1610]     template <typename... TypesToForward, typename... ArgsTy>
[ 1611]     static void kernel_single_task_unpack(handler *h, ArgsTy... Args) {
[ 1612]       h->kernel_single_task<TypesToForward..., Props...>(Args...);
[ 1613]     }
[ 1614] 
[ 1615]     template <typename... TypesToForward, typename... ArgsTy>
[ 1616]     static void kernel_parallel_for_unpack(handler *h, ArgsTy... Args) {
[ 1617]       h->kernel_parallel_for<TypesToForward..., Props...>(Args...);
[ 1618]     }
[ 1619] 
[ 1620]     template <typename... TypesToForward, typename... ArgsTy>
[ 1621]     static void kernel_parallel_for_work_group_unpack(handler *h,
[ 1622]                                                       ArgsTy... Args) {
[ 1623]       h->kernel_parallel_for_work_group<TypesToForward..., Props...>(Args...);
[ 1624]     }
[ 1625]   };
[ 1626] 
[ 1627]   template <typename PropertiesT>
[ 1628]   struct KernelPropertiesUnpacker : public KernelPropertiesUnpackerImpl<> {
[ 1629]     // This should always fail outside the specialization below but must be
[ 1630]     // dependent to avoid failing even if not instantiated.
[ 1631]     static_assert(
[ 1632]         ext::oneapi::experimental::is_property_list<PropertiesT>::value,
[ 1633]         "Template type is not a property list.");
[ 1634]   };
[ 1635] 
[ 1636]   template <typename... Props>
[ 1637]   struct KernelPropertiesUnpacker<
[ 1638]       ext::oneapi::experimental::detail::properties_t<Props...>>
[ 1639]       : public KernelPropertiesUnpackerImpl<Props...> {};
[ 1640] 
[ 1641]   // Helper function to
[ 1642]   //
[ 1643]   //   * Make use of the KernelPropertiesUnpacker above
[ 1644]   //   * Decide if we need an extra kernel_handler parameter
[ 1645]   //
[ 1646]   // The interface uses a \p Lambda callback to propagate that information back
[ 1647]   // to the caller as we need the caller to communicate:
[ 1648]   //
[ 1649]   //   * Name of the method to call
[ 1650]   //   * Provide explicit template type parameters for the call
[ 1651]   //
[ 1652]   // Couldn't think of a better way to achieve both.
[ 1653]   template <typename KernelName, typename KernelType, typename PropertiesT,
[ 1654]             bool HasKernelHandlerArg, typename FuncTy>
[ 1655]   void unpack(_KERNELFUNCPARAM(KernelFunc), FuncTy Lambda) {
[ 1656] #ifdef __SYCL_DEVICE_ONLY__
[ 1657]     detail::CheckDeviceCopyable<KernelType>();
[ 1658] #endif // __SYCL_DEVICE_ONLY__
[ 1659]     using MergedPropertiesT =
[ 1660]         typename detail::GetMergedKernelProperties<KernelType,
[ 1661]                                                    PropertiesT>::type;
[ 1662]     using Unpacker = KernelPropertiesUnpacker<MergedPropertiesT>;
[ 1663] #ifndef __SYCL_DEVICE_ONLY__
[ 1664]     // If there are properties provided by get method then process them.
[ 1665]     if constexpr (ext::oneapi::experimental::detail::
[ 1666]                       HasKernelPropertiesGetMethod<
[ 1667]                           _KERNELFUNCPARAMTYPE>::value) {
[ 1668]       processProperties<KernelName>(
[ 1669]           KernelFunc.get(ext::oneapi::experimental::properties_tag{}));
[ 1670]     }
[ 1671] #endif
[ 1672]     if constexpr (HasKernelHandlerArg) {
[ 1673]       kernel_handler KH;
[ 1674]       Lambda(Unpacker{}, this, KernelFunc, KH);
[ 1675]     } else {
[ 1676]       Lambda(Unpacker{}, this, KernelFunc);
[ 1677]     }
[ 1678]   }
[ 1679] 
[ 1680]   // NOTE: to support kernel_handler argument in kernel lambdas, only
[ 1681]   // kernel_***_wrapper functions must be called in this code
[ 1682] 
[ 1683]   template <
[ 1684]       typename KernelName, typename KernelType,
[ 1685]       typename PropertiesT = ext::oneapi::experimental::empty_properties_t>
[ 1686]   void kernel_single_task_wrapper(_KERNELFUNCPARAM(KernelFunc)) {
[ 1687]     unpack<KernelName, KernelType, PropertiesT,
[ 1688]            detail::KernelLambdaHasKernelHandlerArgT<KernelType>::value>(
[ 1689]         KernelFunc, [&](auto Unpacker, auto... args) {
[ 1690]           Unpacker.template kernel_single_task_unpack<KernelName, KernelType>(
[ 1691]               args...);
[ 1692]         });
[ 1693]   }
[ 1694] 
[ 1695]   template <
[ 1696]       typename KernelName, typename ElementType, typename KernelType,
[ 1697]       typename PropertiesT = ext::oneapi::experimental::empty_properties_t>
[ 1698]   void kernel_parallel_for_wrapper(_KERNELFUNCPARAM(KernelFunc)) {
[ 1699]     unpack<KernelName, KernelType, PropertiesT,
[ 1700]            detail::KernelLambdaHasKernelHandlerArgT<KernelType,
[ 1701]                                                     ElementType>::value>(
[ 1702]         KernelFunc, [&](auto Unpacker, auto... args) {
[ 1703]           Unpacker.template kernel_parallel_for_unpack<KernelName, ElementType,
[ 1704]                                                        KernelType>(args...);
[ 1705]         });
[ 1706]   }
[ 1707] 
[ 1708]   template <
[ 1709]       typename KernelName, typename ElementType, typename KernelType,
[ 1710]       typename PropertiesT = ext::oneapi::experimental::empty_properties_t>
[ 1711]   void kernel_parallel_for_work_group_wrapper(_KERNELFUNCPARAM(KernelFunc)) {
[ 1712]     unpack<KernelName, KernelType, PropertiesT,
[ 1713]            detail::KernelLambdaHasKernelHandlerArgT<KernelType,
[ 1714]                                                     ElementType>::value>(
[ 1715]         KernelFunc, [&](auto Unpacker, auto... args) {
[ 1716]           Unpacker.template kernel_parallel_for_work_group_unpack<
[ 1717]               KernelName, ElementType, KernelType>(args...);
[ 1718]         });
[ 1719]   }
[ 1720] 
[ 1721]   /// Defines and invokes a SYCL kernel function as a function object type.
[ 1722]   ///
[ 1723]   /// If it is a named function object and the function object type is
[ 1724]   /// globally visible, there is no need for the developer to provide
[ 1725]   /// a kernel name for it.
[ 1726]   ///
[ 1727]   /// \param KernelFunc is a SYCL kernel function.
[ 1728]   template <
[ 1729]       typename KernelName, typename KernelType,
[ 1730]       typename PropertiesT = ext::oneapi::experimental::empty_properties_t>
[ 1731]   void single_task_lambda_impl(PropertiesT Props,
[ 1732]                                _KERNELFUNCPARAM(KernelFunc)) {
[ 1733]     (void)Props;
[ 1734]     throwIfActionIsCreated();
[ 1735]     throwOnLocalAccessorMisuse<KernelName, KernelType>();
[ 1736]     // TODO: Properties may change the kernel function, so in order to avoid
[ 1737]     //       conflicts they should be included in the name.
[ 1738]     using NameT =
[ 1739]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 1740]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 1741]     kernel_single_task_wrapper<NameT, KernelType, PropertiesT>(KernelFunc);
[ 1742] #ifndef __SYCL_DEVICE_ONLY__
[ 1743]     // No need to check if range is out of INT_MAX limits as it's compile-time
[ 1744]     // known constant.
[ 1745]     MNDRDesc.set(range<1>{1});
[ 1746]     processProperties<NameT, PropertiesT>(Props);
[ 1747]     StoreLambda<NameT, KernelType, /*Dims*/ 1, void>(KernelFunc);
[ 1748]     setType(detail::CG::Kernel);
[ 1749] #endif
[ 1750]   }
[ 1751] 
[ 1752]   void setStateExplicitKernelBundle();
[ 1753]   void setStateSpecConstSet();
[ 1754]   bool isStateExplicitKernelBundle() const;
[ 1755] 
[ 1756]   std::shared_ptr<detail::kernel_bundle_impl>
[ 1757]   getOrInsertHandlerKernelBundle(bool Insert) const;
[ 1758] 
[ 1759]   void setHandlerKernelBundle(kernel Kernel);
[ 1760] 
[ 1761]   void setHandlerKernelBundle(
[ 1762]       const std::shared_ptr<detail::kernel_bundle_impl> &NewKernelBundleImpPtr);
[ 1763] 
[ 1764]   template <typename FuncT>
[ 1765]   std::enable_if_t<detail::check_fn_signature<std::remove_reference_t<FuncT>,
[ 1766]                                               void()>::value ||
[ 1767]                    detail::check_fn_signature<std::remove_reference_t<FuncT>,
[ 1768]                                               void(interop_handle)>::value>
[ 1769]   host_task_impl(FuncT &&Func) {
[ 1770]     throwIfActionIsCreated();
[ 1771] 
[ 1772]     MNDRDesc.set(range<1>(1));
[ 1773]     MArgs = std::move(MAssociatedAccesors);
[ 1774] 
[ 1775]     MHostTask.reset(new detail::HostTask(std::move(Func)));
[ 1776] 
[ 1777]     setType(detail::CG::CodeplayHostTask);
[ 1778]   }
[ 1779] 
[ 1780]   /// @brief Get the command graph if any associated with this handler. It can
[ 1781]   /// come from either the associated queue or from being set explicitly through
[ 1782]   /// the appropriate constructor.
[ 1783]   std::shared_ptr<ext::oneapi::experimental::detail::graph_impl>
[ 1784]   getCommandGraph() const;
[ 1785] 
[ 1786] public:
[ 1787]   handler(const handler &) = delete;
[ 1788]   handler(handler &&) = delete;
[ 1789]   handler &operator=(const handler &) = delete;
[ 1790]   handler &operator=(handler &&) = delete;
[ 1791] 
[ 1792]   template <auto &SpecName>
[ 1793]   void set_specialization_constant(
[ 1794]       typename std::remove_reference_t<decltype(SpecName)>::value_type Value) {
[ 1795] 
[ 1796]     setStateSpecConstSet();
[ 1797] 
[ 1798]     std::shared_ptr<detail::kernel_bundle_impl> KernelBundleImplPtr =
[ 1799]         getOrInsertHandlerKernelBundle(/*Insert=*/true);
[ 1800] 
[ 1801]     detail::createSyclObjFromImpl<kernel_bundle<bundle_state::input>>(
[ 1802]         KernelBundleImplPtr)
[ 1803]         .set_specialization_constant<SpecName>(Value);
[ 1804]   }
[ 1805] 
[ 1806]   template <auto &SpecName>
[ 1807]   typename std::remove_reference_t<decltype(SpecName)>::value_type
[ 1808]   get_specialization_constant() const {
[ 1809] 
[ 1810]     if (isStateExplicitKernelBundle())
[ 1811]       throw sycl::exception(make_error_code(errc::invalid),
[ 1812]                             "Specialization constants cannot be read after "
[ 1813]                             "explicitly setting the used kernel bundle");
[ 1814] 
[ 1815]     std::shared_ptr<detail::kernel_bundle_impl> KernelBundleImplPtr =
[ 1816]         getOrInsertHandlerKernelBundle(/*Insert=*/true);
[ 1817] 
[ 1818]     return detail::createSyclObjFromImpl<kernel_bundle<bundle_state::input>>(
[ 1819]                KernelBundleImplPtr)
[ 1820]         .get_specialization_constant<SpecName>();
[ 1821]   }
[ 1822] 
[ 1823]   void
[ 1824]   use_kernel_bundle(const kernel_bundle<bundle_state::executable> &ExecBundle);
[ 1825] 
[ 1826]   /// Requires access to the memory object associated with the placeholder
[ 1827]   /// accessor. Calling this function with a non-placeholder accessor has no
[ 1828]   /// effect.
[ 1829]   ///
[ 1830]   /// The command group has a requirement to gain access to the given memory
[ 1831]   /// object before executing.
[ 1832]   ///
[ 1833]   /// \param Acc is a SYCL accessor describing required memory region.
[ 1834]   template <typename DataT, int Dims, access::mode AccMode,
[ 1835]             access::target AccTarget, access::placeholder isPlaceholder>
[ 1836]   void require(accessor<DataT, Dims, AccMode, AccTarget, isPlaceholder> Acc) {
[ 1837]     if (Acc.is_placeholder())
[ 1838]       associateWithHandler(&Acc, AccTarget);
[ 1839]   }
[ 1840] 
[ 1841]   /// Registers event dependencies on this command group.
[ 1842]   ///
[ 1843]   /// \param Event is a valid SYCL event to wait on.
[ 1844]   void depends_on(event Event);
[ 1845] 
[ 1846]   /// Registers event dependencies on this command group.
[ 1847]   ///
[ 1848]   /// \param Events is a vector of valid SYCL events to wait on.
[ 1849]   void depends_on(const std::vector<event> &Events);
[ 1850] 
[ 1851]   template <typename T>
[ 1852]   using remove_cv_ref_t = typename std::remove_cv_t<std::remove_reference_t<T>>;
[ 1853] 
[ 1854]   template <typename U, typename T>
[ 1855]   using is_same_type = std::is_same<remove_cv_ref_t<U>, remove_cv_ref_t<T>>;
[ 1856] 
[ 1857]   template <typename T> struct ShouldEnableSetArg {
[ 1858]     static constexpr bool value =
[ 1859]         std::is_trivially_copyable_v<std::remove_reference_t<T>>
[ 1860] #if SYCL_LANGUAGE_VERSION && SYCL_LANGUAGE_VERSION <= 201707
[ 1861]             && std::is_standard_layout<std::remove_reference_t<T>>::value
[ 1862] #endif
[ 1863]         || is_same_type<sampler, T>::value // Sampler
[ 1864]         || (!is_same_type<cl_mem, T>::value &&
[ 1865]             std::is_pointer_v<remove_cv_ref_t<T>>) // USM
[ 1866]         || is_same_type<cl_mem, T>::value;         // Interop
[ 1867]   };
[ 1868] 
[ 1869]   /// Sets argument for OpenCL interoperability kernels.
[ 1870]   ///
[ 1871]   /// Registers Arg passed as argument # ArgIndex.
[ 1872]   ///
[ 1873]   /// \param ArgIndex is a positional number of argument to be set.
[ 1874]   /// \param Arg is an argument value to be set.
[ 1875]   template <typename T>
[ 1876]   typename std::enable_if_t<ShouldEnableSetArg<T>::value, void>
[ 1877]   set_arg(int ArgIndex, T &&Arg) {
[ 1878]     setArgHelper(ArgIndex, std::move(Arg));
[ 1879]   }
[ 1880] 
[ 1881]   template <typename DataT, int Dims, access::mode AccessMode,
[ 1882]             access::target AccessTarget, access::placeholder IsPlaceholder>
[ 1883]   void
[ 1884]   set_arg(int ArgIndex,
[ 1885]           accessor<DataT, Dims, AccessMode, AccessTarget, IsPlaceholder> Arg) {
[ 1886]     setArgHelper(ArgIndex, std::move(Arg));
[ 1887]   }
[ 1888] 
[ 1889]   template <typename DataT, int Dims>
[ 1890]   void set_arg(int ArgIndex, local_accessor<DataT, Dims> Arg) {
[ 1891]     setArgHelper(ArgIndex, std::move(Arg));
[ 1892]   }
[ 1893] 
[ 1894]   /// Sets arguments for OpenCL interoperability kernels.
[ 1895]   ///
[ 1896]   /// Registers pack of arguments(Args) with indexes starting from 0.
[ 1897]   ///
[ 1898]   /// \param Args are argument values to be set.
[ 1899]   template <typename... Ts> void set_args(Ts &&...Args) {
[ 1900]     setArgsHelper(0, std::move(Args)...);
[ 1901]   }
[ 1902] 
[ 1903]   /// Defines and invokes a SYCL kernel function as a function object type.
[ 1904]   ///
[ 1905]   /// If it is a named function object and the function object type is
[ 1906]   /// globally visible, there is no need for the developer to provide
[ 1907]   /// a kernel name for it.
[ 1908]   ///
[ 1909]   /// \param KernelFunc is a SYCL kernel function.
[ 1910]   template <typename KernelName = detail::auto_name, typename KernelType>
[ 1911]   void single_task(_KERNELFUNCPARAM(KernelFunc)) {
[ 1912]     single_task_lambda_impl<KernelName>(
[ 1913]         ext::oneapi::experimental::empty_properties_t{}, KernelFunc);
[ 1914]   }
[ 1915] 
[ 1916]   template <typename KernelName = detail::auto_name, typename KernelType>
[ 1917]   void parallel_for(range<1> NumWorkItems, _KERNELFUNCPARAM(KernelFunc)) {
[ 1918]     parallel_for_lambda_impl<KernelName>(
[ 1919]         NumWorkItems, ext::oneapi::experimental::empty_properties_t{},
[ 1920]         std::move(KernelFunc));
[ 1921]   }
[ 1922] 
[ 1923]   template <typename KernelName = detail::auto_name, typename KernelType>
[ 1924]   void parallel_for(range<2> NumWorkItems, _KERNELFUNCPARAM(KernelFunc)) {
[ 1925]     parallel_for_lambda_impl<KernelName>(
[ 1926]         NumWorkItems, ext::oneapi::experimental::empty_properties_t{},
[ 1927]         std::move(KernelFunc));
[ 1928]   }
[ 1929] 
[ 1930]   template <typename KernelName = detail::auto_name, typename KernelType>
[ 1931]   void parallel_for(range<3> NumWorkItems, _KERNELFUNCPARAM(KernelFunc)) {
[ 1932]     parallel_for_lambda_impl<KernelName>(
[ 1933]         NumWorkItems, ext::oneapi::experimental::empty_properties_t{},
[ 1934]         std::move(KernelFunc));
[ 1935]   }
[ 1936] 
[ 1937]   /// Enqueues a command to the SYCL runtime to invoke \p Func once.
[ 1938]   template <typename FuncT>
[ 1939]   std::enable_if_t<detail::check_fn_signature<std::remove_reference_t<FuncT>,
[ 1940]                                               void()>::value ||
[ 1941]                    detail::check_fn_signature<std::remove_reference_t<FuncT>,
[ 1942]                                               void(interop_handle)>::value>
[ 1943]   host_task(FuncT &&Func) {
[ 1944]     host_task_impl(Func);
[ 1945]   }
[ 1946] 
[ 1947]   /// Defines and invokes a SYCL kernel function for the specified range and
[ 1948]   /// offset.
[ 1949]   ///
[ 1950]   /// The SYCL kernel function is defined as a lambda function or a named
[ 1951]   /// function object type and given an id or item for indexing in the indexing
[ 1952]   /// space defined by range.
[ 1953]   /// If it is a named function object and the function object type is
[ 1954]   /// globally visible, there is no need for the developer to provide
[ 1955]   /// a kernel name for it.
[ 1956]   ///
[ 1957]   /// \param NumWorkItems is a range defining indexing space.
[ 1958]   /// \param WorkItemOffset is an offset to be applied to each work item index.
[ 1959]   /// \param KernelFunc is a SYCL kernel function.
[ 1960]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 1961]             int Dims>
[ 1962]   __SYCL2020_DEPRECATED("offsets are deprecated in SYCL2020")
[ 1963]   void parallel_for(range<Dims> NumWorkItems, id<Dims> WorkItemOffset,
[ 1964]                     _KERNELFUNCPARAM(KernelFunc)) {
[ 1965]     throwIfActionIsCreated();
[ 1966]     using NameT =
[ 1967]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 1968]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 1969]     using LambdaArgType = sycl::detail::lambda_arg_type<KernelType, item<Dims>>;
[ 1970]     using TransformedArgType = std::conditional_t<
[ 1971]         std::is_integral<LambdaArgType>::value && Dims == 1, item<Dims>,
[ 1972]         typename TransformUserItemType<Dims, LambdaArgType>::type>;
[ 1973]     (void)NumWorkItems;
[ 1974]     (void)WorkItemOffset;
[ 1975]     kernel_parallel_for_wrapper<NameT, TransformedArgType>(KernelFunc);
[ 1976] #ifndef __SYCL_DEVICE_ONLY__
[ 1977]     detail::checkValueRange<Dims>(NumWorkItems, WorkItemOffset);
[ 1978]     MNDRDesc.set(std::move(NumWorkItems), std::move(WorkItemOffset));
[ 1979]     StoreLambda<NameT, KernelType, Dims, TransformedArgType>(
[ 1980]         std::move(KernelFunc));
[ 1981]     setType(detail::CG::Kernel);
[ 1982] #endif
[ 1983]   }
[ 1984] 
[ 1985]   /// Hierarchical kernel invocation method of a kernel defined as a lambda
[ 1986]   /// encoding the body of each work-group to launch.
[ 1987]   ///
[ 1988]   /// Lambda may contain multiple calls to parallel_for_work_item(...) methods
[ 1989]   /// representing the execution on each work-item. Launches NumWorkGroups
[ 1990]   /// work-groups of runtime-defined size.
[ 1991]   ///
[ 1992]   /// \param NumWorkGroups is a range describing the number of work-groups in
[ 1993]   /// each dimension.
[ 1994]   /// \param KernelFunc is a lambda representing kernel.
[ 1995]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 1996]             int Dims>
[ 1997]   void parallel_for_work_group(range<Dims> NumWorkGroups,
[ 1998]                                _KERNELFUNCPARAM(KernelFunc)) {
[ 1999]     parallel_for_work_group_lambda_impl<KernelName>(
[ 2000]         NumWorkGroups, ext::oneapi::experimental::empty_properties_t{},
[ 2001]         KernelFunc);
[ 2002]   }
[ 2003] 
[ 2004]   /// Hierarchical kernel invocation method of a kernel defined as a lambda
[ 2005]   /// encoding the body of each work-group to launch.
[ 2006]   ///
[ 2007]   /// Lambda may contain multiple calls to parallel_for_work_item(...) methods
[ 2008]   /// representing the execution on each work-item. Launches NumWorkGroups
[ 2009]   /// work-groups of WorkGroupSize size.
[ 2010]   ///
[ 2011]   /// \param NumWorkGroups is a range describing the number of work-groups in
[ 2012]   /// each dimension.
[ 2013]   /// \param WorkGroupSize is a range describing the size of work-groups in
[ 2014]   /// each dimension.
[ 2015]   /// \param KernelFunc is a lambda representing kernel.
[ 2016]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2017]             int Dims>
[ 2018]   void parallel_for_work_group(range<Dims> NumWorkGroups,
[ 2019]                                range<Dims> WorkGroupSize,
[ 2020]                                _KERNELFUNCPARAM(KernelFunc)) {
[ 2021]     parallel_for_work_group_lambda_impl<KernelName>(
[ 2022]         NumWorkGroups, WorkGroupSize,
[ 2023]         ext::oneapi::experimental::empty_properties_t{}, KernelFunc);
[ 2024]   }
[ 2025] 
[ 2026]   /// Invokes a SYCL kernel.
[ 2027]   ///
[ 2028]   /// Executes exactly once. The kernel invocation method has no functors and
[ 2029]   /// cannot be called on host.
[ 2030]   ///
[ 2031]   /// \param Kernel is a SYCL kernel object.
[ 2032]   void single_task(kernel Kernel) {
[ 2033]     throwIfActionIsCreated();
[ 2034]     // Ignore any set kernel bundles and use the one associated with the kernel
[ 2035]     setHandlerKernelBundle(Kernel);
[ 2036]     // No need to check if range is out of INT_MAX limits as it's compile-time
[ 2037]     // known constant
[ 2038]     MNDRDesc.set(range<1>{1});
[ 2039]     MKernel = detail::getSyclObjImpl(std::move(Kernel));
[ 2040]     setType(detail::CG::Kernel);
[ 2041]     extractArgsAndReqs();
[ 2042]     MKernelName = getKernelName();
[ 2043]   }
[ 2044] 
[ 2045]   void parallel_for(range<1> NumWorkItems, kernel Kernel) {
[ 2046]     parallel_for_impl(NumWorkItems, Kernel);
[ 2047]   }
[ 2048] 
[ 2049]   void parallel_for(range<2> NumWorkItems, kernel Kernel) {
[ 2050]     parallel_for_impl(NumWorkItems, Kernel);
[ 2051]   }
[ 2052] 
[ 2053]   void parallel_for(range<3> NumWorkItems, kernel Kernel) {
[ 2054]     parallel_for_impl(NumWorkItems, Kernel);
[ 2055]   }
[ 2056] 
[ 2057]   /// Defines and invokes a SYCL kernel function for the specified range and
[ 2058]   /// offsets.
[ 2059]   ///
[ 2060]   /// The SYCL kernel function is defined as SYCL kernel object.
[ 2061]   ///
[ 2062]   /// \param NumWorkItems is a range defining indexing space.
[ 2063]   /// \param WorkItemOffset is an offset to be applied to each work item index.
[ 2064]   /// \param Kernel is a SYCL kernel function.
[ 2065]   template <int Dims>
[ 2066]   __SYCL2020_DEPRECATED("offsets are deprecated in SYCL 2020")
[ 2067]   void parallel_for(range<Dims> NumWorkItems, id<Dims> WorkItemOffset,
[ 2068]                     kernel Kernel) {
[ 2069]     throwIfActionIsCreated();
[ 2070]     MKernel = detail::getSyclObjImpl(std::move(Kernel));
[ 2071]     detail::checkValueRange<Dims>(NumWorkItems, WorkItemOffset);
[ 2072]     MNDRDesc.set(std::move(NumWorkItems), std::move(WorkItemOffset));
[ 2073]     setType(detail::CG::Kernel);
[ 2074]     extractArgsAndReqs();
[ 2075]     MKernelName = getKernelName();
[ 2076]   }
[ 2077] 
[ 2078]   /// Defines and invokes a SYCL kernel function for the specified range and
[ 2079]   /// offsets.
[ 2080]   ///
[ 2081]   /// The SYCL kernel function is defined as SYCL kernel object.
[ 2082]   ///
[ 2083]   /// \param NDRange is a ND-range defining global and local sizes as
[ 2084]   /// well as offset.
[ 2085]   /// \param Kernel is a SYCL kernel function.
[ 2086]   template <int Dims> void parallel_for(nd_range<Dims> NDRange, kernel Kernel) {
[ 2087]     throwIfActionIsCreated();
[ 2088]     MKernel = detail::getSyclObjImpl(std::move(Kernel));
[ 2089]     detail::checkValueRange<Dims>(NDRange);
[ 2090]     MNDRDesc.set(std::move(NDRange));
[ 2091]     setType(detail::CG::Kernel);
[ 2092]     extractArgsAndReqs();
[ 2093]     MKernelName = getKernelName();
[ 2094]   }
[ 2095] 
[ 2096]   /// Defines and invokes a SYCL kernel function.
[ 2097]   ///
[ 2098]   /// \param Kernel is a SYCL kernel that is executed on a SYCL device
[ 2099]   /// (except for the host device).
[ 2100]   /// \param KernelFunc is a lambda that is used if device, queue is bound to,
[ 2101]   /// is a host device.
[ 2102]   template <typename KernelName = detail::auto_name, typename KernelType>
[ 2103]   void single_task(kernel Kernel, _KERNELFUNCPARAM(KernelFunc)) {
[ 2104]     throwIfActionIsCreated();
[ 2105]     // Ignore any set kernel bundles and use the one associated with the kernel
[ 2106]     setHandlerKernelBundle(Kernel);
[ 2107]     using NameT =
[ 2108]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 2109]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 2110]     (void)Kernel;
[ 2111]     kernel_single_task<NameT>(KernelFunc);
[ 2112] #ifndef __SYCL_DEVICE_ONLY__
[ 2113]     // No need to check if range is out of INT_MAX limits as it's compile-time
[ 2114]     // known constant
[ 2115]     MNDRDesc.set(range<1>{1});
[ 2116]     MKernel = detail::getSyclObjImpl(std::move(Kernel));
[ 2117]     setType(detail::CG::Kernel);
[ 2118]     if (!MIsHost && !lambdaAndKernelHaveEqualName<NameT>()) {
[ 2119]       extractArgsAndReqs();
[ 2120]       MKernelName = getKernelName();
[ 2121]     } else
[ 2122]       StoreLambda<NameT, KernelType, /*Dims*/ 1, void>(std::move(KernelFunc));
[ 2123] #else
[ 2124]     detail::CheckDeviceCopyable<KernelType>();
[ 2125] #endif
[ 2126]   }
[ 2127] 
[ 2128]   /// Defines and invokes a SYCL kernel function for the specified range.
[ 2129]   ///
[ 2130]   /// \param Kernel is a SYCL kernel that is executed on a SYCL device
[ 2131]   /// (except for the host device).
[ 2132]   /// \param NumWorkItems is a range defining indexing space.
[ 2133]   /// \param KernelFunc is a lambda that is used if device, queue is bound to,
[ 2134]   /// is a host device.
[ 2135]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2136]             int Dims>
[ 2137]   void parallel_for(kernel Kernel, range<Dims> NumWorkItems,
[ 2138]                     _KERNELFUNCPARAM(KernelFunc)) {
[ 2139]     throwIfActionIsCreated();
[ 2140]     // Ignore any set kernel bundles and use the one associated with the kernel
[ 2141]     setHandlerKernelBundle(Kernel);
[ 2142]     using NameT =
[ 2143]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 2144]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 2145]     using LambdaArgType = sycl::detail::lambda_arg_type<KernelType, item<Dims>>;
[ 2146]     (void)Kernel;
[ 2147]     (void)NumWorkItems;
[ 2148]     kernel_parallel_for_wrapper<NameT, LambdaArgType>(KernelFunc);
[ 2149] #ifndef __SYCL_DEVICE_ONLY__
[ 2150]     detail::checkValueRange<Dims>(NumWorkItems);
[ 2151]     MNDRDesc.set(std::move(NumWorkItems));
[ 2152]     MKernel = detail::getSyclObjImpl(std::move(Kernel));
[ 2153]     setType(detail::CG::Kernel);
[ 2154]     if (!MIsHost && !lambdaAndKernelHaveEqualName<NameT>()) {
[ 2155]       extractArgsAndReqs();
[ 2156]       MKernelName = getKernelName();
[ 2157]     } else
[ 2158]       StoreLambda<NameT, KernelType, Dims, LambdaArgType>(
[ 2159]           std::move(KernelFunc));
[ 2160] #endif
[ 2161]   }
[ 2162] 
[ 2163]   /// Defines and invokes a SYCL kernel function for the specified range and
[ 2164]   /// offsets.
[ 2165]   ///
[ 2166]   /// \param Kernel is a SYCL kernel that is executed on a SYCL device
[ 2167]   /// (except for the host device).
[ 2168]   /// \param NumWorkItems is a range defining indexing space.
[ 2169]   /// \param WorkItemOffset is an offset to be applied to each work item index.
[ 2170]   /// \param KernelFunc is a lambda that is used if device, queue is bound to,
[ 2171]   /// is a host device.
[ 2172]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2173]             int Dims>
[ 2174]   __SYCL2020_DEPRECATED("offsets are deprecated in SYCL 2020")
[ 2175]   void parallel_for(kernel Kernel, range<Dims> NumWorkItems,
[ 2176]                     id<Dims> WorkItemOffset, _KERNELFUNCPARAM(KernelFunc)) {
[ 2177]     throwIfActionIsCreated();
[ 2178]     // Ignore any set kernel bundles and use the one associated with the kernel
[ 2179]     setHandlerKernelBundle(Kernel);
[ 2180]     using NameT =
[ 2181]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 2182]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 2183]     using LambdaArgType = sycl::detail::lambda_arg_type<KernelType, item<Dims>>;
[ 2184]     (void)Kernel;
[ 2185]     (void)NumWorkItems;
[ 2186]     (void)WorkItemOffset;
[ 2187]     kernel_parallel_for_wrapper<NameT, LambdaArgType>(KernelFunc);
[ 2188] #ifndef __SYCL_DEVICE_ONLY__
[ 2189]     detail::checkValueRange<Dims>(NumWorkItems, WorkItemOffset);
[ 2190]     MNDRDesc.set(std::move(NumWorkItems), std::move(WorkItemOffset));
[ 2191]     MKernel = detail::getSyclObjImpl(std::move(Kernel));
[ 2192]     setType(detail::CG::Kernel);
[ 2193]     if (!MIsHost && !lambdaAndKernelHaveEqualName<NameT>()) {
[ 2194]       extractArgsAndReqs();
[ 2195]       MKernelName = getKernelName();
[ 2196]     } else
[ 2197]       StoreLambda<NameT, KernelType, Dims, LambdaArgType>(
[ 2198]           std::move(KernelFunc));
[ 2199] #endif
[ 2200]   }
[ 2201] 
[ 2202]   /// Defines and invokes a SYCL kernel function for the specified range and
[ 2203]   /// offsets.
[ 2204]   ///
[ 2205]   /// \param Kernel is a SYCL kernel that is executed on a SYCL device
[ 2206]   /// (except for the host device).
[ 2207]   /// \param NDRange is a ND-range defining global and local sizes as
[ 2208]   /// well as offset.
[ 2209]   /// \param KernelFunc is a lambda that is used if device, queue is bound to,
[ 2210]   /// is a host device.
[ 2211]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2212]             int Dims>
[ 2213]   void parallel_for(kernel Kernel, nd_range<Dims> NDRange,
[ 2214]                     _KERNELFUNCPARAM(KernelFunc)) {
[ 2215]     throwIfActionIsCreated();
[ 2216]     // Ignore any set kernel bundles and use the one associated with the kernel
[ 2217]     setHandlerKernelBundle(Kernel);
[ 2218]     using NameT =
[ 2219]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 2220]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 2221]     using LambdaArgType =
[ 2222]         sycl::detail::lambda_arg_type<KernelType, nd_item<Dims>>;
[ 2223]     (void)Kernel;
[ 2224]     (void)NDRange;
[ 2225]     kernel_parallel_for_wrapper<NameT, LambdaArgType>(KernelFunc);
[ 2226] #ifndef __SYCL_DEVICE_ONLY__
[ 2227]     detail::checkValueRange<Dims>(NDRange);
[ 2228]     MNDRDesc.set(std::move(NDRange));
[ 2229]     MKernel = detail::getSyclObjImpl(std::move(Kernel));
[ 2230]     setType(detail::CG::Kernel);
[ 2231]     if (!MIsHost && !lambdaAndKernelHaveEqualName<NameT>()) {
[ 2232]       extractArgsAndReqs();
[ 2233]       MKernelName = getKernelName();
[ 2234]     } else
[ 2235]       StoreLambda<NameT, KernelType, Dims, LambdaArgType>(
[ 2236]           std::move(KernelFunc));
[ 2237] #endif
[ 2238]   }
[ 2239] 
[ 2240]   /// Hierarchical kernel invocation method of a kernel.
[ 2241]   ///
[ 2242]   /// This version of \c parallel_for_work_group takes two parameters
[ 2243]   /// representing the same kernel. The first one - \c Kernel - is a
[ 2244]   /// compiled form of the second one - \c kernelFunc, which is the source form
[ 2245]   /// of the kernel. The same source kernel can be compiled multiple times
[ 2246]   /// yielding multiple kernel class objects accessible via the \c program class
[ 2247]   /// interface.
[ 2248]   ///
[ 2249]   /// \param Kernel is a compiled SYCL kernel.
[ 2250]   /// \param NumWorkGroups is a range describing the number of work-groups in
[ 2251]   /// each dimension.
[ 2252]   /// \param KernelFunc is a lambda representing kernel.
[ 2253]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2254]             int Dims>
[ 2255]   void parallel_for_work_group(kernel Kernel, range<Dims> NumWorkGroups,
[ 2256]                                _KERNELFUNCPARAM(KernelFunc)) {
[ 2257]     throwIfActionIsCreated();
[ 2258]     // Ignore any set kernel bundles and use the one associated with the kernel
[ 2259]     setHandlerKernelBundle(Kernel);
[ 2260]     using NameT =
[ 2261]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 2262]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 2263]     using LambdaArgType =
[ 2264]         sycl::detail::lambda_arg_type<KernelType, group<Dims>>;
[ 2265]     (void)Kernel;
[ 2266]     (void)NumWorkGroups;
[ 2267]     kernel_parallel_for_work_group_wrapper<NameT, LambdaArgType>(KernelFunc);
[ 2268] #ifndef __SYCL_DEVICE_ONLY__
[ 2269]     detail::checkValueRange<Dims>(NumWorkGroups);
[ 2270]     MNDRDesc.setNumWorkGroups(NumWorkGroups);
[ 2271]     MKernel = detail::getSyclObjImpl(std::move(Kernel));
[ 2272]     StoreLambda<NameT, KernelType, Dims, LambdaArgType>(std::move(KernelFunc));
[ 2273]     setType(detail::CG::Kernel);
[ 2274] #endif // __SYCL_DEVICE_ONLY__
[ 2275]   }
[ 2276] 
[ 2277]   /// Hierarchical kernel invocation method of a kernel.
[ 2278]   ///
[ 2279]   /// This version of \c parallel_for_work_group takes two parameters
[ 2280]   /// representing the same kernel. The first one - \c Kernel - is a
[ 2281]   /// compiled form of the second one - \c kernelFunc, which is the source form
[ 2282]   /// of the kernel. The same source kernel can be compiled multiple times
[ 2283]   /// yielding multiple kernel class objects accessible via the \c program class
[ 2284]   /// interface.
[ 2285]   ///
[ 2286]   /// \param Kernel is a compiled SYCL kernel.
[ 2287]   /// \param NumWorkGroups is a range describing the number of work-groups in
[ 2288]   /// each dimension.
[ 2289]   /// \param WorkGroupSize is a range describing the size of work-groups in
[ 2290]   /// each dimension.
[ 2291]   /// \param KernelFunc is a lambda representing kernel.
[ 2292]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2293]             int Dims>
[ 2294]   void parallel_for_work_group(kernel Kernel, range<Dims> NumWorkGroups,
[ 2295]                                range<Dims> WorkGroupSize,
[ 2296]                                _KERNELFUNCPARAM(KernelFunc)) {
[ 2297]     throwIfActionIsCreated();
[ 2298]     // Ignore any set kernel bundles and use the one associated with the kernel
[ 2299]     setHandlerKernelBundle(Kernel);
[ 2300]     using NameT =
[ 2301]         typename detail::get_kernel_name_t<KernelName, KernelType>::name;
[ 2302]     verifyUsedKernelBundle(detail::KernelInfo<NameT>::getName());
[ 2303]     using LambdaArgType =
[ 2304]         sycl::detail::lambda_arg_type<KernelType, group<Dims>>;
[ 2305]     (void)Kernel;
[ 2306]     (void)NumWorkGroups;
[ 2307]     (void)WorkGroupSize;
[ 2308]     kernel_parallel_for_work_group_wrapper<NameT, LambdaArgType>(KernelFunc);
[ 2309] #ifndef __SYCL_DEVICE_ONLY__
[ 2310]     nd_range<Dims> ExecRange =
[ 2311]         nd_range<Dims>(NumWorkGroups * WorkGroupSize, WorkGroupSize);
[ 2312]     detail::checkValueRange<Dims>(ExecRange);
[ 2313]     MNDRDesc.set(std::move(ExecRange));
[ 2314]     MKernel = detail::getSyclObjImpl(std::move(Kernel));
[ 2315]     StoreLambda<NameT, KernelType, Dims, LambdaArgType>(std::move(KernelFunc));
[ 2316]     setType(detail::CG::Kernel);
[ 2317] #endif // __SYCL_DEVICE_ONLY__
[ 2318]   }
[ 2319] 
[ 2320]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2321]             typename PropertiesT>
[ 2322]   std::enable_if_t<
[ 2323]       ext::oneapi::experimental::is_property_list<PropertiesT>::value>
[ 2324]   single_task(PropertiesT Props, _KERNELFUNCPARAM(KernelFunc)) {
[ 2325]     throwIfGraphAssociatedAndKernelProperties<PropertiesT>();
[ 2326]     single_task_lambda_impl<KernelName, KernelType, PropertiesT>(Props,
[ 2327]                                                                  KernelFunc);
[ 2328]   }
[ 2329] 
[ 2330]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2331]             typename PropertiesT>
[ 2332]   std::enable_if_t<
[ 2333]       ext::oneapi::experimental::is_property_list<PropertiesT>::value>
[ 2334]   parallel_for(range<1> NumWorkItems, PropertiesT Props,
[ 2335]                _KERNELFUNCPARAM(KernelFunc)) {
[ 2336]     throwIfGraphAssociatedAndKernelProperties<PropertiesT>();
[ 2337]     parallel_for_lambda_impl<KernelName, KernelType, 1, PropertiesT>(
[ 2338]         NumWorkItems, Props, std::move(KernelFunc));
[ 2339]   }
[ 2340] 
[ 2341]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2342]             typename PropertiesT>
[ 2343]   std::enable_if_t<
[ 2344]       ext::oneapi::experimental::is_property_list<PropertiesT>::value>
[ 2345]   parallel_for(range<2> NumWorkItems, PropertiesT Props,
[ 2346]                _KERNELFUNCPARAM(KernelFunc)) {
[ 2347]     throwIfGraphAssociatedAndKernelProperties<PropertiesT>();
[ 2348]     parallel_for_lambda_impl<KernelName, KernelType, 2, PropertiesT>(
[ 2349]         NumWorkItems, Props, std::move(KernelFunc));
[ 2350]   }
[ 2351] 
[ 2352]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2353]             typename PropertiesT>
[ 2354]   std::enable_if_t<
[ 2355]       ext::oneapi::experimental::is_property_list<PropertiesT>::value>
[ 2356]   parallel_for(range<3> NumWorkItems, PropertiesT Props,
[ 2357]                _KERNELFUNCPARAM(KernelFunc)) {
[ 2358]     throwIfGraphAssociatedAndKernelProperties<PropertiesT>();
[ 2359]     parallel_for_lambda_impl<KernelName, KernelType, 3, PropertiesT>(
[ 2360]         NumWorkItems, Props, std::move(KernelFunc));
[ 2361]   }
[ 2362] 
[ 2363]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2364]             typename PropertiesT, int Dims>
[ 2365]   std::enable_if_t<
[ 2366]       ext::oneapi::experimental::is_property_list<PropertiesT>::value>
[ 2367]   parallel_for(nd_range<Dims> Range, PropertiesT Properties,
[ 2368]                _KERNELFUNCPARAM(KernelFunc)) {
[ 2369]     throwIfGraphAssociatedAndKernelProperties<PropertiesT>();
[ 2370]     parallel_for_impl<KernelName>(Range, Properties, std::move(KernelFunc));
[ 2371]   }
[ 2372] 
[ 2373]   /// Reductions @{
[ 2374] 
[ 2375]   template <typename KernelName = detail::auto_name, typename PropertiesT,
[ 2376]             typename... RestT>
[ 2377]   std::enable_if_t<
[ 2378]       (sizeof...(RestT) > 1) &&
[ 2379]       detail::AreAllButLastReductions<RestT...>::value &&
[ 2380]       ext::oneapi::experimental::is_property_list<PropertiesT>::value>
[ 2381]   parallel_for(range<1> Range, PropertiesT Properties, RestT &&...Rest) {
[ 2382]     throwIfGraphAssociated<ext::oneapi::experimental::detail::
[ 2383]                                UnsupportedGraphFeatures::sycl_reductions>();
[ 2384]     throwIfGraphAssociatedAndKernelProperties<PropertiesT>();
[ 2385]     detail::reduction_parallel_for<KernelName>(*this, Range, Properties,
[ 2386]                                                std::forward<RestT>(Rest)...);
[ 2387]   }
[ 2388] 
[ 2389]   template <typename KernelName = detail::auto_name, typename PropertiesT,
[ 2390]             typename... RestT>
[ 2391]   std::enable_if_t<
[ 2392]       (sizeof...(RestT) > 1) &&
[ 2393]       detail::AreAllButLastReductions<RestT...>::value &&
[ 2394]       ext::oneapi::experimental::is_property_list<PropertiesT>::value>
[ 2395]   parallel_for(range<2> Range, PropertiesT Properties, RestT &&...Rest) {
[ 2396]     throwIfGraphAssociated<ext::oneapi::experimental::detail::
[ 2397]                                UnsupportedGraphFeatures::sycl_reductions>();
[ 2398]     throwIfGraphAssociatedAndKernelProperties<PropertiesT>();
[ 2399]     detail::reduction_parallel_for<KernelName>(*this, Range, Properties,
[ 2400]                                                std::forward<RestT>(Rest)...);
[ 2401]   }
[ 2402] 
[ 2403]   template <typename KernelName = detail::auto_name, typename PropertiesT,
[ 2404]             typename... RestT>
[ 2405]   std::enable_if_t<
[ 2406]       (sizeof...(RestT) > 1) &&
[ 2407]       detail::AreAllButLastReductions<RestT...>::value &&
[ 2408]       ext::oneapi::experimental::is_property_list<PropertiesT>::value>
[ 2409]   parallel_for(range<3> Range, PropertiesT Properties, RestT &&...Rest) {
[ 2410]     throwIfGraphAssociated<ext::oneapi::experimental::detail::
[ 2411]                                UnsupportedGraphFeatures::sycl_reductions>();
[ 2412]     throwIfGraphAssociatedAndKernelProperties<PropertiesT>();
[ 2413]     detail::reduction_parallel_for<KernelName>(*this, Range, Properties,
[ 2414]                                                std::forward<RestT>(Rest)...);
[ 2415]   }
[ 2416] 
[ 2417]   template <typename KernelName = detail::auto_name, typename... RestT>
[ 2418]   std::enable_if_t<detail::AreAllButLastReductions<RestT...>::value>
[ 2419]   parallel_for(range<1> Range, RestT &&...Rest) {
[ 2420]     parallel_for<KernelName>(Range,
[ 2421]                              ext::oneapi::experimental::empty_properties_t{},
[ 2422]                              std::forward<RestT>(Rest)...);
[ 2423]   }
[ 2424] 
[ 2425]   template <typename KernelName = detail::auto_name, typename... RestT>
[ 2426]   std::enable_if_t<detail::AreAllButLastReductions<RestT...>::value>
[ 2427]   parallel_for(range<2> Range, RestT &&...Rest) {
[ 2428]     parallel_for<KernelName>(Range,
[ 2429]                              ext::oneapi::experimental::empty_properties_t{},
[ 2430]                              std::forward<RestT>(Rest)...);
[ 2431]   }
[ 2432] 
[ 2433]   template <typename KernelName = detail::auto_name, typename... RestT>
[ 2434]   std::enable_if_t<detail::AreAllButLastReductions<RestT...>::value>
[ 2435]   parallel_for(range<3> Range, RestT &&...Rest) {
[ 2436]     parallel_for<KernelName>(Range,
[ 2437]                              ext::oneapi::experimental::empty_properties_t{},
[ 2438]                              std::forward<RestT>(Rest)...);
[ 2439]   }
[ 2440] 
[ 2441]   template <typename KernelName = detail::auto_name, int Dims,
[ 2442]             typename PropertiesT, typename... RestT>
[ 2443]   std::enable_if_t<
[ 2444]       (sizeof...(RestT) > 1) &&
[ 2445]       detail::AreAllButLastReductions<RestT...>::value &&
[ 2446]       ext::oneapi::experimental::is_property_list<PropertiesT>::value>
[ 2447]   parallel_for(nd_range<Dims> Range, PropertiesT Properties, RestT &&...Rest) {
[ 2448]     throwIfGraphAssociated<ext::oneapi::experimental::detail::
[ 2449]                                UnsupportedGraphFeatures::sycl_reductions>();
[ 2450]     detail::reduction_parallel_for<KernelName>(*this, Range, Properties,
[ 2451]                                                std::forward<RestT>(Rest)...);
[ 2452]   }
[ 2453] 
[ 2454]   template <typename KernelName = detail::auto_name, int Dims,
[ 2455]             typename... RestT>
[ 2456]   std::enable_if_t<detail::AreAllButLastReductions<RestT...>::value>
[ 2457]   parallel_for(nd_range<Dims> Range, RestT &&...Rest) {
[ 2458]     parallel_for<KernelName>(Range,
[ 2459]                              ext::oneapi::experimental::empty_properties_t{},
[ 2460]                              std::forward<RestT>(Rest)...);
[ 2461]   }
[ 2462] 
[ 2463]   /// }@
[ 2464] 
[ 2465]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2466]             int Dims, typename PropertiesT>
[ 2467]   void parallel_for_work_group(range<Dims> NumWorkGroups, PropertiesT Props,
[ 2468]                                _KERNELFUNCPARAM(KernelFunc)) {
[ 2469]     throwIfGraphAssociatedAndKernelProperties<PropertiesT>();
[ 2470]     parallel_for_work_group_lambda_impl<KernelName, KernelType, Dims,
[ 2471]                                         PropertiesT>(NumWorkGroups, Props,
[ 2472]                                                      KernelFunc);
[ 2473]   }
[ 2474] 
[ 2475]   template <typename KernelName = detail::auto_name, typename KernelType,
[ 2476]             int Dims, typename PropertiesT>
[ 2477]   void parallel_for_work_group(range<Dims> NumWorkGroups,
[ 2478]                                range<Dims> WorkGroupSize, PropertiesT Props,
[ 2479]                                _KERNELFUNCPARAM(KernelFunc)) {
[ 2480]     throwIfGraphAssociatedAndKernelProperties<PropertiesT>();
[ 2481]     parallel_for_work_group_lambda_impl<KernelName, KernelType, Dims,
[ 2482]                                         PropertiesT>(
[ 2483]         NumWorkGroups, WorkGroupSize, Props, KernelFunc);
[ 2484]   }
[ 2485] 
[ 2486]   // Clean up KERNELFUNC macro.
[ 2487] #undef _KERNELFUNCPARAM
[ 2488] 
[ 2489]   // Explicit copy operations API
[ 2490] 
[ 2491]   /// Copies the content of memory object accessed by Src into the memory
[ 2492]   /// pointed by Dst.
[ 2493]   ///
[ 2494]   /// Source must have at least as many bytes as the range accessed by Dst.
[ 2495]   ///
[ 2496]   /// \param Src is a source SYCL accessor.
[ 2497]   /// \param Dst is a smart pointer to destination memory.
[ 2498]   template <typename T_Src, typename T_Dst, int Dims, access::mode AccessMode,
[ 2499]             access::target AccessTarget,
[ 2500]             access::placeholder IsPlaceholder = access::placeholder::false_t>
[ 2501]   void copy(accessor<T_Src, Dims, AccessMode, AccessTarget, IsPlaceholder> Src,
[ 2502]             std::shared_ptr<T_Dst> Dst) {
[ 2503]     if (Src.is_placeholder())
[ 2504]       checkIfPlaceholderIsBoundToHandler(Src);
[ 2505] 
[ 2506]     throwIfActionIsCreated();
[ 2507]     static_assert(isValidTargetForExplicitOp(AccessTarget),
[ 2508]                   "Invalid accessor target for the copy method.");
[ 2509]     static_assert(isValidModeForSourceAccessor(AccessMode),
[ 2510]                   "Invalid accessor mode for the copy method.");
[ 2511]     // Make sure data shared_ptr points to is not released until we finish
[ 2512]     // work with it.
[ 2513]     CGData.MSharedPtrStorage.push_back(Dst);
[ 2514]     typename std::shared_ptr<T_Dst>::element_type *RawDstPtr = Dst.get();
[ 2515]     copy(Src, RawDstPtr);
[ 2516]   }
[ 2517] 
[ 2518]   /// Copies the content of memory pointed by Src into the memory object
[ 2519]   /// accessed by Dst.
[ 2520]   ///
[ 2521]   /// Source must have at least as many bytes as the range accessed by Dst.
[ 2522]   ///
[ 2523]   /// \param Src is a smart pointer to source memory.
[ 2524]   /// \param Dst is a destination SYCL accessor.
[ 2525]   template <typename T_Src, typename T_Dst, int Dims, access::mode AccessMode,
[ 2526]             access::target AccessTarget,
[ 2527]             access::placeholder IsPlaceholder = access::placeholder::false_t>
[ 2528]   void
[ 2529]   copy(std::shared_ptr<T_Src> Src,
[ 2530]        accessor<T_Dst, Dims, AccessMode, AccessTarget, IsPlaceholder> Dst) {
[ 2531]     if (Dst.is_placeholder())
[ 2532]       checkIfPlaceholderIsBoundToHandler(Dst);
[ 2533] 
[ 2534]     throwIfActionIsCreated();
[ 2535]     static_assert(isValidTargetForExplicitOp(AccessTarget),
[ 2536]                   "Invalid accessor target for the copy method.");
[ 2537]     static_assert(isValidModeForDestinationAccessor(AccessMode),
[ 2538]                   "Invalid accessor mode for the copy method.");
[ 2539]     // TODO: Add static_assert with is_device_copyable when vec is
[ 2540]     // device-copyable.
[ 2541]     // Make sure data shared_ptr points to is not released until we finish
[ 2542]     // work with it.
[ 2543]     CGData.MSharedPtrStorage.push_back(Src);
[ 2544]     typename std::shared_ptr<T_Src>::element_type *RawSrcPtr = Src.get();
[ 2545]     copy(RawSrcPtr, Dst);
[ 2546]   }
[ 2547] 
[ 2548]   /// Copies the content of memory object accessed by Src into the memory
[ 2549]   /// pointed by Dst.
[ 2550]   ///
[ 2551]   /// Source must have at least as many bytes as the range accessed by Dst.
[ 2552]   ///
[ 2553]   /// \param Src is a source SYCL accessor.
[ 2554]   /// \param Dst is a pointer to destination memory.
[ 2555]   template <typename T_Src, typename T_Dst, int Dims, access::mode AccessMode,
[ 2556]             access::target AccessTarget,
[ 2557]             access::placeholder IsPlaceholder = access::placeholder::false_t>
[ 2558]   void copy(accessor<T_Src, Dims, AccessMode, AccessTarget, IsPlaceholder> Src,
[ 2559]             T_Dst *Dst) {
[ 2560]     if (Src.is_placeholder())
[ 2561]       checkIfPlaceholderIsBoundToHandler(Src);
[ 2562] 
[ 2563]     throwIfActionIsCreated();
[ 2564]     static_assert(isValidTargetForExplicitOp(AccessTarget),
[ 2565]                   "Invalid accessor target for the copy method.");
[ 2566]     static_assert(isValidModeForSourceAccessor(AccessMode),
[ 2567]                   "Invalid accessor mode for the copy method.");
[ 2568] #ifndef __SYCL_DEVICE_ONLY__
[ 2569]     if (MIsHost) {
[ 2570]       // TODO: Temporary implementation for host. Should be handled by memory
[ 2571]       // manager.
[ 2572]       copyAccToPtrHost(Src, Dst);
[ 2573]       return;
[ 2574]     }
[ 2575] #endif
[ 2576]     setType(detail::CG::CopyAccToPtr);
[ 2577] 
[ 2578]     detail::AccessorBaseHost *AccBase = (detail::AccessorBaseHost *)&Src;
[ 2579]     detail::AccessorImplPtr AccImpl = detail::getSyclObjImpl(*AccBase);
[ 2580] 
[ 2581]     CGData.MRequirements.push_back(AccImpl.get());
[ 2582]     MSrcPtr = static_cast<void *>(AccImpl.get());
[ 2583]     MDstPtr = static_cast<void *>(Dst);
[ 2584]     // Store copy of accessor to the local storage to make sure it is alive
[ 2585]     // until we finish
[ 2586]     CGData.MAccStorage.push_back(std::move(AccImpl));
[ 2587]   }
[ 2588] 
[ 2589]   /// Copies the content of memory pointed by Src into the memory object
[ 2590]   /// accessed by Dst.
[ 2591]   ///
[ 2592]   /// Source must have at least as many bytes as the range accessed by Dst.
[ 2593]   ///
[ 2594]   /// \param Src is a pointer to source memory.
[ 2595]   /// \param Dst is a destination SYCL accessor.
[ 2596]   template <typename T_Src, typename T_Dst, int Dims, access::mode AccessMode,
[ 2597]             access::target AccessTarget,
[ 2598]             access::placeholder IsPlaceholder = access::placeholder::false_t>
[ 2599]   void
[ 2600]   copy(const T_Src *Src,
[ 2601]        accessor<T_Dst, Dims, AccessMode, AccessTarget, IsPlaceholder> Dst) {
[ 2602]     if (Dst.is_placeholder())
[ 2603]       checkIfPlaceholderIsBoundToHandler(Dst);
[ 2604] 
[ 2605]     throwIfActionIsCreated();
[ 2606]     static_assert(isValidTargetForExplicitOp(AccessTarget),
[ 2607]                   "Invalid accessor target for the copy method.");
[ 2608]     static_assert(isValidModeForDestinationAccessor(AccessMode),
[ 2609]                   "Invalid accessor mode for the copy method.");
[ 2610]     // TODO: Add static_assert with is_device_copyable when vec is
[ 2611]     // device-copyable.
[ 2612] #ifndef __SYCL_DEVICE_ONLY__
[ 2613]     if (MIsHost) {
[ 2614]       // TODO: Temporary implementation for host. Should be handled by memory
[ 2615]       // manager.
[ 2616]       copyPtrToAccHost(Src, Dst);
[ 2617]       return;
[ 2618]     }
[ 2619] #endif
[ 2620]     setType(detail::CG::CopyPtrToAcc);
[ 2621] 
[ 2622]     detail::AccessorBaseHost *AccBase = (detail::AccessorBaseHost *)&Dst;
[ 2623]     detail::AccessorImplPtr AccImpl = detail::getSyclObjImpl(*AccBase);
[ 2624] 
[ 2625]     CGData.MRequirements.push_back(AccImpl.get());
[ 2626]     MSrcPtr = const_cast<T_Src *>(Src);
[ 2627]     MDstPtr = static_cast<void *>(AccImpl.get());
[ 2628]     // Store copy of accessor to the local storage to make sure it is alive
[ 2629]     // until we finish
[ 2630]     CGData.MAccStorage.push_back(std::move(AccImpl));
[ 2631]   }
[ 2632] 
[ 2633]   /// Copies the content of memory object accessed by Src to the memory
[ 2634]   /// object accessed by Dst.
[ 2635]   ///
[ 2636]   /// Dst must have at least as many bytes as the range accessed by Src.
[ 2637]   ///
[ 2638]   /// \param Src is a source SYCL accessor.
[ 2639]   /// \param Dst is a destination SYCL accessor.
[ 2640]   template <
[ 2641]       typename T_Src, int Dims_Src, access::mode AccessMode_Src,
[ 2642]       access::target AccessTarget_Src, typename T_Dst, int Dims_Dst,
[ 2643]       access::mode AccessMode_Dst, access::target AccessTarget_Dst,
[ 2644]       access::placeholder IsPlaceholder_Src = access::placeholder::false_t,
[ 2645]       access::placeholder IsPlaceholder_Dst = access::placeholder::false_t>
[ 2646]   void copy(accessor<T_Src, Dims_Src, AccessMode_Src, AccessTarget_Src,
[ 2647]                      IsPlaceholder_Src>
[ 2648]                 Src,
[ 2649]             accessor<T_Dst, Dims_Dst, AccessMode_Dst, AccessTarget_Dst,
[ 2650]                      IsPlaceholder_Dst>
[ 2651]                 Dst) {
[ 2652]     if (Src.is_placeholder())
[ 2653]       checkIfPlaceholderIsBoundToHandler(Src);
[ 2654]     if (Dst.is_placeholder())
[ 2655]       checkIfPlaceholderIsBoundToHandler(Dst);
[ 2656] 
[ 2657]     throwIfActionIsCreated();
[ 2658]     static_assert(isValidTargetForExplicitOp(AccessTarget_Src),
[ 2659]                   "Invalid source accessor target for the copy method.");
[ 2660]     static_assert(isValidTargetForExplicitOp(AccessTarget_Dst),
[ 2661]                   "Invalid destination accessor target for the copy method.");
[ 2662]     static_assert(isValidModeForSourceAccessor(AccessMode_Src),
[ 2663]                   "Invalid source accessor mode for the copy method.");
[ 2664]     static_assert(isValidModeForDestinationAccessor(AccessMode_Dst),
[ 2665]                   "Invalid destination accessor mode for the copy method.");
[ 2666]     if (Dst.get_size() < Src.get_size())
[ 2667]       throw sycl::invalid_object_error(
[ 2668]           "The destination accessor size is too small to copy the memory into.",
[ 2669]           PI_ERROR_INVALID_OPERATION);
[ 2670] 
[ 2671]     if (copyAccToAccHelper(Src, Dst))
[ 2672]       return;
[ 2673]     setType(detail::CG::CopyAccToAcc);
[ 2674] 
[ 2675]     detail::AccessorBaseHost *AccBaseSrc = (detail::AccessorBaseHost *)&Src;
[ 2676]     detail::AccessorImplPtr AccImplSrc = detail::getSyclObjImpl(*AccBaseSrc);
[ 2677] 
[ 2678]     detail::AccessorBaseHost *AccBaseDst = (detail::AccessorBaseHost *)&Dst;
[ 2679]     detail::AccessorImplPtr AccImplDst = detail::getSyclObjImpl(*AccBaseDst);
[ 2680] 
[ 2681]     CGData.MRequirements.push_back(AccImplSrc.get());
[ 2682]     CGData.MRequirements.push_back(AccImplDst.get());
[ 2683]     MSrcPtr = AccImplSrc.get();
[ 2684]     MDstPtr = AccImplDst.get();
[ 2685]     // Store copy of accessor to the local storage to make sure it is alive
[ 2686]     // until we finish
[ 2687]     CGData.MAccStorage.push_back(std::move(AccImplSrc));
[ 2688]     CGData.MAccStorage.push_back(std::move(AccImplDst));
[ 2689]   }
[ 2690] 
[ 2691]   /// Provides guarantees that the memory object accessed via Acc is updated
[ 2692]   /// on the host after command group object execution is complete.
[ 2693]   ///
[ 2694]   /// \param Acc is a SYCL accessor that needs to be updated on host.
[ 2695]   template <typename T, int Dims, access::mode AccessMode,
[ 2696]             access::target AccessTarget,
[ 2697]             access::placeholder IsPlaceholder = access::placeholder::false_t>
[ 2698]   void
[ 2699]   update_host(accessor<T, Dims, AccessMode, AccessTarget, IsPlaceholder> Acc) {
[ 2700]     if (Acc.is_placeholder())
[ 2701]       checkIfPlaceholderIsBoundToHandler(Acc);
[ 2702] 
[ 2703]     throwIfActionIsCreated();
[ 2704]     static_assert(isValidTargetForExplicitOp(AccessTarget),
[ 2705]                   "Invalid accessor target for the update_host method.");
[ 2706]     setType(detail::CG::UpdateHost);
[ 2707] 
[ 2708]     detail::AccessorBaseHost *AccBase = (detail::AccessorBaseHost *)&Acc;
[ 2709]     detail::AccessorImplPtr AccImpl = detail::getSyclObjImpl(*AccBase);
[ 2710] 
[ 2711]     MDstPtr = static_cast<void *>(AccImpl.get());
[ 2712]     CGData.MRequirements.push_back(AccImpl.get());
[ 2713]     CGData.MAccStorage.push_back(std::move(AccImpl));
[ 2714]   }
[ 2715] 
[ 2716] public:
[ 2717]   /// Fills memory pointed by accessor with the pattern given.
[ 2718]   ///
[ 2719]   /// If the operation is submitted to queue associated with OpenCL device and
[ 2720]   /// accessor points to one dimensional memory object then use special type for
[ 2721]   /// filling. Otherwise fill using regular kernel.
[ 2722]   ///
[ 2723]   /// \param Dst is a destination SYCL accessor.
[ 2724]   /// \param Pattern is a value to be used to fill the memory.
[ 2725]   template <typename T, int Dims, access::mode AccessMode,
[ 2726]             access::target AccessTarget,
[ 2727]             access::placeholder IsPlaceholder = access::placeholder::false_t,
[ 2728]             typename PropertyListT = property_list>
[ 2729]   void
[ 2730]   fill(accessor<T, Dims, AccessMode, AccessTarget, IsPlaceholder, PropertyListT>
[ 2731]            Dst,
[ 2732]        const T &Pattern) {
[ 2733]     assert(!MIsHost && "fill() should no longer be callable on a host device.");
[ 2734] 
[ 2735]     if (Dst.is_placeholder())
[ 2736]       checkIfPlaceholderIsBoundToHandler(Dst);
[ 2737] 
[ 2738]     throwIfActionIsCreated();
[ 2739]     // TODO add check:T must be an integral scalar value or a SYCL vector type
[ 2740]     static_assert(isValidTargetForExplicitOp(AccessTarget),
[ 2741]                   "Invalid accessor target for the fill method.");
[ 2742]     // CG::Fill will result in piEnqueuFillBuffer/Image which requires that mem
[ 2743]     // data is contiguous. Thus we check range and offset when dim > 1
[ 2744]     // Images don't allow ranged accessors and are fine.
[ 2745]     if constexpr (isBackendSupportedFillSize(sizeof(T)) &&
[ 2746]                   ((Dims <= 1) || isImageOrImageArray(AccessTarget))) {
[ 2747]       StageFillCG(Dst, Pattern);
[ 2748]     } else if constexpr (Dims == 0) {
[ 2749]       // Special case for zero-dim accessors.
[ 2750]       parallel_for<__fill<T, Dims, AccessMode, AccessTarget, IsPlaceholder>>(
[ 2751]           range<1>(1), [=](id<1>) { Dst = Pattern; });
[ 2752]     } else {
[ 2753]       // Dim > 1
[ 2754]       bool OffsetUsable = (Dst.get_offset() == sycl::id<Dims>{});
[ 2755]       detail::AccessorBaseHost *AccBase = (detail::AccessorBaseHost *)&Dst;
[ 2756]       bool RangesUsable =
[ 2757]           (AccBase->getAccessRange() == AccBase->getMemoryRange());
[ 2758]       if (OffsetUsable && RangesUsable &&
[ 2759]           isBackendSupportedFillSize(sizeof(T))) {
[ 2760]         StageFillCG(Dst, Pattern);
[ 2761]       } else {
[ 2762]         range<Dims> Range = Dst.get_range();
[ 2763]         parallel_for<__fill<T, Dims, AccessMode, AccessTarget, IsPlaceholder>>(
[ 2764]             Range, [=](id<Dims> Index) { Dst[Index] = Pattern; });
[ 2765]       }
[ 2766]     }
[ 2767]   }
[ 2768] 
[ 2769]   /// Fills the specified memory with the specified pattern.
[ 2770]   ///
[ 2771]   /// \param Ptr is the pointer to the memory to fill
[ 2772]   /// \param Pattern is the pattern to fill into the memory.  T should be
[ 2773]   /// device copyable.
[ 2774]   /// \param Count is the number of times to fill Pattern into Ptr.
[ 2775]   template <typename T> void fill(void *Ptr, const T &Pattern, size_t Count) {
[ 2776]     throwIfActionIsCreated();
[ 2777]     static_assert(is_device_copyable<T>::value,
[ 2778]                   "Pattern must be device copyable");
[ 2779]     parallel_for<__usmfill<T>>(range<1>(Count), [=](id<1> Index) {
[ 2780]       T *CastedPtr = static_cast<T *>(Ptr);
[ 2781]       CastedPtr[Index] = Pattern;
[ 2782]     });
[ 2783]   }
[ 2784] 
[ 2785]   /// Prevents any commands submitted afterward to this queue from executing
[ 2786]   /// until all commands previously submitted to this queue have entered the
[ 2787]   /// complete state.
[ 2788]   void ext_oneapi_barrier() {
[ 2789]     throwIfActionIsCreated();
[ 2790]     setType(detail::CG::Barrier);
[ 2791]   }
[ 2792] 
[ 2793]   /// Prevents any commands submitted afterward to this queue from executing
[ 2794]   /// until all events in WaitList have entered the complete state. If WaitList
[ 2795]   /// is empty, then the barrier has no effect.
[ 2796]   ///
[ 2797]   /// \param WaitList is a vector of valid SYCL events that need to complete
[ 2798]   /// before barrier command can be executed.
[ 2799]   void ext_oneapi_barrier(const std::vector<event> &WaitList);
[ 2800] 
[ 2801]   /// Copies data from one memory region to another, each is either a host
[ 2802]   /// pointer or a pointer within USM allocation accessible on this handler's
[ 2803]   /// device.
[ 2804]   /// No operations is done if \p Count is zero. An exception is thrown if
[ 2805]   /// either \p Dest or \p Src is nullptr. The behavior is undefined if any of
[ 2806]   /// the pointer parameters is invalid.
[ 2807]   ///
[ 2808]   /// \param Dest is a USM pointer to the destination memory.
[ 2809]   /// \param Src is a USM pointer to the source memory.
[ 2810]   /// \param Count is a number of bytes to copy.
[ 2811]   void memcpy(void *Dest, const void *Src, size_t Count);
[ 2812] 
[ 2813]   /// Copies data from one memory region to another, each is either a host
[ 2814]   /// pointer or a pointer within USM allocation accessible on this handler's
[ 2815]   /// device.
[ 2816]   /// No operations is done if \p Count is zero. An exception is thrown if
[ 2817]   /// either \p Dest or \p Src is nullptr. The behavior is undefined if any of
[ 2818]   /// the pointer parameters is invalid.
[ 2819]   ///
[ 2820]   /// \param Src is a USM pointer to the source memory.
[ 2821]   /// \param Dest is a USM pointer to the destination memory.
[ 2822]   /// \param Count is a number of elements of type T to copy.
[ 2823]   template <typename T> void copy(const T *Src, T *Dest, size_t Count) {
[ 2824]     this->memcpy(Dest, Src, Count * sizeof(T));
[ 2825]   }
[ 2826] 
[ 2827]   /// Fills the memory pointed by a USM pointer with the value specified.
[ 2828]   /// No operations is done if \p Count is zero. An exception is thrown if \p
[ 2829]   /// Dest is nullptr. The behavior is undefined if \p Dest is invalid.
[ 2830]   ///
[ 2831]   /// \param Dest is a USM pointer to the memory to fill.
[ 2832]   /// \param Value is a value to be set. Value is cast as an unsigned char.
[ 2833]   /// \param Count is a number of bytes to fill.
[ 2834]   void memset(void *Dest, int Value, size_t Count);
[ 2835] 
[ 2836]   /// Provides hints to the runtime library that data should be made available
[ 2837]   /// on a device earlier than Unified Shared Memory would normally require it
[ 2838]   /// to be available.
[ 2839]   ///
[ 2840]   /// \param Ptr is a USM pointer to the memory to be prefetched to the device.
[ 2841]   /// \param Count is a number of bytes to be prefetched.
[ 2842]   void prefetch(const void *Ptr, size_t Count);
[ 2843] 
[ 2844]   /// Provides additional information to the underlying runtime about how
[ 2845]   /// different allocations are used.
[ 2846]   ///
[ 2847]   /// \param Ptr is a USM pointer to the allocation.
[ 2848]   /// \param Length is a number of bytes in the allocation.
[ 2849]   /// \param Advice is a device-defined advice for the specified allocation.
[ 2850]   void mem_advise(const void *Ptr, size_t Length, int Advice);
[ 2851] 
[ 2852]   /// Copies data from one 2D memory region to another, both pointed by
[ 2853]   /// USM pointers.
[ 2854]   /// No operations is done if \p Width or \p Height is zero. An exception is
[ 2855]   /// thrown if either \p Dest or \p Src is nullptr or if \p Width is strictly
[ 2856]   /// greater than either \p DestPitch or \p SrcPitch. The behavior is undefined
[ 2857]   /// if any of the pointer parameters is invalid.
[ 2858]   ///
[ 2859]   /// NOTE: Function is dependent to prevent the fallback kernels from
[ 2860]   /// materializing without the use of the function.
[ 2861]   ///
[ 2862]   /// \param Dest is a USM pointer to the destination memory.
[ 2863]   /// \param DestPitch is the pitch of the rows in \p Dest.
[ 2864]   /// \param Src is a USM pointer to the source memory.
[ 2865]   /// \param SrcPitch is the pitch of the rows in \p Src.
[ 2866]   /// \param Width is the width in bytes of the 2D region to copy.
[ 2867]   /// \param Height is the height in number of row of the 2D region to copy.
[ 2868]   template <typename T = unsigned char,
[ 2869]             typename = std::enable_if_t<std::is_same_v<T, unsigned char>>>
[ 2870]   void ext_oneapi_memcpy2d(void *Dest, size_t DestPitch, const void *Src,
[ 2871]                            size_t SrcPitch, size_t Width, size_t Height) {
[ 2872]     throwIfGraphAssociated<
[ 2873]         ext::oneapi::experimental::detail::UnsupportedGraphFeatures::
[ 2874]             sycl_ext_oneapi_memcpy2d>();
[ 2875]     throwIfActionIsCreated();
[ 2876]     if (Width > DestPitch)
[ 2877]       throw sycl::exception(sycl::make_error_code(errc::invalid),
[ 2878]                             "Destination pitch must be greater than or equal "
[ 2879]                             "to the width specified in 'ext_oneapi_memcpy2d'");
[ 2880]     if (Width > SrcPitch)
[ 2881]       throw sycl::exception(sycl::make_error_code(errc::invalid),
[ 2882]                             "Source pitch must be greater than or equal "
[ 2883]                             "to the width specified in 'ext_oneapi_memcpy2d'");
[ 2884] 
[ 2885]     // Get the type of the pointers.
[ 2886]     context Ctx = detail::createSyclObjFromImpl<context>(getContextImplPtr());
[ 2887]     usm::alloc SrcAllocType = get_pointer_type(Src, Ctx);
[ 2888]     usm::alloc DestAllocType = get_pointer_type(Dest, Ctx);
[ 2889]     bool SrcIsHost =
[ 2890]         SrcAllocType == usm::alloc::unknown || SrcAllocType == usm::alloc::host;
[ 2891]     bool DestIsHost = DestAllocType == usm::alloc::unknown ||
[ 2892]                       DestAllocType == usm::alloc::host;
[ 2893] 
[ 2894]     // Do the following:
[ 2895]     // 1. If both are host, use host_task to copy.
[ 2896]     // 2. If either pointer is host or the backend supports native memcpy2d, use
[ 2897]     //    special command.
[ 2898]     // 3. Otherwise, launch a kernel for copying.
[ 2899]     if (SrcIsHost && DestIsHost) {
[ 2900]       commonUSMCopy2DFallbackHostTask<T>(Src, SrcPitch, Dest, DestPitch, Width,
[ 2901]                                          Height);
[ 2902]     } else if (SrcIsHost || DestIsHost || supportsUSMMemcpy2D()) {
[ 2903]       ext_oneapi_memcpy2d_impl(Dest, DestPitch, Src, SrcPitch, Width, Height);
[ 2904]     } else {
[ 2905]       commonUSMCopy2DFallbackKernel<T>(Src, SrcPitch, Dest, DestPitch, Width,
[ 2906]                                        Height);
[ 2907]     }
[ 2908]   }
[ 2909] 
[ 2910]   /// Copies data from one 2D memory region to another, both pointed by
[ 2911]   /// USM pointers.
[ 2912]   /// No operations is done if \p Width or \p Height is zero. An exception is
[ 2913]   /// thrown if either \p Dest or \p Src is nullptr or if \p Width is strictly
[ 2914]   /// greater than either \p DestPitch or \p SrcPitch. The behavior is undefined
[ 2915]   /// if any of the pointer parameters is invalid.
[ 2916]   ///
[ 2917]   /// \param Src is a USM pointer to the source memory.
[ 2918]   /// \param SrcPitch is the pitch of the rows in \p Src.
[ 2919]   /// \param Dest is a USM pointer to the destination memory.
[ 2920]   /// \param DestPitch is the pitch of the rows in \p Dest.
[ 2921]   /// \param Width is the width in number of elements of the 2D region to copy.
[ 2922]   /// \param Height is the height in number of rows of the 2D region to copy.
[ 2923]   template <typename T>
[ 2924]   void ext_oneapi_copy2d(const T *Src, size_t SrcPitch, T *Dest,
[ 2925]                          size_t DestPitch, size_t Width, size_t Height) {
[ 2926]     if (Width > DestPitch)
[ 2927]       throw sycl::exception(sycl::make_error_code(errc::invalid),
[ 2928]                             "Destination pitch must be greater than or equal "
[ 2929]                             "to the width specified in 'ext_oneapi_copy2d'");
[ 2930]     if (Width > SrcPitch)
[ 2931]       throw sycl::exception(sycl::make_error_code(errc::invalid),
[ 2932]                             "Source pitch must be greater than or equal "
[ 2933]                             "to the width specified in 'ext_oneapi_copy2d'");
[ 2934] 
[ 2935]     // Get the type of the pointers.
[ 2936]     context Ctx = detail::createSyclObjFromImpl<context>(getContextImplPtr());
[ 2937]     usm::alloc SrcAllocType = get_pointer_type(Src, Ctx);
[ 2938]     usm::alloc DestAllocType = get_pointer_type(Dest, Ctx);
[ 2939]     bool SrcIsHost =
[ 2940]         SrcAllocType == usm::alloc::unknown || SrcAllocType == usm::alloc::host;
[ 2941]     bool DestIsHost = DestAllocType == usm::alloc::unknown ||
[ 2942]                       DestAllocType == usm::alloc::host;
[ 2943] 
[ 2944]     // Do the following:
[ 2945]     // 1. If both are host, use host_task to copy.
[ 2946]     // 2. If either pointer is host or of the backend supports native memcpy2d,
[ 2947]     //    use special command.
[ 2948]     // 3. Otherwise, launch a kernel for copying.
[ 2949]     if (SrcIsHost && DestIsHost) {
[ 2950]       commonUSMCopy2DFallbackHostTask<T>(Src, SrcPitch, Dest, DestPitch, Width,
[ 2951]                                          Height);
[ 2952]     } else if (SrcIsHost || DestIsHost || supportsUSMMemcpy2D()) {
[ 2953]       ext_oneapi_memcpy2d_impl(Dest, DestPitch * sizeof(T), Src,
[ 2954]                                SrcPitch * sizeof(T), Width * sizeof(T), Height);
[ 2955]     } else {
[ 2956]       commonUSMCopy2DFallbackKernel<T>(Src, SrcPitch, Dest, DestPitch, Width,
[ 2957]                                        Height);
[ 2958]     }
[ 2959]   }
[ 2960] 
[ 2961]   /// Fills the memory pointed by a USM pointer with the value specified.
[ 2962]   /// No operations is done if \p Width or \p Height is zero. An exception is
[ 2963]   /// thrown if either \p Dest or \p Src is nullptr or if \p Width is strictly
[ 2964]   /// greater than \p DestPitch. The behavior is undefined if any of the pointer
[ 2965]   /// parameters is invalid.
[ 2966]   ///
[ 2967]   /// NOTE: Function is dependent to prevent the fallback kernels from
[ 2968]   /// materializing without the use of the function.
[ 2969]   ///
[ 2970]   /// \param Dest is a USM pointer to the destination memory.
[ 2971]   /// \param DestPitch is the pitch of the rows in \p Dest.
[ 2972]   /// \param Value is the value to fill into the region in \p Dest. Value is
[ 2973]   /// cast as an unsigned char.
[ 2974]   /// \param Width is the width in number of elements of the 2D region to fill.
[ 2975]   /// \param Height is the height in number of rows of the 2D region to fill.
[ 2976]   template <typename T = unsigned char,
[ 2977]             typename = std::enable_if_t<std::is_same_v<T, unsigned char>>>
[ 2978]   void ext_oneapi_memset2d(void *Dest, size_t DestPitch, int Value,
[ 2979]                            size_t Width, size_t Height) {
[ 2980]     throwIfActionIsCreated();
[ 2981]     if (Width > DestPitch)
[ 2982]       throw sycl::exception(sycl::make_error_code(errc::invalid),
[ 2983]                             "Destination pitch must be greater than or equal "
[ 2984]                             "to the width specified in 'ext_oneapi_memset2d'");
[ 2985]     T CharVal = static_cast<T>(Value);
[ 2986] 
[ 2987]     context Ctx = detail::createSyclObjFromImpl<context>(getContextImplPtr());
[ 2988]     usm::alloc DestAllocType = get_pointer_type(Dest, Ctx);
[ 2989] 
[ 2990]     // If the backends supports 2D fill we use that. Otherwise we use a fallback
[ 2991]     // kernel. If the target is on host we will always do the operation on host.
[ 2992]     if (DestAllocType == usm::alloc::unknown ||
[ 2993]         DestAllocType == usm::alloc::host)
[ 2994]       commonUSMFill2DFallbackHostTask(Dest, DestPitch, CharVal, Width, Height);
[ 2995]     else if (supportsUSMMemset2D())
[ 2996]       ext_oneapi_memset2d_impl(Dest, DestPitch, Value, Width, Height);
[ 2997]     else
[ 2998]       commonUSMFill2DFallbackKernel(Dest, DestPitch, CharVal, Width, Height);
[ 2999]   }
[ 3000] 
[ 3001]   /// Fills the memory pointed by a USM pointer with the value specified.
[ 3002]   /// No operations is done if \p Width or \p Height is zero. An exception is
[ 3003]   /// thrown if either \p Dest or \p Src is nullptr or if \p Width is strictly
[ 3004]   /// greater than \p DestPitch. The behavior is undefined if any of the pointer
[ 3005]   /// parameters is invalid.
[ 3006]   ///
[ 3007]   /// \param Dest is a USM pointer to the destination memory.
[ 3008]   /// \param DestPitch is the pitch of the rows in \p Dest.
[ 3009]   /// \param Pattern is the pattern to fill into the memory.  T should be
[ 3010]   /// device copyable.
[ 3011]   /// \param Width is the width in number of elements of the 2D region to fill.
[ 3012]   /// \param Height is the height in number of rows of the 2D region to fill.
[ 3013]   template <typename T>
[ 3014]   void ext_oneapi_fill2d(void *Dest, size_t DestPitch, const T &Pattern,
[ 3015]                          size_t Width, size_t Height) {
[ 3016]     throwIfActionIsCreated();
[ 3017]     static_assert(is_device_copyable<T>::value,
[ 3018]                   "Pattern must be device copyable");
[ 3019]     if (Width > DestPitch)
[ 3020]       throw sycl::exception(sycl::make_error_code(errc::invalid),
[ 3021]                             "Destination pitch must be greater than or equal "
[ 3022]                             "to the width specified in 'ext_oneapi_fill2d'");
[ 3023] 
[ 3024]     context Ctx = detail::createSyclObjFromImpl<context>(getContextImplPtr());
[ 3025]     usm::alloc DestAllocType = get_pointer_type(Dest, Ctx);
[ 3026] 
[ 3027]     // If the backends supports 2D fill we use that. Otherwise we use a fallback
[ 3028]     // kernel. If the target is on host we will always do the operation on host.
[ 3029]     if (DestAllocType == usm::alloc::unknown ||
[ 3030]         DestAllocType == usm::alloc::host)
[ 3031]       commonUSMFill2DFallbackHostTask(Dest, DestPitch, Pattern, Width, Height);
[ 3032]     else if (supportsUSMFill2D())
[ 3033]       ext_oneapi_fill2d_impl(Dest, DestPitch, &Pattern, sizeof(T), Width,
[ 3034]                              Height);
[ 3035]     else
[ 3036]       commonUSMFill2DFallbackKernel(Dest, DestPitch, Pattern, Width, Height);
[ 3037]   }
[ 3038] 
[ 3039]   /// Copies data from a USM memory region to a device_global.
[ 3040]   /// Throws an exception if the copy operation intends to write outside the
[ 3041]   /// memory range \p Dest, as specified through \p NumBytes and \p DestOffset.
[ 3042]   ///
[ 3043]   /// \param Dest is the destination device_glboal.
[ 3044]   /// \param Src is a USM pointer to the source memory.
[ 3045]   /// \param NumBytes is a number of bytes to copy.
[ 3046]   /// \param DestOffset is the offset into \p Dest to copy to.
[ 3047]   template <typename T, typename PropertyListT>
[ 3048]   void memcpy(ext::oneapi::experimental::device_global<T, PropertyListT> &Dest,
[ 3049]               const void *Src, size_t NumBytes = sizeof(T),
[ 3050]               size_t DestOffset = 0) {
[ 3051]     throwIfGraphAssociated<
[ 3052]         ext::oneapi::experimental::detail::UnsupportedGraphFeatures::
[ 3053]             sycl_ext_oneapi_device_global>();
[ 3054]     if (sizeof(T) < DestOffset + NumBytes)
[ 3055]       throw sycl::exception(make_error_code(errc::invalid),
[ 3056]                             "Copy to device_global is out of bounds.");
[ 3057] 
[ 3058]     constexpr bool IsDeviceImageScoped = PropertyListT::template has_property<
[ 3059]         ext::oneapi::experimental::device_image_scope_key>();
[ 3060] 
[ 3061]     if (!detail::isDeviceGlobalUsedInKernel(&Dest)) {
[ 3062]       // If the corresponding device_global isn't used in any kernels, we fall
[ 3063]       // back to doing the memory operation on host-only.
[ 3064]       memcpyToHostOnlyDeviceGlobal(&Dest, Src, sizeof(T), IsDeviceImageScoped,
[ 3065]                                    NumBytes, DestOffset);
[ 3066]       return;
[ 3067]     }
[ 3068] 
[ 3069]     memcpyToDeviceGlobal(&Dest, Src, IsDeviceImageScoped, NumBytes, DestOffset);
[ 3070]   }
[ 3071] 
[ 3072]   /// Copies data from a device_global to USM memory.
[ 3073]   /// Throws an exception if the copy operation intends to read outside the
[ 3074]   /// memory range \p Src, as specified through \p NumBytes and \p SrcOffset.
[ 3075]   ///
[ 3076]   /// \param Dest is a USM pointer to copy to.
[ 3077]   /// \param Src is the source device_global.
[ 3078]   /// \param NumBytes is a number of bytes to copy.
[ 3079]   /// \param SrcOffset is the offset into \p Src to copy from.
[ 3080]   template <typename T, typename PropertyListT>
[ 3081]   void
[ 3082]   memcpy(void *Dest,
[ 3083]          const ext::oneapi::experimental::device_global<T, PropertyListT> &Src,
[ 3084]          size_t NumBytes = sizeof(T), size_t SrcOffset = 0) {
[ 3085]     throwIfGraphAssociated<
[ 3086]         ext::oneapi::experimental::detail::UnsupportedGraphFeatures::
[ 3087]             sycl_ext_oneapi_device_global>();
[ 3088]     if (sizeof(T) < SrcOffset + NumBytes)
[ 3089]       throw sycl::exception(make_error_code(errc::invalid),
[ 3090]                             "Copy from device_global is out of bounds.");
[ 3091] 
[ 3092]     constexpr bool IsDeviceImageScoped = PropertyListT::template has_property<
[ 3093]         ext::oneapi::experimental::device_image_scope_key>();
[ 3094] 
[ 3095]     if (!detail::isDeviceGlobalUsedInKernel(&Src)) {
[ 3096]       // If the corresponding device_global isn't used in any kernels, we fall
[ 3097]       // back to doing the memory operation on host-only.
[ 3098]       memcpyFromHostOnlyDeviceGlobal(Dest, &Src, IsDeviceImageScoped, NumBytes,
[ 3099]                                      SrcOffset);
[ 3100]       return;
[ 3101]     }
[ 3102] 
[ 3103]     memcpyFromDeviceGlobal(Dest, &Src, IsDeviceImageScoped, NumBytes,
[ 3104]                            SrcOffset);
[ 3105]   }
[ 3106] 
[ 3107]   /// Copies elements of type `std::remove_all_extents_t<T>` from a USM memory
[ 3108]   /// region to a device_global.
[ 3109]   /// Throws an exception if the copy operation intends to write outside the
[ 3110]   /// memory range \p Dest, as specified through \p Count and \p StartIndex.
[ 3111]   ///
[ 3112]   /// \param Src is a USM pointer to the source memory.
[ 3113]   /// \param Dest is the destination device_glboal.
[ 3114]   /// \param Count is a number of elements to copy.
[ 3115]   /// \param StartIndex is the index of the first element in \p Dest to copy to.
[ 3116]   template <typename T, typename PropertyListT>
[ 3117]   void copy(const std::remove_all_extents_t<T> *Src,
[ 3118]             ext::oneapi::experimental::device_global<T, PropertyListT> &Dest,
[ 3119]             size_t Count = sizeof(T) / sizeof(std::remove_all_extents_t<T>),
[ 3120]             size_t StartIndex = 0) {
[ 3121]     this->memcpy(Dest, Src, Count * sizeof(std::remove_all_extents_t<T>),
[ 3122]                  StartIndex * sizeof(std::remove_all_extents_t<T>));
[ 3123]   }
[ 3124] 
[ 3125]   /// Copies elements of type `std::remove_all_extents_t<T>` from a
[ 3126]   /// device_global to a USM memory region.
[ 3127]   /// Throws an exception if the copy operation intends to write outside the
[ 3128]   /// memory range \p Src, as specified through \p Count and \p StartIndex.
[ 3129]   ///
[ 3130]   /// \param Src is the source device_global.
[ 3131]   /// \param Dest is a USM pointer to copy to.
[ 3132]   /// \param Count is a number of elements to copy.
[ 3133]   /// \param StartIndex is the index of the first element in \p Src to copy
[ 3134]   ///        from.
[ 3135]   template <typename T, typename PropertyListT>
[ 3136]   void
[ 3137]   copy(const ext::oneapi::experimental::device_global<T, PropertyListT> &Src,
[ 3138]        std::remove_all_extents_t<T> *Dest,
[ 3139]        size_t Count = sizeof(T) / sizeof(std::remove_all_extents_t<T>),
[ 3140]        size_t StartIndex = 0) {
[ 3141]     this->memcpy(Dest, Src, Count * sizeof(std::remove_all_extents_t<T>),
[ 3142]                  StartIndex * sizeof(std::remove_all_extents_t<T>));
[ 3143]   }
[ 3144]   /// Executes a command_graph.
[ 3145]   ///
[ 3146]   /// \param Graph Executable command_graph to run
[ 3147]   void ext_oneapi_graph(ext::oneapi::experimental::command_graph<
[ 3148]                         ext::oneapi::experimental::graph_state::executable>
[ 3149]                             Graph);
[ 3150] 
[ 3151]   /// Copies data from one memory region to another, where \p Src is a USM
[ 3152]   /// pointer and \p Dest is an opaque image memory handle. An exception is
[ 3153]   /// thrown if either \p Src is nullptr or \p Dest is incomplete. The behavior
[ 3154]   /// is undefined if \p Desc is inconsistent with the allocated memory region.
[ 3155]   ///
[ 3156]   /// \param Src is a USM pointer to the source memory.
[ 3157]   /// \param Dest is an opaque image memory handle to the destination memory.
[ 3158]   /// \param DestImgDesc is the image descriptor
[ 3159]   void ext_oneapi_copy(
[ 3160]       void *Src, ext::oneapi::experimental::image_mem_handle Dest,
[ 3161]       const ext::oneapi::experimental::image_descriptor &DestImgDesc);
[ 3162] 
[ 3163]   /// Copies data from one memory region to another, where \p Src is a USM
[ 3164]   /// pointer and \p Dest is an opaque image memory handle. Allows for a
[ 3165]   /// sub-region copy, where \p SrcOffset , \p DestOffset , and \p CopyExtent
[ 3166]   /// are used to determine the sub-region. Pixel size is determined
[ 3167]   /// by \p DestImgDesc
[ 3168]   /// An exception is thrown if either \p Src is nullptr or \p Dest is
[ 3169]   /// incomplete.
[ 3170]   ///
[ 3171]   /// \param Src is a USM pointer to the source memory.
[ 3172]   /// \param SrcOffset is an offset from the origin where the x, y, and z
[ 3173]   ///                  components are measured in bytes, rows, and slices
[ 3174]   ///                  respectively
[ 3175]   /// \param SrcExtent is the extent of the source memory to copy, measured in
[ 3176]   ///                  pixels (pixel size determined by \p DestImgDesc )
[ 3177]   /// \param Dest is an opaque image memory handle to the destination memory.
[ 3178]   /// \param DestOffset is an offset from the destination origin measured in
[ 3179]   ///                   pixels (pixel size determined by \p DestImgDesc )
[ 3180]   /// \param DestImgDesc is the destination image descriptor
[ 3181]   /// \param CopyExtent is the width, height, and depth of the region to copy
[ 3182]   ///               measured in pixels as determined by \p DestImgDesc
[ 3183]   void ext_oneapi_copy(
[ 3184]       void *Src, sycl::range<3> SrcOffset, sycl::range<3> SrcExtent,
[ 3185]       ext::oneapi::experimental::image_mem_handle Dest,
[ 3186]       sycl::range<3> DestOffset,
[ 3187]       const ext::oneapi::experimental::image_descriptor &DestImgDesc,
[ 3188]       sycl::range<3> CopyExtent);
[ 3189] 
[ 3190]   /// Copies data from one memory region to another, where \p Src is an opaque
[ 3191]   /// image memory handle and \p Dest is a USM pointer.
[ 3192]   /// An exception is thrown if either \p Src is incomplete or \p Dest is
[ 3193]   /// nullptr. The behavior is undefined if \p Desc is inconsistent with the
[ 3194]   /// allocated memory region.
[ 3195]   ///
[ 3196]   /// \param Src is an opaque image memory handle to the source memory.
[ 3197]   /// \param Dest is a USM pointer to the destination memory.
[ 3198]   /// \param SrcImgDesc is the source image descriptor
[ 3199]   void ext_oneapi_copy(
[ 3200]       ext::oneapi::experimental::image_mem_handle Src, void *Dest,
[ 3201]       const ext::oneapi::experimental::image_descriptor &SrcImgDesc);
[ 3202] 
[ 3203]   /// Copies data from one memory region to another, where \p Src is an opaque
[ 3204]   /// image memory handle and \p Dest is a USM pointer. Allows for a
[ 3205]   /// sub-region copy, where \p SrcOffset , \p DestOffset , and \p Extent are
[ 3206]   /// used to determine the sub-region.  Pixel size is determined
[ 3207]   /// by \p SrcImgDesc
[ 3208]   /// An exception is thrown if either \p Src is nullptr or \p Dest is
[ 3209]   /// incomplete.
[ 3210]   ///
[ 3211]   /// \param Src is an opaque image memory handle to the source memory.
[ 3212]   /// \param SrcOffset is an offset from the origin of source measured in pixels
[ 3213]   ///                   (pixel size determined by \p SrcImgDesc )
[ 3214]   /// \param SrcImgDesc is the source image descriptor
[ 3215]   /// \param Dest is a USM pointer to the destination memory.
[ 3216]   /// \param DestOffset is an offset from the destination origin where the
[ 3217]   ///                  x, y, and z components are measured in bytes, rows,
[ 3218]   ///                  and slices respectively
[ 3219]   /// \param DestExtent is the extent of the dest memory to copy, measured in
[ 3220]   ///                  pixels (pixel size determined by \p DestImgDesc )
[ 3221]   /// \param CopyExtent is the width, height, and depth of the region to copy
[ 3222]   ///               measured in pixels (pixel size determined by
[ 3223]   ///               \p SrcImgDesc )
[ 3224]   void
[ 3225]   ext_oneapi_copy(ext::oneapi::experimental::image_mem_handle Src,
[ 3226]                   sycl::range<3> SrcOffset,
[ 3227]                   const ext::oneapi::experimental::image_descriptor &SrcImgDesc,
[ 3228]                   void *Dest, sycl::range<3> DestOffset,
[ 3229]                   sycl::range<3> DestExtent, sycl::range<3> CopyExtent);
[ 3230] 
[ 3231]   /// Copies data from one memory region to another, where \p Src and \p Dest
[ 3232]   /// are USM pointers. An exception is thrown if either \p Src is nullptr, \p
[ 3233]   /// Dest is nullptr, or \p Pitch is inconsistent with hardware requirements.
[ 3234]   /// The behavior is undefined if \p Desc is inconsistent with the allocated
[ 3235]   /// memory region.
[ 3236]   ///
[ 3237]   /// \param Src is a USM pointer to the source memory.
[ 3238]   /// \param Dest is a USM pointer to the destination memory.
[ 3239]   /// \param DeviceImgDesc is the image descriptor (format, order, dimensions).
[ 3240]   /// \param DeviceRowPitch is the pitch of the rows on the device.
[ 3241]   void ext_oneapi_copy(
[ 3242]       void *Src, void *Dest,
[ 3243]       const ext::oneapi::experimental::image_descriptor &DeviceImgDesc,
[ 3244]       size_t DeviceRowPitch);
[ 3245] 
[ 3246]   /// Copies data from one memory region to another, where \p Src and \p Dest
[ 3247]   /// are USM pointers. Allows for a sub-region copy, where \p SrcOffset ,
[ 3248]   /// \p DestOffset , and \p Extent are used to determine the sub-region.
[ 3249]   /// Pixel size is determined by \p DestImgDesc
[ 3250]   /// An exception is thrown if either \p Src is nullptr or \p Dest is
[ 3251]   /// incomplete.
[ 3252]   ///
[ 3253]   /// \param Src is a USM pointer to the source memory.
[ 3254]   /// \param SrcOffset is an destination offset from the origin where the
[ 3255]   ///                  x, y, and z components are measured in bytes, rows,
[ 3256]   ///                  and slices respectively
[ 3257]   /// \param Dest is a USM pointer to the destination memory.
[ 3258]   /// \param DestOffset is an destination offset from the origin where the
[ 3259]   ///                  x, y, and z components are measured in bytes, rows,
[ 3260]   ///                  and slices respectively
[ 3261]   /// \param DeviceImgDesc is the device image descriptor
[ 3262]   /// \param DeviceRowPitch is the row pitch on the device
[ 3263]   /// \param HostExtent is the extent of the dest memory to copy, measured in
[ 3264]   ///                  pixels (pixel size determined by \p DeviceImgDesc )
[ 3265]   /// \param CopyExtent is the width, height, and depth of the region to copy
[ 3266]   ///               measured in pixels (pixel size determined by
[ 3267]   ///               \p DeviceImgDesc )
[ 3268]   void ext_oneapi_copy(
[ 3269]       void *Src, sycl::range<3> SrcOffset, void *Dest,
[ 3270]       sycl::range<3> DestOffset,
[ 3271]       const ext::oneapi::experimental::image_descriptor &DeviceImgDesc,
[ 3272]       size_t DeviceRowPitch, sycl::range<3> HostExtent,
[ 3273]       sycl::range<3> CopyExtent);
[ 3274] 
[ 3275]   /// Instruct the queue with a non-blocking wait on an external semaphore.
[ 3276]   /// An exception is thrown if \p SemaphoreHandle is incomplete.
[ 3277]   ///
[ 3278]   /// \param SemaphoreHandle is an opaque external interop semaphore handle
[ 3279]   void ext_oneapi_wait_external_semaphore(
[ 3280]       sycl::ext::oneapi::experimental::interop_semaphore_handle
[ 3281]           SemaphoreHandle);
[ 3282] 
[ 3283]   /// Instruct the queue to signal the external semaphore once all previous
[ 3284]   /// commands have completed execution.
[ 3285]   /// An exception is thrown if \p SemaphoreHandle is incomplete.
[ 3286]   ///
[ 3287]   /// \param SemaphoreHandle is an opaque external interop semaphore handle
[ 3288]   void ext_oneapi_signal_external_semaphore(
[ 3289]       sycl::ext::oneapi::experimental::interop_semaphore_handle
[ 3290]           SemaphoreHandle);
[ 3291] 
[ 3292] private:
[ 3293]   std::shared_ptr<detail::handler_impl> MImpl;
[ 3294]   std::shared_ptr<detail::queue_impl> MQueue;
[ 3295] 
[ 3296]   /// The storage for the arguments passed.
[ 3297]   /// We need to store a copy of values that are passed explicitly through
[ 3298]   /// set_arg, require and so on, because we need them to be alive after
[ 3299]   /// we exit the method they are passed in.
[ 3300]   mutable detail::CG::StorageInitHelper CGData;
[ 3301]   std::vector<detail::LocalAccessorImplPtr> MLocalAccStorage;
[ 3302]   std::vector<std::shared_ptr<detail::stream_impl>> MStreamStorage;
[ 3303]   /// The list of arguments for the kernel.
[ 3304]   std::vector<detail::ArgDesc> MArgs;
[ 3305]   /// The list of associated accessors with this handler.
[ 3306]   /// These accessors were created with this handler as argument or
[ 3307]   /// have become required for this handler via require method.
[ 3308]   std::vector<detail::ArgDesc> MAssociatedAccesors;
[ 3309]   /// Struct that encodes global size, local size, ...
[ 3310]   detail::NDRDescT MNDRDesc;
[ 3311]   std::string MKernelName;
[ 3312]   /// Storage for a sycl::kernel object.
[ 3313]   std::shared_ptr<detail::kernel_impl> MKernel;
[ 3314]   /// Type of the command group, e.g. kernel, fill. Can also encode version.
[ 3315]   /// Use getType and setType methods to access this variable unless
[ 3316]   /// manipulations with version are required
[ 3317]   detail::CG::CGTYPE MCGType = detail::CG::None;
[ 3318]   /// Pointer to the source host memory or accessor(depending on command type).
[ 3319]   void *MSrcPtr = nullptr;
[ 3320]   /// Pointer to the dest host memory or accessor(depends on command type).
[ 3321]   void *MDstPtr = nullptr;
[ 3322]   /// Length to copy or fill (for USM operations).
[ 3323]   size_t MLength = 0;
[ 3324]   /// Pattern that is used to fill memory object in case command type is fill.
[ 3325]   std::vector<char> MPattern;
[ 3326]   /// Storage for a lambda or function object.
[ 3327]   std::unique_ptr<detail::HostKernelBase> MHostKernel;
[ 3328]   /// Storage for lambda/function when using HostTask
[ 3329]   std::unique_ptr<detail::HostTask> MHostTask;
[ 3330]   /// The list of valid SYCL events that need to complete
[ 3331]   /// before barrier command can be executed
[ 3332]   std::vector<detail::EventImplPtr> MEventsWaitWithBarrier;
[ 3333] 
[ 3334]   /// The graph that is associated with this handler.
[ 3335]   std::shared_ptr<ext::oneapi::experimental::detail::graph_impl> MGraph;
[ 3336]   /// If we are submitting a graph using ext_oneapi_graph this will be the graph
[ 3337]   /// to be executed.
[ 3338]   std::shared_ptr<ext::oneapi::experimental::detail::exec_graph_impl>
[ 3339]       MExecGraph;
[ 3340]   /// Storage for a node created from a subgraph submission.
[ 3341]   std::shared_ptr<ext::oneapi::experimental::detail::node_impl> MSubgraphNode;
[ 3342]   /// Storage for the CG created when handling graph nodes added explicitly.
[ 3343]   std::unique_ptr<detail::CG> MGraphNodeCG;
[ 3344] 
[ 3345]   bool MIsHost = false;
[ 3346] 
[ 3347]   detail::code_location MCodeLoc = {};
[ 3348]   bool MIsFinalized = false;
[ 3349]   event MLastEvent;
[ 3350] 
[ 3351]   // Make queue_impl class friend to be able to call finalize method.
[ 3352]   friend class detail::queue_impl;
[ 3353]   // Make accessor class friend to keep the list of associated accessors.
[ 3354]   template <typename DataT, int Dims, access::mode AccMode,
[ 3355]             access::target AccTarget, access::placeholder isPlaceholder,
[ 3356]             typename PropertyListT>
[ 3357]   friend class accessor;
[ 3358]   friend device detail::getDeviceFromHandler(handler &);
[ 3359] 
[ 3360]   template <typename DataT, int Dimensions, access::mode AccessMode,
[ 3361]             access::target AccessTarget, access::placeholder IsPlaceholder>
[ 3362]   friend class detail::image_accessor;
[ 3363]   // Make stream class friend to be able to keep the list of associated streams
[ 3364]   friend class stream;
[ 3365]   friend class detail::stream_impl;
[ 3366]   // Make reduction friends to store buffers and arrays created for it
[ 3367]   // in handler from reduction methods.
[ 3368]   template <typename T, class BinaryOperation, int Dims, size_t Extent,
[ 3369]             bool ExplicitIdentity, typename RedOutVar>
[ 3370]   friend class detail::reduction_impl_algo;
[ 3371] 
[ 3372]   friend inline void detail::reduction::finalizeHandler(handler &CGH);
[ 3373]   template <class FunctorTy>
[ 3374]   friend void detail::reduction::withAuxHandler(handler &CGH, FunctorTy Func);
[ 3375] 
[ 3376]   template <typename KernelName, detail::reduction::strategy Strategy, int Dims,
[ 3377]             typename PropertiesT, typename... RestT>
[ 3378]   friend void detail::reduction_parallel_for(handler &CGH, range<Dims> NDRange,
[ 3379]                                              PropertiesT Properties,
[ 3380]                                              RestT... Rest);
[ 3381] 
[ 3382]   template <typename KernelName, detail::reduction::strategy Strategy, int Dims,
[ 3383]             typename PropertiesT, typename... RestT>
[ 3384]   friend void
[ 3385]   detail::reduction_parallel_for(handler &CGH, nd_range<Dims> NDRange,
[ 3386]                                  PropertiesT Properties, RestT... Rest);
[ 3387] 
[ 3388] #ifndef __SYCL_DEVICE_ONLY__
[ 3389]   friend void detail::associateWithHandler(handler &,
[ 3390]                                            detail::AccessorBaseHost *,
[ 3391]                                            access::target);
[ 3392]   friend void detail::associateWithHandler(
[ 3393]       handler &, detail::UnsampledImageAccessorBaseHost *, image_target);
[ 3394]   friend void detail::associateWithHandler(
[ 3395]       handler &, detail::SampledImageAccessorBaseHost *, image_target);
[ 3396] #endif
[ 3397] 
[ 3398]   friend class ::MockHandler;
[ 3399]   friend class detail::queue_impl;
[ 3400] 
[ 3401]   // Make pipe class friend to be able to call ext_intel_read/write_host_pipe
[ 3402]   // method.
[ 3403]   template <class _name, class _dataT, int32_t _min_capacity,
[ 3404]             class _propertiesT, class>
[ 3405]   friend class ext::intel::experimental::pipe;
[ 3406] 
[ 3407]   /// Read from a host pipe given a host address and
[ 3408]   /// \param Name name of the host pipe to be passed into lower level runtime
[ 3409]   /// \param Ptr host pointer of host pipe as identified by address of its const
[ 3410]   ///        expr m_Storage member
[ 3411]   /// \param Size the size of data getting read back / to.
[ 3412]   /// \param Block if read operation is blocking, default to false.
[ 3413]   void ext_intel_read_host_pipe(const std::string &Name, void *Ptr, size_t Size,
[ 3414]                                 bool Block = false);
[ 3415] 
[ 3416]   /// Write to host pipes given a host address and
[ 3417]   /// \param Name name of the host pipe to be passed into lower level runtime
[ 3418]   /// \param Ptr host pointer of host pipe as identified by address of its const
[ 3419]   /// expr m_Storage member
[ 3420]   /// \param Size the size of data getting read back / to.
[ 3421]   /// \param Block if write opeartion is blocking, default to false.
[ 3422]   void ext_intel_write_host_pipe(const std::string &Name, void *Ptr,
[ 3423]                                  size_t Size, bool Block = false);
[ 3424]   friend class ext::oneapi::experimental::detail::graph_impl;
[ 3425] 
[ 3426]   bool DisableRangeRounding();
[ 3427] 
[ 3428]   bool RangeRoundingTrace();
[ 3429] 
[ 3430]   void GetRangeRoundingSettings(size_t &MinFactor, size_t &GoodFactor,
[ 3431]                                 size_t &MinRange);
[ 3432] 
[ 3433]   template <typename WrapperT, typename TransformedArgType, int Dims,
[ 3434]             typename KernelType,
[ 3435]             std::enable_if_t<detail::KernelLambdaHasKernelHandlerArgT<
[ 3436]                 KernelType, TransformedArgType>::value> * = nullptr>
[ 3437]   auto getRangeRoundedKernelLambda(KernelType KernelFunc,
[ 3438]                                    range<Dims> UserRange) {
[ 3439]     return detail::RoundedRangeKernelWithKH<TransformedArgType, Dims,
[ 3440]                                             KernelType>{UserRange, KernelFunc};
[ 3441]   }
[ 3442] 
[ 3443]   template <typename WrapperT, typename TransformedArgType, int Dims,
[ 3444]             typename KernelType,
[ 3445]             std::enable_if_t<!detail::KernelLambdaHasKernelHandlerArgT<
[ 3446]                 KernelType, TransformedArgType>::value> * = nullptr>
[ 3447]   auto getRangeRoundedKernelLambda(KernelType KernelFunc,
[ 3448]                                    range<Dims> UserRange) {
[ 3449]     return detail::RoundedRangeKernel<TransformedArgType, Dims, KernelType>{
[ 3450]         UserRange, KernelFunc};
[ 3451]   }
[ 3452] 
[ 3453]   const std::shared_ptr<detail::context_impl> &getContextImplPtr() const;
[ 3454] 
[ 3455]   // Checks if 2D memory operations are supported by the underlying platform.
[ 3456]   bool supportsUSMMemcpy2D();
[ 3457]   bool supportsUSMFill2D();
[ 3458]   bool supportsUSMMemset2D();
[ 3459] 
[ 3460]   // Helper function for getting a loose bound on work-items.
[ 3461]   id<2> computeFallbackKernelBounds(size_t Width, size_t Height);
[ 3462] 
[ 3463]   // Common function for launching a 2D USM memcpy kernel to avoid redefinitions
[ 3464]   // of the kernel from copy and memcpy.
[ 3465]   template <typename T>
[ 3466]   void commonUSMCopy2DFallbackKernel(const void *Src, size_t SrcPitch,
[ 3467]                                      void *Dest, size_t DestPitch, size_t Width,
[ 3468]                                      size_t Height) {
[ 3469]     // Otherwise the data is accessible on the device so we do the operation
[ 3470]     // there instead.
[ 3471]     // Limit number of work items to be resistant to big copies.
[ 3472]     id<2> Chunk = computeFallbackKernelBounds(Height, Width);
[ 3473]     id<2> Iterations = (Chunk + id<2>{Height, Width} - 1) / Chunk;
[ 3474]     parallel_for<__usmmemcpy2d<T>>(
[ 3475]         range<2>{Chunk[0], Chunk[1]}, [=](id<2> Index) {
[ 3476]           T *CastedDest = static_cast<T *>(Dest);
[ 3477]           const T *CastedSrc = static_cast<const T *>(Src);
[ 3478]           for (uint32_t I = 0; I < Iterations[0]; ++I) {
[ 3479]             for (uint32_t J = 0; J < Iterations[1]; ++J) {
[ 3480]               id<2> adjustedIndex = Index + Chunk * id<2>{I, J};
[ 3481]               if (adjustedIndex[0] < Height && adjustedIndex[1] < Width) {
[ 3482]                 CastedDest[adjustedIndex[0] * DestPitch + adjustedIndex[1]] =
[ 3483]                     CastedSrc[adjustedIndex[0] * SrcPitch + adjustedIndex[1]];
[ 3484]               }
[ 3485]             }
[ 3486]           }
[ 3487]         });
[ 3488]   }
[ 3489] 
[ 3490]   // Common function for launching a 2D USM memcpy host-task to avoid
[ 3491]   // redefinitions of the kernel from copy and memcpy.
[ 3492]   template <typename T>
[ 3493]   void commonUSMCopy2DFallbackHostTask(const void *Src, size_t SrcPitch,
[ 3494]                                        void *Dest, size_t DestPitch,
[ 3495]                                        size_t Width, size_t Height) {
[ 3496]     // If both pointers are host USM or unknown (assumed non-USM) we use a
[ 3497]     // host-task to satisfy dependencies.
[ 3498]     host_task([=] {
[ 3499]       const T *CastedSrc = static_cast<const T *>(Src);
[ 3500]       T *CastedDest = static_cast<T *>(Dest);
[ 3501]       for (size_t I = 0; I < Height; ++I) {
[ 3502]         const T *SrcItBegin = CastedSrc + SrcPitch * I;
[ 3503]         T *DestItBegin = CastedDest + DestPitch * I;
[ 3504]         std::copy(SrcItBegin, SrcItBegin + Width, DestItBegin);
[ 3505]       }
[ 3506]     });
[ 3507]   }
[ 3508] 
[ 3509]   // StageFillCG()  Supporting function to fill()
[ 3510]   template <typename T, int Dims, access::mode AccessMode,
[ 3511]             access::target AccessTarget,
[ 3512]             access::placeholder IsPlaceholder = access::placeholder::false_t,
[ 3513]             typename PropertyListT = property_list>
[ 3514]   void StageFillCG(
[ 3515]       accessor<T, Dims, AccessMode, AccessTarget, IsPlaceholder, PropertyListT>
[ 3516]           Dst,
[ 3517]       const T &Pattern) {
[ 3518]     setType(detail::CG::Fill);
[ 3519]     detail::AccessorBaseHost *AccBase = (detail::AccessorBaseHost *)&Dst;
[ 3520]     detail::AccessorImplPtr AccImpl = detail::getSyclObjImpl(*AccBase);
[ 3521] 
[ 3522]     MDstPtr = static_cast<void *>(AccImpl.get());
[ 3523]     CGData.MRequirements.push_back(AccImpl.get());
[ 3524]     CGData.MAccStorage.push_back(std::move(AccImpl));
[ 3525] 
[ 3526]     MPattern.resize(sizeof(T));
[ 3527]     auto PatternPtr = reinterpret_cast<T *>(MPattern.data());
[ 3528]     *PatternPtr = Pattern;
[ 3529]   }
[ 3530] 
[ 3531]   // Common function for launching a 2D USM fill kernel to avoid redefinitions
[ 3532]   // of the kernel from memset and fill.
[ 3533]   template <typename T>
[ 3534]   void commonUSMFill2DFallbackKernel(void *Dest, size_t DestPitch,
[ 3535]                                      const T &Pattern, size_t Width,
[ 3536]                                      size_t Height) {
[ 3537]     // Otherwise the data is accessible on the device so we do the operation
[ 3538]     // there instead.
[ 3539]     // Limit number of work items to be resistant to big fill operations.
[ 3540]     id<2> Chunk = computeFallbackKernelBounds(Height, Width);
[ 3541]     id<2> Iterations = (Chunk + id<2>{Height, Width} - 1) / Chunk;
[ 3542]     parallel_for<__usmfill2d<T>>(
[ 3543]         range<2>{Chunk[0], Chunk[1]}, [=](id<2> Index) {
[ 3544]           T *CastedDest = static_cast<T *>(Dest);
[ 3545]           for (uint32_t I = 0; I < Iterations[0]; ++I) {
[ 3546]             for (uint32_t J = 0; J < Iterations[1]; ++J) {
[ 3547]               id<2> adjustedIndex = Index + Chunk * id<2>{I, J};
[ 3548]               if (adjustedIndex[0] < Height && adjustedIndex[1] < Width) {
[ 3549]                 CastedDest[adjustedIndex[0] * DestPitch + adjustedIndex[1]] =
[ 3550]                     Pattern;
[ 3551]               }
[ 3552]             }
[ 3553]           }
[ 3554]         });
[ 3555]   }
[ 3556] 
[ 3557]   // Common function for launching a 2D USM fill kernel or host_task to avoid
[ 3558]   // redefinitions of the kernel from memset and fill.
[ 3559]   template <typename T>
[ 3560]   void commonUSMFill2DFallbackHostTask(void *Dest, size_t DestPitch,
[ 3561]                                        const T &Pattern, size_t Width,
[ 3562]                                        size_t Height) {
[ 3563]     // If the pointer is host USM or unknown (assumed non-USM) we use a
[ 3564]     // host-task to satisfy dependencies.
[ 3565]     host_task([=] {
[ 3566]       T *CastedDest = static_cast<T *>(Dest);
[ 3567]       for (size_t I = 0; I < Height; ++I) {
[ 3568]         T *ItBegin = CastedDest + DestPitch * I;
[ 3569]         std::fill(ItBegin, ItBegin + Width, Pattern);
[ 3570]       }
[ 3571]     });
[ 3572]   }
[ 3573] 
[ 3574]   // Implementation of ext_oneapi_memcpy2d using command for native 2D memcpy.
[ 3575]   void ext_oneapi_memcpy2d_impl(void *Dest, size_t DestPitch, const void *Src,
[ 3576]                                 size_t SrcPitch, size_t Width, size_t Height);
[ 3577] 
[ 3578]   // Untemplated version of ext_oneapi_fill2d using command for native 2D fill.
[ 3579]   void ext_oneapi_fill2d_impl(void *Dest, size_t DestPitch, const void *Value,
[ 3580]                               size_t ValueSize, size_t Width, size_t Height);
[ 3581] 
[ 3582]   // Implementation of ext_oneapi_memset2d using command for native 2D memset.
[ 3583]   void ext_oneapi_memset2d_impl(void *Dest, size_t DestPitch, int Value,
[ 3584]                                 size_t Width, size_t Height);
[ 3585] 
[ 3586]   // Implementation of memcpy to device_global.
[ 3587]   void memcpyToDeviceGlobal(const void *DeviceGlobalPtr, const void *Src,
[ 3588]                             bool IsDeviceImageScoped, size_t NumBytes,
[ 3589]                             size_t Offset);
[ 3590] 
[ 3591]   // Implementation of memcpy from device_global.
[ 3592]   void memcpyFromDeviceGlobal(void *Dest, const void *DeviceGlobalPtr,
[ 3593]                               bool IsDeviceImageScoped, size_t NumBytes,
[ 3594]                               size_t Offset);
[ 3595] 
[ 3596]   // Implementation of memcpy to an unregistered device_global.
[ 3597]   void memcpyToHostOnlyDeviceGlobal(const void *DeviceGlobalPtr,
[ 3598]                                     const void *Src, size_t DeviceGlobalTSize,
[ 3599]                                     bool IsDeviceImageScoped, size_t NumBytes,
[ 3600]                                     size_t Offset);
[ 3601] 
[ 3602]   // Implementation of memcpy from an unregistered device_global.
[ 3603]   void memcpyFromHostOnlyDeviceGlobal(void *Dest, const void *DeviceGlobalPtr,
[ 3604]                                       bool IsDeviceImageScoped, size_t NumBytes,
[ 3605]                                       size_t Offset);
[ 3606] 
[ 3607]   template <typename T, int Dims, access::mode AccessMode,
[ 3608]             access::target AccessTarget,
[ 3609]             access::placeholder IsPlaceholder = access::placeholder::false_t,
[ 3610]             typename PropertyListT = property_list>
[ 3611]   void checkIfPlaceholderIsBoundToHandler(
[ 3612]       accessor<T, Dims, AccessMode, AccessTarget, IsPlaceholder, PropertyListT>
[ 3613]           Acc) {
[ 3614]     auto *AccBase = reinterpret_cast<detail::AccessorBaseHost *>(&Acc);
[ 3615]     detail::AccessorImplPtr AccImpl = detail::getSyclObjImpl(*AccBase);
[ 3616]     detail::AccessorImplHost *Req = AccImpl.get();
[ 3617]     if (std::find_if(MAssociatedAccesors.begin(), MAssociatedAccesors.end(),
[ 3618]                      [&](const detail::ArgDesc &AD) {
[ 3619]                        return AD.MType ==
[ 3620]                                   detail::kernel_param_kind_t::kind_accessor &&
[ 3621]                               AD.MPtr == Req &&
[ 3622]                               AD.MSize == static_cast<int>(AccessTarget);
[ 3623]                      }) == MAssociatedAccesors.end())
[ 3624]       throw sycl::exception(make_error_code(errc::kernel_argument),
[ 3625]                             "placeholder accessor must be bound by calling "
[ 3626]                             "handler::require() before it can be used.");
[ 3627]   }
[ 3628] 
[ 3629]   template <typename PropertiesT>
[ 3630]   std::enable_if_t<
[ 3631]       ext::oneapi::experimental::is_property_list<PropertiesT>::value>
[ 3632]   throwIfGraphAssociatedAndKernelProperties() const {
[ 3633]     if (!std::is_same_v<PropertiesT,
[ 3634]                         ext::oneapi::experimental::empty_properties_t>)
[ 3635]       throwIfGraphAssociated<
[ 3636]           ext::oneapi::experimental::detail::UnsupportedGraphFeatures::
[ 3637]               sycl_ext_oneapi_kernel_properties>();
[ 3638]   }
[ 3639] 
[ 3640]   // Set value of the gpu cache configuration for the kernel.
[ 3641]   void setKernelCacheConfig(sycl::detail::pi::PiKernelCacheConfig);
[ 3642] 
[ 3643]   template <
[ 3644]       ext::oneapi::experimental::detail::UnsupportedGraphFeatures FeatureT>
[ 3645]   void throwIfGraphAssociated() const {
[ 3646] 
[ 3647]     if (getCommandGraph()) {
[ 3648]       std::string FeatureString =
[ 3649]           ext::oneapi::experimental::detail::UnsupportedFeatureToString(
[ 3650]               FeatureT);
[ 3651]       throw sycl::exception(sycl::make_error_code(errc::invalid),
[ 3652]                             "The " + FeatureString +
[ 3653]                                 " feature is not yet available "
[ 3654]                                 "for use with the SYCL Graph extension.");
[ 3655]     }
[ 3656]   }
[ 3657] };
[ 3658] } // namespace _V1
[ 3659] } // namespace sycl

